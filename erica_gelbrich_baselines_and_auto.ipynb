{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28ac6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import modularised_utils as mut\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import opt_utils as oput\n",
    "\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "from scipy.linalg import sqrtm\n",
    "\n",
    "import params\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677de9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'synth1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897015a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the radius of the Wasserstein balls (epsilon, delta) and the size for both models.\n",
    "epsilon         = params.radius[experiment][0]\n",
    "ll_num_envs     = params.n_envs[experiment][0]\n",
    "\n",
    "delta           = params.radius[experiment][1]\n",
    "hl_num_envs     = params.n_envs[experiment][1]\n",
    "\n",
    "# Define the number of samples per environment. Currently every environment has the same number of samples\n",
    "num_llsamples   = params.n_samples[experiment][0]\n",
    "num_hlsamples   = params.n_samples[experiment][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ccf37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dll = mut.load_samples(experiment)[None][0] \n",
    "Gll = mut.load_ll_model(experiment)[0]\n",
    "Ill = mut.load_ll_model(experiment)[1]\n",
    "\n",
    "\n",
    "Dhl = mut.load_samples(experiment)[None][1] \n",
    "Ghl = mut.load_hl_model(experiment)[0]\n",
    "Ihl = mut.load_hl_model(experiment)[1]\n",
    "\n",
    "omega = mut.load_omega_map(experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9fb9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_coeffs = mut.get_coefficients(Dll, Gll)\n",
    "hl_coeffs = mut.get_coefficients(Dhl, Ghl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e42545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # [Not suggested] In case we want to explore also the interventional --> worse estimation!\n",
    "# Dlls, Dhls = [], []\n",
    "# for dpair in list(mut.load_samples(experiment).values()):\n",
    "#     Dlls.append(dpair[0])\n",
    "#     Dhls.append(dpair[1])\n",
    "    \n",
    "# ll_coeffs = mut.get_coefficients(Dlls, Gll)\n",
    "# hl_coeffs = mut.get_coefficients(Dhls, Ghl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75470de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_ll_hat, mu_U_ll_hat, Sigma_U_ll_hat = mut.lan_abduction(Dll, Gll, ll_coeffs)\n",
    "U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat = mut.lan_abduction(Dhl, Ghl, hl_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53e18c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLmodels = {}\n",
    "for iota in Ill:\n",
    "    LLmodels[iota] = lanm.LinearAddSCM(Gll, ll_coeffs, iota)\n",
    "    \n",
    "HLmodels, Dhl_samples = {}, {}\n",
    "for eta in Ihl:\n",
    "    HLmodels[eta] = lanm.LinearAddSCM(Ghl, hl_coeffs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ce2f759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1607, 0.5735, 0.0607],\n",
      "        [0.5735, 2.0470, 0.2167],\n",
      "        [0.0607, 0.2167, 1.0000]])\n",
      "tensor([[1.1607, 0.5735, 0.0607],\n",
      "        [0.5735, 2.0470, 0.2167],\n",
      "        [0.0607, 0.2167, 1.0000]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 2.0470, 0.2167],\n",
      "        [0.0000, 0.2167, 1.0000]])\n",
      "tensor([[1.1607, 0.5735, 0.0607],\n",
      "        [0.5735, 2.0470, 0.2167],\n",
      "        [0.0607, 0.2167, 1.0000]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 2.0470, 0.2167],\n",
      "        [0.0000, 0.2167, 1.0000]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 2.0470, 0.2167],\n",
      "        [0.0000, 0.2167, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "L_matrices = compute_struc_matrices(LLmodels, Ill)\n",
    "\n",
    "for L in L_matrices:\n",
    "    print(L @ Sigma_U_ll_hat @ L.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "838bcd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_U_ll_hat    = torch.from_numpy(np.array([0, 0, 0])).float()  \n",
    "Sigma_U_ll_hat = torch.from_numpy(np.diag([1, 2, 1])).float() \n",
    "\n",
    "mu_U_hl_hat    = torch.from_numpy(np.array([0, 0])).float()  \n",
    "Sigma_U_hl_hat = torch.from_numpy(np.diag([1, 1])).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1907803",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_L    = mu_U_ll_hat\n",
    "Sigma_L = Sigma_U_ll_hat\n",
    "\n",
    "mu_H    = mu_U_hl_hat\n",
    "Sigma_H = Sigma_U_hl_hat\n",
    "\n",
    "l = mu_L.shape[0]\n",
    "h = mu_H.shape[0]\n",
    "\n",
    "lambda_L =.2\n",
    "lambda_H =.3\n",
    "eta      = .01\n",
    "max_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae33f25e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected np.ndarray (got Tensor)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mu_L    \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mu_U_ll_hat)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      2\u001b[0m Sigma_L \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(Sigma_U_ll_hat)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m      4\u001b[0m mu_H    \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(mu_U_hl_hat)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected np.ndarray (got Tensor)"
     ]
    }
   ],
   "source": [
    "mu_L    = torch.from_numpy(mu_U_ll_hat).float()\n",
    "Sigma_L = torch.from_numpy(Sigma_U_ll_hat).float()\n",
    "\n",
    "mu_H    = torch.from_numpy(mu_U_hl_hat).float()\n",
    "Sigma_H = torch.from_numpy(Sigma_U_hl_hat).float()\n",
    "\n",
    "l = mu_L.shape[0]\n",
    "h = mu_H.shape[0]\n",
    "\n",
    "lambda_L =.2\n",
    "lambda_H =.3\n",
    "eta      = .01\n",
    "max_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5e43ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the necessary functions using PyTorch for automatic differentiation\n",
    "# def F_func(mu_L, Sigma_L, mu_H, Sigma_H, LLmodels, HLmodels, lambda_L, lambda_H, hat_mu_L, hat_Sigma_L, hat_mu_H, hat_Sigma_H, epsilon, delta):\n",
    "#     term1 = 0\n",
    "#     term2 = 0\n",
    "#     term3 = 0\n",
    "\n",
    "#     # Loop to compute the sum of terms\n",
    "#     for n, iota in enumerate(Ill):\n",
    "#         L_i = torch.from_numpy(LLmodels[iota].compute_mechanism()).float()  # Convert to float32\n",
    "#         V_i = T @ L_i  # Matrix multiplication, ensure V_i is float32\n",
    "#         H_i = torch.from_numpy(HLmodels[omega[iota]].compute_mechanism()).float()  # Convert to float32\n",
    "\n",
    "#         term1 += torch.norm(torch.matmul(V_i, mu_L) - torch.matmul(H_i, mu_H))**2 + torch.trace(torch.matmul(V_i, torch.matmul(Sigma_L, V_i.T))) + torch.trace(torch.matmul(H_i, torch.matmul(Sigma_H, H_i.T)))\n",
    "\n",
    "#     term2 = lambda_L * (epsilon**2 - torch.norm(mu_L - hat_mu_L)**2 - torch.norm(sqrtm_svd(Sigma_L) - sqrtm_svd(hat_Sigma_L))**2)\n",
    "#     term3 = lambda_H * (delta**2 - torch.norm(mu_H - hat_mu_H)**2 - torch.norm(sqrtm_svd(Sigma_H) - sqrtm_svd(hat_Sigma_H))**2)\n",
    "\n",
    "#     return term1 / n + term2 + term3\n",
    "\n",
    "# # Proximal operator for Sigma_L (using soft-thresholding)\n",
    "# def prox_Sigma_L(Sigma_L, lambda_L, LLmodels, HLmodels, Sigma_H):\n",
    "#     # Using the Frobenius norm as a soft-thresholding operator for Sigma_L\n",
    "#     prox = torch.zeros_like(Sigma_L)\n",
    "#     for n, iota in enumerate(Ill):\n",
    "#         L_i = torch.from_numpy(LLmodels[iota].compute_mechanism()).float()  \n",
    "#         V_i = T @ L_i  \n",
    "#         H_i = torch.from_numpy(HLmodels[omega[iota]].compute_mechanism()).float()  \n",
    "\n",
    "#         V_Sigma_V       = torch.matmul(V_i, torch.matmul(Sigma_L, V_i.T))\n",
    "#         sqrtm_V_Sigma_V = sqrtm_svd(V_Sigma_V)\n",
    "#         prox_i          = prox_operator(sqrtm_V_Sigma_V, lambda_L)\n",
    "#         ll_term         = torch.linalg.pinv(V_i) @ torch.matmul(prox_i, prox_i.T) @ torch.linalg.pinv(V_i).T\n",
    "\n",
    "#         H_Sigma_H       = torch.matmul(H_i, torch.matmul(Sigma_H, H_i.T))\n",
    "#         sqrtm_H_Sigma_H = sqrtm_svd(H_Sigma_H)\n",
    "#         hl_term         = torch.norm(sqrtm_H_Sigma_H, p='fro') \n",
    "       \n",
    "#         prox += ll_term * hl_term\n",
    "\n",
    "#     prox *= (2 / n)\n",
    "#     prox = diagonalize(prox)\n",
    "#     return prox\n",
    "\n",
    "# # Proximal operator for Sigma_H (using soft-thresholding)\n",
    "# def prox_Sigma_H(Sigma_H, lambda_H, LLmodels, HLmodels, Sigma_L):\n",
    "#     prox = torch.zeros_like(Sigma_H)\n",
    "#     for n, iota in enumerate(Ill):\n",
    "#         L_i = torch.from_numpy(LLmodels[iota].compute_mechanism()).float()  \n",
    "#         V_i = T @ L_i  \n",
    "#         H_i = torch.from_numpy(HLmodels[omega[iota]].compute_mechanism()).float()  \n",
    "       \n",
    "#         H_Sigma_H       = torch.matmul(H_i, torch.matmul(Sigma_H, H_i.T))\n",
    "#         sqrtm_H_Sigma_H = sqrtm_svd(H_Sigma_H)\n",
    "#         prox_i          = prox_operator(sqrtm_H_Sigma_H, lambda_H)\n",
    "#         hl_term         = torch.linalg.inv(H_i) @ torch.matmul(prox_i, prox_i.T) @ torch.linalg.inv(H_i).T\n",
    "#         #hl_term        = torch.inverse(H_i) @ torch.matmul(prox_i, prox_i.T) @ torch.inverse(H_i).T\n",
    "\n",
    "#         V_Sigma_V       = torch.matmul(V_i, torch.matmul(Sigma_L, V_i.T))\n",
    "#         sqrtm_V_Sigma_V = sqrtm_svd(V_Sigma_V)\n",
    "#         ll_term         = torch.norm(sqrtm_V_Sigma_V, p='fro') \n",
    "        \n",
    "#         prox     += ll_term * hl_term\n",
    "\n",
    "#     prox *= (2 / n)\n",
    "\n",
    "#     prox = diagonalize(prox)\n",
    "#     return prox\n",
    "\n",
    "# # Proximal operator of a matrix frobenious norm\n",
    "# def prox_operator(A, lambda_param):\n",
    "#     frobenius_norm = torch.norm(A, p='fro')\n",
    "#     scaling_factor = torch.max(1 - lambda_param / frobenius_norm, torch.zeros_like(frobenius_norm))\n",
    "#     return scaling_factor * A\n",
    "\n",
    "# def diagonalize(A):\n",
    "#     # Get eigenvalues and eigenvectors\n",
    "#     eigvals, eigvecs = torch.linalg.eig(A)  \n",
    "#     eigvals_real     = eigvals.real  \n",
    "#     eigvals_real     = torch.sqrt(eigvals_real)  # Take the square root of the eigenvalues\n",
    "\n",
    "#     return torch.diag(eigvals_real)\n",
    "\n",
    "# def sqrtm_svd(A):\n",
    "#     # Compute the SVD of A\n",
    "#     U, S, V = torch.svd(A)\n",
    "    \n",
    "#     # Take the square root of the singular values\n",
    "#     S_sqrt = torch.sqrt(torch.clamp(S, min=0.0))  # Ensure non-negative singular values\n",
    "    \n",
    "#     # Reconstruct the square root matrix\n",
    "#     sqrt_A = U @ torch.diag(S_sqrt) @ V.T\n",
    "    \n",
    "#     return sqrt_A\n",
    "\n",
    "# def sqrtm_eig(A):\n",
    "#     eigvals, eigvecs = torch.linalg.eig(A)\n",
    "#     eigvals_real = eigvals.real\n",
    "    \n",
    "#     # Ensure eigenvalues are non-negative for the square root to be valid\n",
    "#     eigvals_sqrt = torch.sqrt(torch.clamp(eigvals_real, min=0.0))  # Square root of non-negative eigenvalues\n",
    "\n",
    "#     # Reconstruct the square root of the matrix using the eigenvectors\n",
    "#     # Make sure the eigenvectors are also real\n",
    "#     eigvecs_real = eigvecs.real\n",
    "    \n",
    "#     # Reconstruct the matrix square root\n",
    "#     sqrt_A = eigvecs_real @ torch.diag(eigvals_sqrt) @ eigvecs_real.T\n",
    "    \n",
    "#     return sqrt_A\n",
    "\n",
    "\n",
    "# # Optimization loop using autograd and PyProximal (maximize using gradient ascent)\n",
    "# def optimize(LLmodels, HLmodels, mu_L, Sigma_L, mu_H, Sigma_H, hat_mu_L, hat_Sigma_L, hat_mu_H, hat_Sigma_H, epsilon, delta, lambda_L, lambda_H, eta, max_iter):\n",
    "#     mu_L.requires_grad_(True)  # Enable autograd for mu_L\n",
    "#     Sigma_L_half.requires_grad_(True)  # Enable autograd for Sigma_L\n",
    "#     mu_H.requires_grad_(True)  # Enable autograd for mu_H\n",
    "#     Sigma_H_half.requires_grad_(True)  # Enable autograd for Sigma_H\n",
    "\n",
    "#     for t in range(max_iter):\n",
    "#         print(f\"Iteration {t}\")\n",
    "        \n",
    "#         objective = F_func(mu_L, Sigma_L, mu_H, Sigma_H, LLmodels, HLmodels, lambda_L, lambda_H, hat_mu_L, hat_Sigma_L, hat_mu_H, hat_Sigma_H, epsilon, delta)\n",
    "#         objective.backward()\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             mu_L += eta * mu_L.grad  # Ascent for mu_L\n",
    "#             mu_H += eta * mu_H.grad  # Ascent for mu_H\n",
    "            \n",
    "#             print(f\"Sigma_L: {Sigma_L.grad}\")\n",
    "#             Sigma_L_half += eta * Sigma_L.grad  # Ascent for Sigma_L\n",
    "#             Sigma_H += eta * Sigma_H.grad  # Ascent for Sigma_H\n",
    "#             Sigma_L = prox_Sigma_L(Sigma_L_half, lambda_L, LLmodels, HLmodels, Sigma_H)\n",
    "#             print(Sigma_L)  \n",
    "#             Sigma_H = prox_Sigma_H(Sigma_H_half, lambda_H, LLmodels, HLmodels, Sigma_L)\n",
    "            \n",
    "#             #Zero the gradients after the update\n",
    "#             mu_L.grad.zero_()\n",
    "#             mu_H.grad.zero_()\n",
    "#             Sigma_L.grad.zero_()\n",
    "#             Sigma_H.grad.zero_()\n",
    "\n",
    "#             # if mu_L.grad is not None:\n",
    "#             #     mu_L.grad.zero_()\n",
    "#             # if mu_H.grad is not None:\n",
    "#             #     mu_H.grad.zero_()\n",
    "#             # if Sigma_L.grad is not None:\n",
    "#             #     Sigma_L.grad.zero_()\n",
    "#             # if Sigma_H.grad is not None:\n",
    "#             #     Sigma_H.grad.zero_()\n",
    "\n",
    "#         # Print progress\n",
    "#         if t % 10 == 0:\n",
    "#             print(f\"Iteration {t}, Objective Value: {objective.item()}\")\n",
    "\n",
    "#     return mu_L, Sigma_L, mu_H, Sigma_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "125e88f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def optimize_max(T, mu_L, Sigma_L, mu_H, Sigma_H, LLmodels, HLmodels, hat_mu_L, hat_Sigma_L, hat_mu_H, hat_Sigma_H, lambda_L, lambda_H, lambda_param, eta, num_steps_max):\n",
    "\n",
    "#     for t in range(num_steps_max): \n",
    "#         #print('mu_L before update:', mu_L)\n",
    "#         mu_L         = update_mu_L(T, mu_L, mu_H, LLmodels, HLmodels, lambda_L, hat_mu_L, eta)\n",
    "#         # print('mu_L after update:', mu_L)\n",
    "#         # print('mu_H before update:', mu_H)\n",
    "#         mu_H         = update_mu_H(T, mu_L, mu_H, LLmodels, HLmodels, lambda_H, hat_mu_H, eta)\n",
    "#         # print('mu_H after update:', mu_H)\n",
    "\n",
    "#         # print('Sigma_L before update:', Sigma_L)\n",
    "#         Sigma_L_half = update_Sigma_L_half(T, Sigma_L, LLmodels, lambda_L, hat_Sigma_L, eta)\n",
    "#         Sigma_L      = update_Sigma_L(T, Sigma_L_half, LLmodels, Sigma_H, HLmodels, lambda_param)\n",
    "#         # print('Sigma_L after update:', Sigma_L)\n",
    "        \n",
    "#         # print('Sigma_H before update:', Sigma_H)\n",
    "#         Sigma_H_half = update_Sigma_H_half(T, Sigma_H, HLmodels, lambda_H, hat_Sigma_H, eta)\n",
    "#         Sigma_H      = update_Sigma_H(T, Sigma_H_half, LLmodels, Sigma_L, HLmodels, lambda_param)\n",
    "#         # print('Sigma_H after update:', Sigma_H)\n",
    "        \n",
    "#         mu_L, Sigma_L, mu_H, Sigma_H = enforce_constraints(mu_L, Sigma_L, mu_H, Sigma_H, hat_mu_L, hat_Sigma_L, hat_mu_H, hat_Sigma_H, epsilon, delta)\n",
    "#         # print('mu_L after constraints:', mu_L)\n",
    "#         # print('Sigma_L after constraints:', Sigma_L)\n",
    "#         # print('mu_H after constraints:', mu_H)\n",
    "#         # print('Sigma_H after constraints:', Sigma_H)\n",
    "#         # print( )\n",
    "#         # Compute the objective function for the current iteration\n",
    "#         obj = 0\n",
    "        \n",
    "#         for i, iota in enumerate(Ill):\n",
    "#             L_i = torch.from_numpy(LLmodels[iota].compute_mechanism())\n",
    "#             V_i = T @ L_i.float()\n",
    "#             H_i = torch.from_numpy(HLmodels[omega[iota]].compute_mechanism()).float()\n",
    "                        \n",
    "#             L_i_mu_L = V_i @ mu_L\n",
    "#             H_i_mu_H = H_i @ mu_H\n",
    "#             term1 = torch.norm(L_i_mu_L.float() - H_i_mu_H.float())**2\n",
    "            \n",
    "#             V_Sigma_V = V_i.float() @ Sigma_L.float() @ V_i.T.float()\n",
    "#             H_Sigma_H = H_i.float() @ Sigma_H.float() @ H_i.T.float()\n",
    "\n",
    "#             term2 = torch.trace(V_Sigma_V)\n",
    "#             term3 = torch.trace(H_Sigma_H)\n",
    "            \n",
    "#             sqrtVSV = oput.sqrtm_svd(V_Sigma_V)\n",
    "#             sqrtHSH = oput.sqrtm_svd(H_Sigma_H)\n",
    "\n",
    "#             #term4 = -2*torch.trace(oput.sqrtm_svd(sqrtHSH @ V_Sigma_V @ sqrtHSH))\n",
    "#             term4 = -2*torch.norm(oput.sqrtm_svd(sqrtVSV) @ oput.sqrtm_svd(sqrtHSH), 'nuc')\n",
    "            \n",
    "#             obj = obj + (term1 + term2 + term3 + term4)\n",
    "        \n",
    "#         obj = obj/i\n",
    "        \n",
    "#         print(f\"Max step {t+1}/{num_steps_max}, Objective: {obj.item()}\")\n",
    "\n",
    "#     return mu_L, Sigma_L, mu_H, Sigma_H\n",
    "\n",
    "# def optimize_min(T, mu_L, Sigma_L, mu_H, Sigma_H, LLmodels, HLmodels, num_steps_min, optimizer_T):\n",
    "\n",
    "#     objective_T = 0  # Initialize the objective for this step\n",
    "\n",
    "#     for step in range(num_steps_min):\n",
    "#         objective_T = 0  # Reset objective at the start of each step\n",
    "#         for n, iota in enumerate(Ill):\n",
    "#             L_i = torch.from_numpy(LLmodels[iota].compute_mechanism()).float()\n",
    "#             H_i = torch.from_numpy(HLmodels[omega[iota]].compute_mechanism()).float()\n",
    "\n",
    "#             L_i_mu_L = L_i @ mu_L  \n",
    "#             H_i_mu_H = H_i @ mu_H \n",
    "\n",
    "#             term1 = torch.norm(T @ L_i_mu_L - H_i_mu_H) ** 2\n",
    "#             term2 = torch.trace(T @ L_i @ Sigma_L @ L_i.T @ T.T)\n",
    "#             term3 = torch.trace(H_i @ Sigma_H @ H_i.T)\n",
    "            \n",
    "#             L_i_Sigma_L = T @ L_i @ Sigma_L @ L_i.T @ T.T\n",
    "#             H_i_Sigma_H = H_i @ Sigma_H @ H_i.T\n",
    "\n",
    "#             # Using the SVD square root term\n",
    "#             term4 = -2 * torch.norm(oput.sqrtm_svd(L_i_Sigma_L) @ oput.sqrtm_svd(H_i_Sigma_H), 'nuc')\n",
    "\n",
    "#             objective_T += term1 + term2 + term3 + term4\n",
    "\n",
    "#         objective_T = objective_T/n\n",
    "\n",
    "#         optimizer_T.zero_grad() # Clear previous gradients\n",
    "#         objective_T.backward(retain_graph=True)  # Backpropagate to compute gradients\n",
    "#         optimizer_T.step()      # Update T using the optimizer\n",
    "\n",
    "#         print(f\"Min step {step+1}/{num_steps_min}, Objective: {objective_T.item()}\")\n",
    "\n",
    "#     return objective_T, T  # Return both the objective and T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddacff25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_struc_matrices(models, I):\n",
    "    matrices = []\n",
    "    for iota in I:\n",
    "        M_i = torch.from_numpy(models[iota].compute_mechanism()).float()  \n",
    "        matrices.append(M_i)\n",
    "\n",
    "    return matrices\n",
    "\n",
    "def compute_mu_bary(struc_matrices, mu):\n",
    "    struc_matrices_tensor = torch.stack(struc_matrices)\n",
    "    mu_barycenter         = torch.sum(struc_matrices_tensor @ mu, dim=0) / len(struc_matrices)\n",
    "\n",
    "    return mu_barycenter\n",
    "\n",
    "def compute_Sigma_bary(matrices, Sigma, initialization, max_iter, tol):\n",
    "\n",
    "    Sigma_matrices = []\n",
    "    for M in matrices:\n",
    "        Sigma_matrices.append(M @ Sigma @ M.T)\n",
    "\n",
    "    return covariance_bary_optim(Sigma_matrices, initialization, max_iter, tol)\n",
    "\n",
    "def covariance_bary_optim(Sigma_list, initialization, max_iter, tol):\n",
    "    \n",
    "    if initialization == 'psd':\n",
    "        S_0 = create_psd_matrix(Sigma_list[0].shape[0])\n",
    "    elif initialization == 'avg':\n",
    "        S_0 = sum(Sigma_list) / len(Sigma_list)\n",
    "    \n",
    "    S_n = S_0.clone()\n",
    "    n   = len(Sigma_list)  # Number of matrices\n",
    "    lambda_j = 1.0 / n   # Equal weights\n",
    "    \n",
    "    for n in range(max_iter):\n",
    "        S_n_old = S_n.clone()\n",
    "\n",
    "        S_n_inv_half = oput.sqrtm_svd(regmat(torch.inverse(S_n)))\n",
    "        \n",
    "        # Compute the sum of S_n^(1/2) Σ_j S_n^(1/2)\n",
    "        sum_term = torch.zeros_like(S_n)\n",
    "        for Sigma_j in Sigma_list:\n",
    "            S_n_half   = oput.sqrtm_svd(regmat(S_n))\n",
    "            inner_term = torch.matmul(torch.matmul(S_n_half, Sigma_j), S_n_half)\n",
    "            sqrt_term  = oput.sqrtm_svd(regmat(inner_term))\n",
    "            sum_term  += lambda_j * sqrt_term\n",
    "        # Square the sum term\n",
    "        squared_sum = torch.matmul(sum_term, sum_term.T)\n",
    "\n",
    "        S_n_next = torch.matmul(torch.matmul(S_n_inv_half, squared_sum), S_n_inv_half)\n",
    "        S_n = S_n_next\n",
    "\n",
    "        if torch.norm(S_n - S_n_old, p='fro') < tol:\n",
    "            print(f\"Converged after {n+1} iterations\")\n",
    "            break\n",
    "            \n",
    "    return S_n\n",
    "\n",
    "def monge(m1, S1, m2, S2):\n",
    "    inner      = torch.matmul(oput.sqrtm_svd(S1), torch.matmul(S2, oput.sqrtm_svd(S1)))\n",
    "    sqrt_inner = oput.sqrtm_svd(inner)\n",
    "    A          = torch.matmul(torch.inverse(oput.sqrtm_svd(regmat(S1))), torch.matmul(sqrt_inner, torch.inverse(oput.sqrtm_svd(regmat(S1)))))  \n",
    "\n",
    "    # Define the Monge map as a function τ(x) = m_2 + A(x - m_1)\n",
    "    def tau(x):\n",
    "        return m2 + A @ (x - m1)\n",
    "\n",
    "    return tau, A\n",
    "\n",
    "def regmat(matrix, eps=1e-10):\n",
    "    # Replace NaN and Inf values with finite numbers\n",
    "    matrix = torch.nan_to_num(matrix, nan=0.0, posinf=1e10, neginf=-1e10)\n",
    "    \n",
    "    # Add a small epsilon to the diagonal for numerical stability\n",
    "    if matrix.dim() == 2 and matrix.size(0) == matrix.size(1):\n",
    "        matrix = matrix + eps * torch.eye(matrix.size(0), device=matrix.device)\n",
    "    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d7850a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_psd_matrix(size):\n",
    "    A = torch.randn(size, size).float()\n",
    "\n",
    "    return torch.matmul(A, A.T)\n",
    "\n",
    "# PCA Projection from higher to lower dimension\n",
    "def pca_projection(Sigma, target_dim):\n",
    "    \"\"\"\n",
    "    Project a d×d matrix to a k×k matrix where k < d\n",
    "    Args:\n",
    "        Sigma: source matrix (d×d)\n",
    "        target_dim: target dimension k\n",
    "    Returns:\n",
    "        k×k projected matrix\n",
    "    \"\"\"\n",
    "    # Perform eigenvalue decomposition\n",
    "    eigenvalues, eigenvectors = torch.linalg.eigh(Sigma)\n",
    "    \n",
    "    # Sort eigenvalues and eigenvectors in descending order\n",
    "    sorted_indices = torch.argsort(eigenvalues, descending=True)\n",
    "    eigenvalues = eigenvalues[sorted_indices]\n",
    "    eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Take only the top target_dim eigenvectors\n",
    "    V = eigenvectors[:, :target_dim]  # d×k matrix\n",
    "    \n",
    "    # Project the covariance matrix\n",
    "    Sigma_projected = torch.matmul(torch.matmul(V.T, Sigma), V)  # k×k matrix\n",
    "    \n",
    "    return Sigma_projected, V\n",
    "\n",
    "# SVD Projection from higher to lower dimension\n",
    "def svd_projection(Sigma, target_dim):\n",
    "    \"\"\"\n",
    "    Project a d×d matrix to a k×k matrix where k < d using SVD\n",
    "    Args:\n",
    "        Sigma: source matrix (d×d)\n",
    "        target_dim: target dimension k\n",
    "    Returns:\n",
    "        k×k projected matrix\n",
    "    \"\"\"\n",
    "    # Perform SVD\n",
    "    U, S, V = torch.svd(Sigma)\n",
    "    \n",
    "    # Take only the first target_dim components\n",
    "    U_k = U[:, :target_dim]  # d×k matrix\n",
    "    S_k = S[:target_dim]     # k singular values\n",
    "    \n",
    "    # Project the covariance matrix\n",
    "    Sigma_projected = torch.matmul(torch.matmul(U_k.T, Sigma), U_k)  # k×k matrix\n",
    "    \n",
    "    return Sigma_projected, U_k\n",
    "\n",
    "def project_covariance(Sigma, n, method):\n",
    "    if method == 'pca':\n",
    "        return pca_projection(Sigma, n)\n",
    "    elif method == 'svd':\n",
    "        return svd_projection(Sigma, n)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown projection method: {method}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "739e4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def barycentric_optimization(mu_L, mu_H, Sigma_L, Sigma_H, LLmodels, HLmodels, Ill, Ihl, projection_method, initialization, max_iter, tol):\n",
    "\n",
    "    h, l = mu_H.shape[0], mu_L.shape[0]\n",
    "\n",
    "    # Initialize the structural matrices    \n",
    "    L_matrices = compute_struc_matrices(LLmodels, Ill)\n",
    "    H_matrices = compute_struc_matrices(HLmodels, Ihl)\n",
    "\n",
    "    # Initilize the barycenteric means and covariances\n",
    "    print(\"Computing barycentric mu_L\")\n",
    "    mu_bary_L = compute_mu_bary(L_matrices, mu_L)\n",
    "    print(\"mu_bary_L:\", mu_bary_L)  \n",
    "    print(\"\\nComputing barycentric mu_H\")\n",
    "    mu_bary_H = compute_mu_bary(H_matrices, mu_H)\n",
    "    print(\"mu_bary_H:\", mu_bary_H)  \n",
    "\n",
    "    print(\"\\nComputing barycentric Sigma_L\")\n",
    "    Sigma_bary_L = compute_Sigma_bary(L_matrices, Sigma_L, initialization, max_iter, tol)\n",
    "    print(Sigma_bary_L)\n",
    "    print(\"\\nComputing barycentric Sigma_H\")\n",
    "    Sigma_bary_H = compute_Sigma_bary(H_matrices, Sigma_H, initialization, max_iter, tol)\n",
    "    print(Sigma_bary_H)\n",
    "    \n",
    "    proj_Sigma_bary_L, Tp = project_covariance(Sigma_bary_L, h, projection_method)\n",
    "    proj_mu_bary_L        = torch.matmul(Tp.T, mu_bary_L)\n",
    "\n",
    "    tau, A = monge(proj_mu_bary_L, proj_Sigma_bary_L, mu_bary_H, Sigma_bary_H)\n",
    "\n",
    "    T = torch.matmul(A, Tp.T)\n",
    "\n",
    "    return tau, T, Tp, mu_bary_L, Sigma_bary_L, mu_bary_H, Sigma_bary_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e21785be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing barycentric mu_L\n",
      "mu_bary_L: tensor([0., 0., 0.])\n",
      "\n",
      "Computing barycentric mu_H\n",
      "mu_bary_H: tensor([0., 0.])\n",
      "\n",
      "Computing barycentric Sigma_L\n",
      "tensor([[-0.1602, -0.1863, -1.3203],\n",
      "        [-1.2593, -1.3067, -1.3496],\n",
      "        [-1.1682,  0.0345, -0.3648]])\n",
      "\n",
      "Computing barycentric Sigma_H\n",
      "Converged after 1 iterations\n",
      "tensor([[1.3602, 0.6002],\n",
      "        [0.6002, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "tau, T, Tp, mu_bary_L, Sigma_bary_L, mu_bary_H, Sigma_bary_H = barycentric_optimization(mu_L, mu_H, Sigma_L, Sigma_H,\n",
    "                                                                                        LLmodels, HLmodels, Ill, Ihl,\n",
    "                                                                                        'svd', 'avg', 100, 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "596e70c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.3200, -0.6395])\n",
      "tensor([ 0.4221, -0.6327])\n",
      "tensor([-1.5095, -0.3283])\n",
      "tensor([1.8620, 0.5970])\n",
      "tensor([-0.2151, -0.3287])\n",
      "tensor([ 0.3774, -0.0894])\n",
      "tensor([1.6335, 0.2247])\n",
      "tensor([0.4873, 0.4357])\n",
      "tensor([-0.0981, -1.5215])\n",
      "tensor([-1.0676, -0.5375])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(10, l)\n",
    "for x_i in x:\n",
    "    print(T@x_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bbd34121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6622, -0.9276])\n",
      "tensor([-0.6622, -0.9276])\n"
     ]
    }
   ],
   "source": [
    "y = Tp.T@x[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bac833c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Barycentric Optimization at 2024-12-02 16:20:10.238005\n",
      "Maximum iterations: 100\n",
      "Parameters:\n",
      "- Projection method: svd\n",
      "- Initialization: psd\n",
      "- Tolerance: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Barycentric Optimization:  20%|██        | 20/100 [00:00<00:00, 694.66it/s, stage=Computing barycentric covariances]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing barycentric mu_L\n",
      "mu_bary_L: tensor([0., 0., 0.])\n",
      "\n",
      "Computing barycentric mu_H\n",
      "mu_bary_H: tensor([0., 0.])\n",
      "\n",
      "Computing barycentric Sigma_L\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Barycentric Optimization: 100%|██████████| 100/100 [00:01<00:00, 78.40it/s, stage=Finalizing, tau=N/A]              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8460, -0.0126, -1.2985],\n",
      "        [-1.9967, -1.2195, -1.6254],\n",
      "        [-1.0787, -0.1480,  0.2046]])\n",
      "\n",
      "Computing barycentric Sigma_H\n",
      "Converged after 2 iterations\n",
      "tensor([[1.3602, 0.6002],\n",
      "        [0.6002, 1.0000]])\n",
      "\n",
      "Optimization Complete!\n",
      "Started at: 2024-12-02 16:20:10.238005\n",
      "Finished at: 2024-12-02 16:20:11.525951\n",
      "Total execution time: 0:00:01\n",
      "\n",
      "Final Results:\n",
      "tau: <function monge.<locals>.tau at 0x19a759580>\n",
      "T shape: torch.Size([2, 3])\n",
      "Tp shape: torch.Size([3, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# from datetime import datetime, timedelta\n",
    "# import torch\n",
    "\n",
    "# def barycentric_optimization(mu_L, mu_H, Sigma_L, Sigma_H, \n",
    "#                            LLmodels, HLmodels, Ill, Ihl, \n",
    "#                            projection_method, initialization, \n",
    "#                            max_iter, tol, pbar=None):\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     h, l = mu_H.shape[0], mu_L.shape[0]\n",
    "\n",
    "#     # Initialize progress tracking\n",
    "#     if pbar:\n",
    "#         pbar.set_postfix({'stage': 'Initializing'})\n",
    "#         pbar.update(0)\n",
    "\n",
    "#     # Initialize the structural matrices    \n",
    "#     L_matrices = compute_struc_matrices(LLmodels, Ill)\n",
    "#     H_matrices = compute_struc_matrices(HLmodels, Ihl)\n",
    "\n",
    "#     if pbar:\n",
    "#         pbar.set_postfix({'stage': 'Computing barycentric means'})\n",
    "#         pbar.update(10)  # Update progress by 10%\n",
    "\n",
    "#     # Initialize the barycentric means and covariances\n",
    "#     print(\"Computing barycentric mu_L\")\n",
    "#     mu_bary_L = compute_mu_bary(L_matrices, mu_L)\n",
    "#     print(\"mu_bary_L:\", mu_bary_L)  \n",
    "\n",
    "#     if pbar:\n",
    "#         pbar.update(10)\n",
    "\n",
    "#     print(\"\\nComputing barycentric mu_H\")\n",
    "#     mu_bary_H = compute_mu_bary(H_matrices, mu_H)\n",
    "#     print(\"mu_bary_H:\", mu_bary_H)  \n",
    "\n",
    "#     if pbar:\n",
    "#         pbar.set_postfix({'stage': 'Computing barycentric covariances'})\n",
    "#         pbar.update(20)\n",
    "\n",
    "#     print(\"\\nComputing barycentric Sigma_L\")\n",
    "#     Sigma_bary_L = compute_Sigma_bary(L_matrices, Sigma_L, initialization, max_iter, tol)\n",
    "#     print(Sigma_bary_L)\n",
    "\n",
    "#     if pbar:\n",
    "#         pbar.update(20)\n",
    "\n",
    "#     print(\"\\nComputing barycentric Sigma_H\")\n",
    "#     Sigma_bary_H = compute_Sigma_bary(H_matrices, Sigma_H, initialization, max_iter, tol)\n",
    "#     print(Sigma_bary_H)\n",
    "    \n",
    "#     if pbar:\n",
    "#         pbar.set_postfix({'stage': 'Projecting covariance'})\n",
    "#         pbar.update(20)\n",
    "\n",
    "#     proj_Sigma_bary_L, Tp = project_covariance(Sigma_bary_L, h, projection_method)\n",
    "#     proj_mu_bary_L = torch.matmul(Tp.T, mu_bary_L)\n",
    "\n",
    "#     if pbar:\n",
    "#         pbar.set_postfix({'stage': 'Computing Monge map'})\n",
    "#         pbar.update(10)\n",
    "\n",
    "#     tau, A = monge(proj_mu_bary_L, proj_Sigma_bary_L, mu_bary_H, Sigma_bary_H)\n",
    "\n",
    "#     if pbar:\n",
    "#         pbar.set_postfix({\n",
    "#             'stage': 'Finalizing',\n",
    "#             'tau': f'{tau:.4f}' if isinstance(tau, (int, float)) else 'N/A'\n",
    "#         })\n",
    "#         pbar.update(10)\n",
    "\n",
    "#     T = torch.matmul(A, Tp.T)\n",
    "\n",
    "#     return tau, T, Tp, mu_bary_L, Sigma_bary_L, mu_bary_H, Sigma_bary_H\n",
    "\n",
    "# # Main execution wrapper\n",
    "# def run_barycentric_optimization(mu_L, mu_H, Sigma_L, Sigma_H,\n",
    "#                                LLmodels, HLmodels, Ill, Ihl,\n",
    "#                                projection_method='svd', \n",
    "#                                initialization='avg', \n",
    "#                                max_iter=100, \n",
    "#                                tol=1e-5):\n",
    "    \n",
    "#     start_time = time.time()\n",
    "#     start_datetime = datetime.now()\n",
    "\n",
    "#     print(f\"\\nStarting Barycentric Optimization at {start_datetime}\")\n",
    "#     print(f\"Maximum iterations: {max_iter}\")\n",
    "#     print(\"Parameters:\")\n",
    "#     print(f\"- Projection method: {projection_method}\")\n",
    "#     print(f\"- Initialization: {initialization}\")\n",
    "#     print(f\"- Tolerance: {tol}\")\n",
    "\n",
    "#     # Create progress bar (100 total steps for all stages)\n",
    "#     with tqdm(total=100, desc=\"Barycentric Optimization\") as pbar:\n",
    "#         try:\n",
    "#             # Run optimization with progress tracking\n",
    "#             tau, T, Tp, mu_bary_L, Sigma_bary_L, mu_bary_H, Sigma_bary_H = barycentric_optimization(\n",
    "#                 mu_L=mu_L, \n",
    "#                 mu_H=mu_H, \n",
    "#                 Sigma_L=Sigma_L, \n",
    "#                 Sigma_H=Sigma_H,\n",
    "#                 LLmodels=LLmodels, \n",
    "#                 HLmodels=HLmodels, \n",
    "#                 Ill=Ill, \n",
    "#                 Ihl=Ihl,\n",
    "#                 projection_method=projection_method, \n",
    "#                 initialization=initialization, \n",
    "#                 max_iter=max_iter, \n",
    "#                 tol=tol,\n",
    "#                 pbar=pbar\n",
    "#             )\n",
    "            \n",
    "#             # Calculate execution time\n",
    "#             end_time = time.time()\n",
    "#             execution_time = end_time - start_time\n",
    "            \n",
    "#             # Print timing information\n",
    "#             print(\"\\nOptimization Complete!\")\n",
    "#             print(f\"Started at: {start_datetime}\")\n",
    "#             print(f\"Finished at: {datetime.now()}\")\n",
    "#             print(f\"Total execution time: {timedelta(seconds=int(execution_time))}\")\n",
    "            \n",
    "#             # Print final results\n",
    "#             print(\"\\nFinal Results:\")\n",
    "#             print(f\"tau: {tau}\")\n",
    "#             print(f\"T shape: {T.shape}\")\n",
    "#             print(f\"Tp shape: {Tp.shape}\")\n",
    "            \n",
    "#             return tau, T, Tp, mu_bary_L, Sigma_bary_L, mu_bary_H, Sigma_bary_H\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(f\"\\nError during optimization: {e}\")\n",
    "#             end_time = time.time()\n",
    "#             print(f\"Time until error: {timedelta(seconds=int(end_time - start_time))}\")\n",
    "#             raise\n",
    "\n",
    "# # Usage\n",
    "# tau, T, Tp, mu_bary_L, Sigma_bary_L, mu_bary_H, Sigma_bary_H = run_barycentric_optimization(\n",
    "#     mu_L, mu_H, Sigma_L, Sigma_H,\n",
    "#     LLmodels, HLmodels, Ill, Ihl,\n",
    "#     projection_method='svd',\n",
    "#     initialization='psd',\n",
    "#     max_iter=100,\n",
    "#     tol=1e-5\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba18bb2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d187d073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ea3fa7c",
   "metadata": {},
   "source": [
    "Barycentric gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc473f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_min(mu_L, Sigma_L, mu_H, Sigma_H, num_steps, seed, tol=1e-2):\n",
    "\n",
    "    # Set seeds for reproducibility\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    T = torch.randn(mu_H.shape[0], mu_L.shape[0], requires_grad=True)\n",
    "\n",
    "    optimizer_T        = torch.optim.Adam([T], lr=0.01)\n",
    "    previous_objective = float('inf')\n",
    "    objective_T        = 0  # Reset objective at the start of each step\n",
    "    # Optimization loop\n",
    "    for step in range(num_steps):\n",
    "        objective_T = 0  # Reset objective at the start of each step\n",
    "\n",
    "        # Calculate each term of the Wasserstein distance\n",
    "        term1 = torch.norm(T @ mu_L - mu_H) ** 2  # Squared Euclidean distance between transformed means\n",
    "        term2 = torch.trace(T @ Sigma_L @ T.T)   # Trace term for low-level covariance\n",
    "        term3 = torch.trace(Sigma_H)             # Trace term for high-level covariance\n",
    "        \n",
    "        # Compute the intermediate covariance matrices\n",
    "        T_Sigma_L_T      = torch.matmul(T, torch.matmul(Sigma_L, T.T))\n",
    "        T_Sigma_L_T_sqrt = oput.sqrtm_svd(T_Sigma_L_T)\n",
    "        Sigma_H_sqrt     = oput.sqrtm_svd(Sigma_H)\n",
    "        \n",
    "        # Coupling term using nuclear norm\n",
    "        term4 = -2 * torch.norm(T_Sigma_L_T_sqrt @ Sigma_H_sqrt, p='nuc')\n",
    "\n",
    "        # Total objective is the sum of terms\n",
    "        objective_T += term1 + term2 + term3 + term4\n",
    "\n",
    "        if abs(previous_objective - objective_T.item()) < tol:\n",
    "            print(f\"Converged at step {step + 1}/{num_steps_min} with objective: {objective_T.item()}\")\n",
    "            break\n",
    "\n",
    "        # Update previous objective\n",
    "        previous_objective = objective_T.item()\n",
    "\n",
    "        # Perform optimization step\n",
    "        optimizer_T.zero_grad()  # Clear gradients\n",
    "        objective_T.backward(retain_graph=True)  # Backpropagate\n",
    "        optimizer_T.step()  # Update T\n",
    "\n",
    "        print(f\"Min step {step+1}/{num_steps}, Objective: {objective_T.item()}\")\n",
    "\n",
    "    return objective_T.item(), T  # Return final objective and optimized T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "92811913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min step 1/1000, Objective: -0.6442282199859619\n",
      "Min step 2/1000, Objective: -0.7537491321563721\n",
      "Min step 3/1000, Objective: -0.8608345985412598\n",
      "Min step 4/1000, Objective: -0.965545654296875\n",
      "Min step 5/1000, Objective: -1.0683064460754395\n",
      "Min step 6/1000, Objective: -1.1698195934295654\n",
      "Min step 7/1000, Objective: -1.2707304954528809\n",
      "Min step 8/1000, Objective: -1.3716082572937012\n",
      "Min step 9/1000, Objective: -1.4730181694030762\n",
      "Min step 10/1000, Objective: -1.5754728317260742\n",
      "Min step 11/1000, Objective: -1.679353952407837\n",
      "Min step 12/1000, Objective: -1.7849090099334717\n",
      "Min step 13/1000, Objective: -1.8922863006591797\n",
      "Min step 14/1000, Objective: -2.0015642642974854\n",
      "Min step 15/1000, Objective: -2.1127963066101074\n",
      "Min step 16/1000, Objective: -2.226024627685547\n",
      "Min step 17/1000, Objective: -2.3412821292877197\n",
      "Min step 18/1000, Objective: -2.4586050510406494\n",
      "Min step 19/1000, Objective: -2.5780253410339355\n",
      "Min step 20/1000, Objective: -2.6995835304260254\n",
      "Min step 21/1000, Objective: -2.8233189582824707\n",
      "Min step 22/1000, Objective: -2.949277639389038\n",
      "Min step 23/1000, Objective: -3.0775012969970703\n",
      "Min step 24/1000, Objective: -3.208038330078125\n",
      "Min step 25/1000, Objective: -3.3409368991851807\n",
      "Min step 26/1000, Objective: -3.4762513637542725\n",
      "Min step 27/1000, Objective: -3.6140341758728027\n",
      "Min step 28/1000, Objective: -3.7543368339538574\n",
      "Min step 29/1000, Objective: -3.897218942642212\n",
      "Min step 30/1000, Objective: -4.042734146118164\n",
      "Min step 31/1000, Objective: -4.190943717956543\n",
      "Min step 32/1000, Objective: -4.341904640197754\n",
      "Min step 33/1000, Objective: -4.495677947998047\n",
      "Min step 34/1000, Objective: -4.652320861816406\n",
      "Min step 35/1000, Objective: -4.811896800994873\n",
      "Min step 36/1000, Objective: -4.974465370178223\n",
      "Min step 37/1000, Objective: -5.140085220336914\n",
      "Min step 38/1000, Objective: -5.308819770812988\n",
      "Min step 39/1000, Objective: -5.480729579925537\n",
      "Min step 40/1000, Objective: -5.655872821807861\n",
      "Min step 41/1000, Objective: -5.8343071937561035\n",
      "Min step 42/1000, Objective: -6.0160932540893555\n",
      "Min step 43/1000, Objective: -6.2012939453125\n",
      "Min step 44/1000, Objective: -6.389957904815674\n",
      "Min step 45/1000, Objective: -6.582150459289551\n",
      "Min step 46/1000, Objective: -6.777922630310059\n",
      "Min step 47/1000, Objective: -6.977329254150391\n",
      "Min step 48/1000, Objective: -7.180425643920898\n",
      "Min step 49/1000, Objective: -7.387265205383301\n",
      "Min step 50/1000, Objective: -7.597902774810791\n",
      "Min step 51/1000, Objective: -7.812385559082031\n",
      "Min step 52/1000, Objective: -8.030760765075684\n",
      "Min step 53/1000, Objective: -8.25308609008789\n",
      "Min step 54/1000, Objective: -8.479402542114258\n",
      "Min step 55/1000, Objective: -8.709759712219238\n",
      "Min step 56/1000, Objective: -8.944202423095703\n",
      "Min step 57/1000, Objective: -9.182771682739258\n",
      "Min step 58/1000, Objective: -9.425515174865723\n",
      "Min step 59/1000, Objective: -9.67247200012207\n",
      "Min step 60/1000, Objective: -9.923683166503906\n",
      "Min step 61/1000, Objective: -10.179187774658203\n",
      "Min step 62/1000, Objective: -10.439023971557617\n",
      "Min step 63/1000, Objective: -10.703226089477539\n",
      "Min step 64/1000, Objective: -10.97183609008789\n",
      "Min step 65/1000, Objective: -11.244884490966797\n",
      "Min step 66/1000, Objective: -11.522406578063965\n",
      "Min step 67/1000, Objective: -11.804433822631836\n",
      "Min step 68/1000, Objective: -12.090997695922852\n",
      "Min step 69/1000, Objective: -12.38212776184082\n",
      "Min step 70/1000, Objective: -12.677852630615234\n",
      "Min step 71/1000, Objective: -12.978202819824219\n",
      "Min step 72/1000, Objective: -13.283205032348633\n",
      "Min step 73/1000, Objective: -13.592889785766602\n",
      "Min step 74/1000, Objective: -13.907272338867188\n",
      "Min step 75/1000, Objective: -14.22638988494873\n",
      "Min step 76/1000, Objective: -14.550254821777344\n",
      "Min step 77/1000, Objective: -14.878897666931152\n",
      "Min step 78/1000, Objective: -15.212334632873535\n",
      "Min step 79/1000, Objective: -15.550594329833984\n",
      "Min step 80/1000, Objective: -15.893692016601562\n",
      "Min step 81/1000, Objective: -16.24164581298828\n",
      "Min step 82/1000, Objective: -16.594486236572266\n",
      "Min step 83/1000, Objective: -16.952213287353516\n",
      "Min step 84/1000, Objective: -17.314857482910156\n",
      "Min step 85/1000, Objective: -17.68243408203125\n",
      "Min step 86/1000, Objective: -18.054962158203125\n",
      "Min step 87/1000, Objective: -18.432445526123047\n",
      "Min step 88/1000, Objective: -18.814910888671875\n",
      "Min step 89/1000, Objective: -19.20236587524414\n",
      "Min step 90/1000, Objective: -19.594829559326172\n",
      "Min step 91/1000, Objective: -19.992313385009766\n",
      "Min step 92/1000, Objective: -20.39482879638672\n",
      "Min step 93/1000, Objective: -20.80239486694336\n",
      "Min step 94/1000, Objective: -21.21501350402832\n",
      "Min step 95/1000, Objective: -21.63270378112793\n",
      "Min step 96/1000, Objective: -22.055471420288086\n",
      "Min step 97/1000, Objective: -22.48333168029785\n",
      "Min step 98/1000, Objective: -22.916288375854492\n",
      "Min step 99/1000, Objective: -23.35436248779297\n",
      "Min step 100/1000, Objective: -23.797550201416016\n",
      "Min step 101/1000, Objective: -24.245872497558594\n",
      "Min step 102/1000, Objective: -24.699323654174805\n",
      "Min step 103/1000, Objective: -25.15792465209961\n",
      "Min step 104/1000, Objective: -25.621673583984375\n",
      "Min step 105/1000, Objective: -26.090587615966797\n",
      "Min step 106/1000, Objective: -26.564672470092773\n",
      "Min step 107/1000, Objective: -27.043928146362305\n",
      "Min step 108/1000, Objective: -27.52836036682129\n",
      "Min step 109/1000, Objective: -28.017986297607422\n",
      "Min step 110/1000, Objective: -28.512798309326172\n",
      "Min step 111/1000, Objective: -29.012813568115234\n",
      "Min step 112/1000, Objective: -29.518024444580078\n",
      "Min step 113/1000, Objective: -30.02845573425293\n",
      "Min step 114/1000, Objective: -30.544092178344727\n",
      "Min step 115/1000, Objective: -31.064952850341797\n",
      "Min step 116/1000, Objective: -31.591032028198242\n",
      "Min step 117/1000, Objective: -32.122344970703125\n",
      "Min step 118/1000, Objective: -32.65888214111328\n",
      "Min step 119/1000, Objective: -33.20066452026367\n",
      "Min step 120/1000, Objective: -33.74767303466797\n",
      "Min step 121/1000, Objective: -34.29994201660156\n",
      "Min step 122/1000, Objective: -34.85743713378906\n",
      "Min step 123/1000, Objective: -35.420188903808594\n",
      "Min step 124/1000, Objective: -35.988189697265625\n",
      "Min step 125/1000, Objective: -36.56145095825195\n",
      "Min step 126/1000, Objective: -37.13995361328125\n",
      "Min step 127/1000, Objective: -37.72373580932617\n",
      "Min step 128/1000, Objective: -38.312767028808594\n",
      "Min step 129/1000, Objective: -38.90707015991211\n",
      "Min step 130/1000, Objective: -39.50663375854492\n",
      "Min step 131/1000, Objective: -40.11146545410156\n",
      "Min step 132/1000, Objective: -40.72156524658203\n",
      "Min step 133/1000, Objective: -41.33692932128906\n",
      "Min step 134/1000, Objective: -41.95758819580078\n",
      "Min step 135/1000, Objective: -42.583499908447266\n",
      "Min step 136/1000, Objective: -43.21469497680664\n",
      "Min step 137/1000, Objective: -43.85116958618164\n",
      "Min step 138/1000, Objective: -44.49291229248047\n",
      "Min step 139/1000, Objective: -45.13993835449219\n",
      "Min step 140/1000, Objective: -45.792240142822266\n",
      "Min step 141/1000, Objective: -46.4498405456543\n",
      "Min step 142/1000, Objective: -47.112693786621094\n",
      "Min step 143/1000, Objective: -47.780860900878906\n",
      "Min step 144/1000, Objective: -48.454288482666016\n",
      "Min step 145/1000, Objective: -49.13301086425781\n",
      "Min step 146/1000, Objective: -49.817012786865234\n",
      "Min step 147/1000, Objective: -50.50629425048828\n",
      "Min step 148/1000, Objective: -51.20086669921875\n",
      "Min step 149/1000, Objective: -51.90071487426758\n",
      "Min step 150/1000, Objective: -52.605857849121094\n",
      "Min step 151/1000, Objective: -53.3162841796875\n",
      "Min step 152/1000, Objective: -54.03199768066406\n",
      "Min step 153/1000, Objective: -54.75299835205078\n",
      "Min step 154/1000, Objective: -55.47926712036133\n",
      "Min step 155/1000, Objective: -56.210853576660156\n",
      "Min step 156/1000, Objective: -56.94769287109375\n",
      "Min step 157/1000, Objective: -57.689842224121094\n",
      "Min step 158/1000, Objective: -58.437255859375\n",
      "Min step 159/1000, Objective: -59.189979553222656\n",
      "Min step 160/1000, Objective: -59.94795608520508\n",
      "Min step 161/1000, Objective: -60.71124267578125\n",
      "Min step 162/1000, Objective: -61.479820251464844\n",
      "Min step 163/1000, Objective: -62.25366973876953\n",
      "Min step 164/1000, Objective: -63.03282165527344\n",
      "Min step 165/1000, Objective: -63.81724548339844\n",
      "Min step 166/1000, Objective: -64.60694122314453\n",
      "Min step 167/1000, Objective: -65.40193939208984\n",
      "Min step 168/1000, Objective: -66.20220184326172\n",
      "Min step 169/1000, Objective: -67.00775146484375\n",
      "Min step 170/1000, Objective: -67.818603515625\n",
      "Min step 171/1000, Objective: -68.63471221923828\n",
      "Min step 172/1000, Objective: -69.45610809326172\n",
      "Min step 173/1000, Objective: -70.28279876708984\n",
      "Min step 174/1000, Objective: -71.1147689819336\n",
      "Min step 175/1000, Objective: -71.9520263671875\n",
      "Min step 176/1000, Objective: -72.79452514648438\n",
      "Min step 177/1000, Objective: -73.6423568725586\n",
      "Min step 178/1000, Objective: -74.49542999267578\n",
      "Min step 179/1000, Objective: -75.35379791259766\n",
      "Min step 180/1000, Objective: -76.21744537353516\n",
      "Min step 181/1000, Objective: -77.08634948730469\n",
      "Min step 182/1000, Objective: -77.9605484008789\n",
      "Min step 183/1000, Objective: -78.83999633789062\n",
      "Min step 184/1000, Objective: -79.72476959228516\n",
      "Min step 185/1000, Objective: -80.6147689819336\n",
      "Min step 186/1000, Objective: -81.51007080078125\n",
      "Min step 187/1000, Objective: -82.41064453125\n",
      "Min step 188/1000, Objective: -83.31647491455078\n",
      "Min step 189/1000, Objective: -84.22756958007812\n",
      "Min step 190/1000, Objective: -85.14395141601562\n",
      "Min step 191/1000, Objective: -86.06561279296875\n",
      "Min step 192/1000, Objective: -86.9925308227539\n",
      "Min step 193/1000, Objective: -87.92473602294922\n",
      "Min step 194/1000, Objective: -88.86222076416016\n",
      "Min step 195/1000, Objective: -89.80491638183594\n",
      "Min step 196/1000, Objective: -90.7529067993164\n",
      "Min step 197/1000, Objective: -91.70616149902344\n",
      "Min step 198/1000, Objective: -92.66471099853516\n",
      "Min step 199/1000, Objective: -93.62847137451172\n",
      "Min step 200/1000, Objective: -94.59756469726562\n",
      "Min step 201/1000, Objective: -95.57186126708984\n",
      "Min step 202/1000, Objective: -96.55146789550781\n",
      "Min step 203/1000, Objective: -97.5362777709961\n",
      "Min step 204/1000, Objective: -98.52639770507812\n",
      "Min step 205/1000, Objective: -99.52178192138672\n",
      "Min step 206/1000, Objective: -100.52239990234375\n",
      "Min step 207/1000, Objective: -101.52825927734375\n",
      "Min step 208/1000, Objective: -102.53938293457031\n",
      "Min step 209/1000, Objective: -103.55580139160156\n",
      "Min step 210/1000, Objective: -104.5774917602539\n",
      "Min step 211/1000, Objective: -105.6043701171875\n",
      "Min step 212/1000, Objective: -106.63653564453125\n",
      "Min step 213/1000, Objective: -107.67395782470703\n",
      "Min step 214/1000, Objective: -108.71662139892578\n",
      "Min step 215/1000, Objective: -109.76454162597656\n",
      "Min step 216/1000, Objective: -110.81771087646484\n",
      "Min step 217/1000, Objective: -111.87615966796875\n",
      "Min step 218/1000, Objective: -112.9397964477539\n",
      "Min step 219/1000, Objective: -114.00872039794922\n",
      "Min step 220/1000, Objective: -115.08293151855469\n",
      "Min step 221/1000, Objective: -116.16232299804688\n",
      "Min step 222/1000, Objective: -117.24700927734375\n",
      "Min step 223/1000, Objective: -118.33690643310547\n",
      "Min step 224/1000, Objective: -119.43205261230469\n",
      "Min step 225/1000, Objective: -120.53242492675781\n",
      "Min step 226/1000, Objective: -121.63807678222656\n",
      "Min step 227/1000, Objective: -122.74893951416016\n",
      "Min step 228/1000, Objective: -123.8650894165039\n",
      "Min step 229/1000, Objective: -124.98639678955078\n",
      "Min step 230/1000, Objective: -126.11305236816406\n",
      "Min step 231/1000, Objective: -127.24488830566406\n",
      "Min step 232/1000, Objective: -128.3819580078125\n",
      "Min step 233/1000, Objective: -129.52426147460938\n",
      "Min step 234/1000, Objective: -130.67176818847656\n",
      "Min step 235/1000, Objective: -131.82455444335938\n",
      "Min step 236/1000, Objective: -132.9825897216797\n",
      "Min step 237/1000, Objective: -134.145751953125\n",
      "Min step 238/1000, Objective: -135.31422424316406\n",
      "Min step 239/1000, Objective: -136.4879608154297\n",
      "Min step 240/1000, Objective: -137.66688537597656\n",
      "Min step 241/1000, Objective: -138.8510284423828\n",
      "Min step 242/1000, Objective: -140.04043579101562\n",
      "Min step 243/1000, Objective: -141.23500061035156\n",
      "Min step 244/1000, Objective: -142.43482971191406\n",
      "Min step 245/1000, Objective: -143.639892578125\n",
      "Min step 246/1000, Objective: -144.85011291503906\n",
      "Min step 247/1000, Objective: -146.065673828125\n",
      "Min step 248/1000, Objective: -147.2863311767578\n",
      "Min step 249/1000, Objective: -148.51231384277344\n",
      "Min step 250/1000, Objective: -149.74343872070312\n",
      "Min step 251/1000, Objective: -150.97979736328125\n",
      "Min step 252/1000, Objective: -152.22137451171875\n",
      "Min step 253/1000, Objective: -153.46815490722656\n",
      "Min step 254/1000, Objective: -154.72015380859375\n",
      "Min step 255/1000, Objective: -155.9773712158203\n",
      "Min step 256/1000, Objective: -157.23985290527344\n",
      "Min step 257/1000, Objective: -158.50746154785156\n",
      "Min step 258/1000, Objective: -159.7803192138672\n",
      "Min step 259/1000, Objective: -161.05841064453125\n",
      "Min step 260/1000, Objective: -162.34164428710938\n",
      "Min step 261/1000, Objective: -163.630126953125\n",
      "Min step 262/1000, Objective: -164.9237060546875\n",
      "Min step 263/1000, Objective: -166.22262573242188\n",
      "Min step 264/1000, Objective: -167.52670288085938\n",
      "Min step 265/1000, Objective: -168.83602905273438\n",
      "Min step 266/1000, Objective: -170.15042114257812\n",
      "Min step 267/1000, Objective: -171.4701690673828\n",
      "Min step 268/1000, Objective: -172.79501342773438\n",
      "Min step 269/1000, Objective: -174.12506103515625\n",
      "Min step 270/1000, Objective: -175.46026611328125\n",
      "Min step 271/1000, Objective: -176.80078125\n",
      "Min step 272/1000, Objective: -178.14639282226562\n",
      "Min step 273/1000, Objective: -179.49728393554688\n",
      "Min step 274/1000, Objective: -180.85328674316406\n",
      "Min step 275/1000, Objective: -182.21446228027344\n",
      "Min step 276/1000, Objective: -183.58090209960938\n",
      "Min step 277/1000, Objective: -184.95242309570312\n",
      "Min step 278/1000, Objective: -186.32925415039062\n",
      "Min step 279/1000, Objective: -187.711181640625\n",
      "Min step 280/1000, Objective: -189.09825134277344\n",
      "Min step 281/1000, Objective: -190.49057006835938\n",
      "Min step 282/1000, Objective: -191.88812255859375\n",
      "Min step 283/1000, Objective: -193.2906951904297\n",
      "Min step 284/1000, Objective: -194.6985321044922\n",
      "Min step 285/1000, Objective: -196.11163330078125\n",
      "Min step 286/1000, Objective: -197.5297393798828\n",
      "Min step 287/1000, Objective: -198.95309448242188\n",
      "Min step 288/1000, Objective: -200.3816680908203\n",
      "Min step 289/1000, Objective: -201.81532287597656\n",
      "Min step 290/1000, Objective: -203.2541046142578\n",
      "Min step 291/1000, Objective: -204.6981964111328\n",
      "Min step 292/1000, Objective: -206.1473846435547\n",
      "Min step 293/1000, Objective: -207.60162353515625\n",
      "Min step 294/1000, Objective: -209.06117248535156\n",
      "Min step 295/1000, Objective: -210.52587890625\n",
      "Min step 296/1000, Objective: -211.99566650390625\n",
      "Min step 297/1000, Objective: -213.47071838378906\n",
      "Min step 298/1000, Objective: -214.95079040527344\n",
      "Min step 299/1000, Objective: -216.43606567382812\n",
      "Min step 300/1000, Objective: -217.9265594482422\n",
      "Min step 301/1000, Objective: -219.422119140625\n",
      "Min step 302/1000, Objective: -220.9229736328125\n",
      "Min step 303/1000, Objective: -222.42880249023438\n",
      "Min step 304/1000, Objective: -223.9397735595703\n",
      "Min step 305/1000, Objective: -225.45616149902344\n",
      "Min step 306/1000, Objective: -226.97738647460938\n",
      "Min step 307/1000, Objective: -228.50376892089844\n",
      "Min step 308/1000, Objective: -230.03536987304688\n",
      "Min step 309/1000, Objective: -231.5720672607422\n",
      "Min step 310/1000, Objective: -233.114013671875\n",
      "Min step 311/1000, Objective: -234.66104125976562\n",
      "Min step 312/1000, Objective: -236.21327209472656\n",
      "Min step 313/1000, Objective: -237.77059936523438\n",
      "Min step 314/1000, Objective: -239.3330078125\n",
      "Min step 315/1000, Objective: -240.90057373046875\n",
      "Min step 316/1000, Objective: -242.47332763671875\n",
      "Min step 317/1000, Objective: -244.05120849609375\n",
      "Min step 318/1000, Objective: -245.63401794433594\n",
      "Min step 319/1000, Objective: -247.22210693359375\n",
      "Min step 320/1000, Objective: -248.81521606445312\n",
      "Min step 321/1000, Objective: -250.41355895996094\n",
      "Min step 322/1000, Objective: -252.01698303222656\n",
      "Min step 323/1000, Objective: -253.62551879882812\n",
      "Min step 324/1000, Objective: -255.2391357421875\n",
      "Min step 325/1000, Objective: -256.8580017089844\n",
      "Min step 326/1000, Objective: -258.4819030761719\n",
      "Min step 327/1000, Objective: -260.1108703613281\n",
      "Min step 328/1000, Objective: -261.7449035644531\n",
      "Min step 329/1000, Objective: -263.38409423828125\n",
      "Min step 330/1000, Objective: -265.0284729003906\n",
      "Min step 331/1000, Objective: -266.6780090332031\n",
      "Min step 332/1000, Objective: -268.3324279785156\n",
      "Min step 333/1000, Objective: -269.9919738769531\n",
      "Min step 334/1000, Objective: -271.6567687988281\n",
      "Min step 335/1000, Objective: -273.3266296386719\n",
      "Min step 336/1000, Objective: -275.0015563964844\n",
      "Min step 337/1000, Objective: -276.68157958984375\n",
      "Min step 338/1000, Objective: -278.36669921875\n",
      "Min step 339/1000, Objective: -280.056884765625\n",
      "Min step 340/1000, Objective: -281.7521667480469\n",
      "Min step 341/1000, Objective: -283.4524841308594\n",
      "Min step 342/1000, Objective: -285.15802001953125\n",
      "Min step 343/1000, Objective: -286.86871337890625\n",
      "Min step 344/1000, Objective: -288.5843200683594\n",
      "Min step 345/1000, Objective: -290.304931640625\n",
      "Min step 346/1000, Objective: -292.03082275390625\n",
      "Min step 347/1000, Objective: -293.7616271972656\n",
      "Min step 348/1000, Objective: -295.4975891113281\n",
      "Min step 349/1000, Objective: -297.238525390625\n",
      "Min step 350/1000, Objective: -298.9847106933594\n",
      "Min step 351/1000, Objective: -300.7359924316406\n",
      "Min step 352/1000, Objective: -302.4920959472656\n",
      "Min step 353/1000, Objective: -304.2534484863281\n",
      "Min step 354/1000, Objective: -306.0198059082031\n",
      "Min step 355/1000, Objective: -307.7913818359375\n",
      "Min step 356/1000, Objective: -309.56787109375\n",
      "Min step 357/1000, Objective: -311.3494567871094\n",
      "Min step 358/1000, Objective: -313.1360778808594\n",
      "Min step 359/1000, Objective: -314.9278259277344\n",
      "Min step 360/1000, Objective: -316.72430419921875\n",
      "Min step 361/1000, Objective: -318.526123046875\n",
      "Min step 362/1000, Objective: -320.33331298828125\n",
      "Min step 363/1000, Objective: -322.1446533203125\n",
      "Min step 364/1000, Objective: -323.9620056152344\n",
      "Min step 365/1000, Objective: -325.78387451171875\n",
      "Min step 366/1000, Objective: -327.6108093261719\n",
      "Min step 367/1000, Objective: -329.4429016113281\n",
      "Min step 368/1000, Objective: -331.2801208496094\n",
      "Min step 369/1000, Objective: -333.122314453125\n",
      "Min step 370/1000, Objective: -334.9695739746094\n",
      "Min step 371/1000, Objective: -336.82159423828125\n",
      "Min step 372/1000, Objective: -338.6790466308594\n",
      "Min step 373/1000, Objective: -340.5413818359375\n",
      "Min step 374/1000, Objective: -342.4087219238281\n",
      "Min step 375/1000, Objective: -344.28106689453125\n",
      "Min step 376/1000, Objective: -346.1584167480469\n",
      "Min step 377/1000, Objective: -348.0410461425781\n",
      "Min step 378/1000, Objective: -349.9284362792969\n",
      "Min step 379/1000, Objective: -351.8208312988281\n",
      "Min step 380/1000, Objective: -353.71807861328125\n",
      "Min step 381/1000, Objective: -355.6210632324219\n",
      "Min step 382/1000, Objective: -357.52850341796875\n",
      "Min step 383/1000, Objective: -359.44110107421875\n",
      "Min step 384/1000, Objective: -361.358642578125\n",
      "Min step 385/1000, Objective: -363.28125\n",
      "Min step 386/1000, Objective: -365.2088623046875\n",
      "Min step 387/1000, Objective: -367.1412353515625\n",
      "Min step 388/1000, Objective: -369.0792541503906\n",
      "Min step 389/1000, Objective: -371.0216979980469\n",
      "Min step 390/1000, Objective: -372.9692077636719\n",
      "Min step 391/1000, Objective: -374.9217834472656\n",
      "Min step 392/1000, Objective: -376.8794860839844\n",
      "Min step 393/1000, Objective: -378.84210205078125\n",
      "Min step 394/1000, Objective: -380.8096008300781\n",
      "Min step 395/1000, Objective: -382.7822570800781\n",
      "Min step 396/1000, Objective: -384.7598571777344\n",
      "Min step 397/1000, Objective: -386.7426452636719\n",
      "Min step 398/1000, Objective: -388.7299499511719\n",
      "Min step 399/1000, Objective: -390.7227478027344\n",
      "Min step 400/1000, Objective: -392.7203369140625\n",
      "Min step 401/1000, Objective: -394.7224426269531\n",
      "Min step 402/1000, Objective: -396.73028564453125\n",
      "Min step 403/1000, Objective: -398.7428283691406\n",
      "Min step 404/1000, Objective: -400.7606506347656\n",
      "Min step 405/1000, Objective: -402.7828063964844\n",
      "Min step 406/1000, Objective: -404.8101501464844\n",
      "Min step 407/1000, Objective: -406.8426513671875\n",
      "Min step 408/1000, Objective: -408.88018798828125\n",
      "Min step 409/1000, Objective: -410.92242431640625\n",
      "Min step 410/1000, Objective: -412.969970703125\n",
      "Min step 411/1000, Objective: -415.02191162109375\n",
      "Min step 412/1000, Objective: -417.0791931152344\n",
      "Min step 413/1000, Objective: -419.1413879394531\n",
      "Min step 414/1000, Objective: -421.20867919921875\n",
      "Min step 415/1000, Objective: -423.2807312011719\n",
      "Min step 416/1000, Objective: -425.358154296875\n",
      "Min step 417/1000, Objective: -427.4397888183594\n",
      "Min step 418/1000, Objective: -429.52728271484375\n",
      "Min step 419/1000, Objective: -431.6190185546875\n",
      "Min step 420/1000, Objective: -433.715576171875\n",
      "Min step 421/1000, Objective: -435.81756591796875\n",
      "Min step 422/1000, Objective: -437.9244384765625\n",
      "Min step 423/1000, Objective: -440.03564453125\n",
      "Min step 424/1000, Objective: -442.15264892578125\n",
      "Min step 425/1000, Objective: -444.27435302734375\n",
      "Min step 426/1000, Objective: -446.4010314941406\n",
      "Min step 427/1000, Objective: -448.5325012207031\n",
      "Min step 428/1000, Objective: -450.66876220703125\n",
      "Min step 429/1000, Objective: -452.8101501464844\n",
      "Min step 430/1000, Objective: -454.9564514160156\n",
      "Min step 431/1000, Objective: -457.1078796386719\n",
      "Min step 432/1000, Objective: -459.2641296386719\n",
      "Min step 433/1000, Objective: -461.4249267578125\n",
      "Min step 434/1000, Objective: -463.5908203125\n",
      "Min step 435/1000, Objective: -465.7620544433594\n",
      "Min step 436/1000, Objective: -467.93756103515625\n",
      "Min step 437/1000, Objective: -470.11846923828125\n",
      "Min step 438/1000, Objective: -472.30419921875\n",
      "Min step 439/1000, Objective: -474.4948425292969\n",
      "Min step 440/1000, Objective: -476.69036865234375\n",
      "Min step 441/1000, Objective: -478.8905029296875\n",
      "Min step 442/1000, Objective: -481.0959777832031\n",
      "Min step 443/1000, Objective: -483.3062438964844\n",
      "Min step 444/1000, Objective: -485.52142333984375\n",
      "Min step 445/1000, Objective: -487.741455078125\n",
      "Min step 446/1000, Objective: -489.9665832519531\n",
      "Min step 447/1000, Objective: -492.19610595703125\n",
      "Min step 448/1000, Objective: -494.43109130859375\n",
      "Min step 449/1000, Objective: -496.67071533203125\n",
      "Min step 450/1000, Objective: -498.91497802734375\n",
      "Min step 451/1000, Objective: -501.1645812988281\n",
      "Min step 452/1000, Objective: -503.41912841796875\n",
      "Min step 453/1000, Objective: -505.6780700683594\n",
      "Min step 454/1000, Objective: -507.9423522949219\n",
      "Min step 455/1000, Objective: -510.2109375\n",
      "Min step 456/1000, Objective: -512.485107421875\n",
      "Min step 457/1000, Objective: -514.7637939453125\n",
      "Min step 458/1000, Objective: -517.0471801757812\n",
      "Min step 459/1000, Objective: -519.336181640625\n",
      "Min step 460/1000, Objective: -521.6292724609375\n",
      "Min step 461/1000, Objective: -523.9273681640625\n",
      "Min step 462/1000, Objective: -526.2307739257812\n",
      "Min step 463/1000, Objective: -528.5385131835938\n",
      "Min step 464/1000, Objective: -530.8519287109375\n",
      "Min step 465/1000, Objective: -533.1691284179688\n",
      "Min step 466/1000, Objective: -535.492431640625\n",
      "Min step 467/1000, Objective: -537.8192138671875\n",
      "Min step 468/1000, Objective: -540.15185546875\n",
      "Min step 469/1000, Objective: -542.4887084960938\n",
      "Min step 470/1000, Objective: -544.8311767578125\n",
      "Min step 471/1000, Objective: -547.1777954101562\n",
      "Min step 472/1000, Objective: -549.52978515625\n",
      "Min step 473/1000, Objective: -551.8862915039062\n",
      "Min step 474/1000, Objective: -554.2474975585938\n",
      "Min step 475/1000, Objective: -556.6140747070312\n",
      "Min step 476/1000, Objective: -558.985107421875\n",
      "Min step 477/1000, Objective: -561.361328125\n",
      "Min step 478/1000, Objective: -563.7418212890625\n",
      "Min step 479/1000, Objective: -566.1279296875\n",
      "Min step 480/1000, Objective: -568.5186767578125\n",
      "Min step 481/1000, Objective: -570.9136962890625\n",
      "Min step 482/1000, Objective: -573.3135986328125\n",
      "Min step 483/1000, Objective: -575.718505859375\n",
      "Min step 484/1000, Objective: -578.1293334960938\n",
      "Min step 485/1000, Objective: -580.5433959960938\n",
      "Min step 486/1000, Objective: -582.9631958007812\n",
      "Min step 487/1000, Objective: -585.38720703125\n",
      "Min step 488/1000, Objective: -587.8167114257812\n",
      "Min step 489/1000, Objective: -590.2509155273438\n",
      "Min step 490/1000, Objective: -592.6897583007812\n",
      "Min step 491/1000, Objective: -595.13330078125\n",
      "Min step 492/1000, Objective: -597.58154296875\n",
      "Min step 493/1000, Objective: -600.03466796875\n",
      "Min step 494/1000, Objective: -602.4929809570312\n",
      "Min step 495/1000, Objective: -604.9561157226562\n",
      "Min step 496/1000, Objective: -607.4236450195312\n",
      "Min step 497/1000, Objective: -609.8963012695312\n",
      "Min step 498/1000, Objective: -612.3731079101562\n",
      "Min step 499/1000, Objective: -614.8553466796875\n",
      "Min step 500/1000, Objective: -617.3423461914062\n",
      "Min step 501/1000, Objective: -619.8335571289062\n",
      "Min step 502/1000, Objective: -622.3306274414062\n",
      "Min step 503/1000, Objective: -624.8319091796875\n",
      "Min step 504/1000, Objective: -627.3382568359375\n",
      "Min step 505/1000, Objective: -629.8490600585938\n",
      "Min step 506/1000, Objective: -632.3650512695312\n",
      "Min step 507/1000, Objective: -634.8851928710938\n",
      "Min step 508/1000, Objective: -637.41064453125\n",
      "Min step 509/1000, Objective: -639.9408569335938\n",
      "Min step 510/1000, Objective: -642.4751586914062\n",
      "Min step 511/1000, Objective: -645.0151977539062\n",
      "Min step 512/1000, Objective: -647.5589599609375\n",
      "Min step 513/1000, Objective: -650.1091918945312\n",
      "Min step 514/1000, Objective: -652.6626586914062\n",
      "Min step 515/1000, Objective: -655.2213745117188\n",
      "Min step 516/1000, Objective: -657.7849731445312\n",
      "Min step 517/1000, Objective: -660.3532104492188\n",
      "Min step 518/1000, Objective: -662.9270629882812\n",
      "Min step 519/1000, Objective: -665.5040893554688\n",
      "Min step 520/1000, Objective: -668.0875244140625\n",
      "Min step 521/1000, Objective: -670.6741333007812\n",
      "Min step 522/1000, Objective: -673.2667846679688\n",
      "Min step 523/1000, Objective: -675.8631591796875\n",
      "Min step 524/1000, Objective: -678.4649047851562\n",
      "Min step 525/1000, Objective: -681.0715942382812\n",
      "Min step 526/1000, Objective: -683.6828002929688\n",
      "Min step 527/1000, Objective: -686.29931640625\n",
      "Min step 528/1000, Objective: -688.9192504882812\n",
      "Min step 529/1000, Objective: -691.5455322265625\n",
      "Min step 530/1000, Objective: -694.1746215820312\n",
      "Min step 531/1000, Objective: -696.8098754882812\n",
      "Min step 532/1000, Objective: -699.4500732421875\n",
      "Min step 533/1000, Objective: -702.0945434570312\n",
      "Min step 534/1000, Objective: -704.74365234375\n",
      "Min step 535/1000, Objective: -707.3972778320312\n",
      "Min step 536/1000, Objective: -710.05615234375\n",
      "Min step 537/1000, Objective: -712.7191772460938\n",
      "Min step 538/1000, Objective: -715.3876342773438\n",
      "Min step 539/1000, Objective: -718.0604248046875\n",
      "Min step 540/1000, Objective: -720.7374877929688\n",
      "Min step 541/1000, Objective: -723.4199829101562\n",
      "Min step 542/1000, Objective: -726.1074829101562\n",
      "Min step 543/1000, Objective: -728.7993774414062\n",
      "Min step 544/1000, Objective: -731.4957885742188\n",
      "Min step 545/1000, Objective: -734.1968383789062\n",
      "Min step 546/1000, Objective: -736.903076171875\n",
      "Min step 547/1000, Objective: -739.6130981445312\n",
      "Min step 548/1000, Objective: -742.3284301757812\n",
      "Min step 549/1000, Objective: -745.0484008789062\n",
      "Min step 550/1000, Objective: -747.7735595703125\n",
      "Min step 551/1000, Objective: -750.5025634765625\n",
      "Min step 552/1000, Objective: -753.2374877929688\n",
      "Min step 553/1000, Objective: -755.976318359375\n",
      "Min step 554/1000, Objective: -758.7203369140625\n",
      "Min step 555/1000, Objective: -761.4683837890625\n",
      "Min step 556/1000, Objective: -764.2211303710938\n",
      "Min step 557/1000, Objective: -766.9783935546875\n",
      "Min step 558/1000, Objective: -769.7410888671875\n",
      "Min step 559/1000, Objective: -772.5087890625\n",
      "Min step 560/1000, Objective: -775.2798461914062\n",
      "Min step 561/1000, Objective: -778.0570678710938\n",
      "Min step 562/1000, Objective: -780.837646484375\n",
      "Min step 563/1000, Objective: -783.6239013671875\n",
      "Min step 564/1000, Objective: -786.414306640625\n",
      "Min step 565/1000, Objective: -789.2095947265625\n",
      "Min step 566/1000, Objective: -792.0099487304688\n",
      "Min step 567/1000, Objective: -794.8148193359375\n",
      "Min step 568/1000, Objective: -797.6236572265625\n",
      "Min step 569/1000, Objective: -800.4378051757812\n",
      "Min step 570/1000, Objective: -803.2557983398438\n",
      "Min step 571/1000, Objective: -806.0797119140625\n",
      "Min step 572/1000, Objective: -808.908203125\n",
      "Min step 573/1000, Objective: -811.7401733398438\n",
      "Min step 574/1000, Objective: -814.578125\n",
      "Min step 575/1000, Objective: -817.4202880859375\n",
      "Min step 576/1000, Objective: -820.2662353515625\n",
      "Min step 577/1000, Objective: -823.1182861328125\n",
      "Min step 578/1000, Objective: -825.9732055664062\n",
      "Min step 579/1000, Objective: -828.834228515625\n",
      "Min step 580/1000, Objective: -831.69970703125\n",
      "Min step 581/1000, Objective: -834.569580078125\n",
      "Min step 582/1000, Objective: -837.444580078125\n",
      "Min step 583/1000, Objective: -840.32421875\n",
      "Min step 584/1000, Objective: -843.2080688476562\n",
      "Min step 585/1000, Objective: -846.0963745117188\n",
      "Min step 586/1000, Objective: -848.9896850585938\n",
      "Min step 587/1000, Objective: -851.88720703125\n",
      "Min step 588/1000, Objective: -854.7899780273438\n",
      "Min step 589/1000, Objective: -857.6970825195312\n",
      "Min step 590/1000, Objective: -860.609375\n",
      "Min step 591/1000, Objective: -863.5250244140625\n",
      "Min step 592/1000, Objective: -866.4468383789062\n",
      "Min step 593/1000, Objective: -869.372314453125\n",
      "Min step 594/1000, Objective: -872.303466796875\n",
      "Min step 595/1000, Objective: -875.2385864257812\n",
      "Min step 596/1000, Objective: -878.1785278320312\n",
      "Min step 597/1000, Objective: -881.1220703125\n",
      "Min step 598/1000, Objective: -884.0709228515625\n",
      "Min step 599/1000, Objective: -887.0244140625\n",
      "Min step 600/1000, Objective: -889.982421875\n",
      "Min step 601/1000, Objective: -892.9452514648438\n",
      "Min step 602/1000, Objective: -895.9140014648438\n",
      "Min step 603/1000, Objective: -898.8861694335938\n",
      "Min step 604/1000, Objective: -901.8616943359375\n",
      "Min step 605/1000, Objective: -904.8433227539062\n",
      "Min step 606/1000, Objective: -907.8286743164062\n",
      "Min step 607/1000, Objective: -910.8201293945312\n",
      "Min step 608/1000, Objective: -913.813720703125\n",
      "Min step 609/1000, Objective: -916.8148193359375\n",
      "Min step 610/1000, Objective: -919.8181762695312\n",
      "Min step 611/1000, Objective: -922.827392578125\n",
      "Min step 612/1000, Objective: -925.8403930664062\n",
      "Min step 613/1000, Objective: -928.8587646484375\n",
      "Min step 614/1000, Objective: -931.881103515625\n",
      "Min step 615/1000, Objective: -934.9083862304688\n",
      "Min step 616/1000, Objective: -937.941162109375\n",
      "Min step 617/1000, Objective: -940.9774780273438\n",
      "Min step 618/1000, Objective: -944.018798828125\n",
      "Min step 619/1000, Objective: -947.0647583007812\n",
      "Min step 620/1000, Objective: -950.1140747070312\n",
      "Min step 621/1000, Objective: -953.1692504882812\n",
      "Min step 622/1000, Objective: -956.22998046875\n",
      "Min step 623/1000, Objective: -959.2929077148438\n",
      "Min step 624/1000, Objective: -962.361328125\n",
      "Min step 625/1000, Objective: -965.4351806640625\n",
      "Min step 626/1000, Objective: -968.5121459960938\n",
      "Min step 627/1000, Objective: -971.594970703125\n",
      "Min step 628/1000, Objective: -974.6810302734375\n",
      "Min step 629/1000, Objective: -977.7735595703125\n",
      "Min step 630/1000, Objective: -980.8702392578125\n",
      "Min step 631/1000, Objective: -983.9705810546875\n",
      "Min step 632/1000, Objective: -987.074951171875\n",
      "Min step 633/1000, Objective: -990.185302734375\n",
      "Min step 634/1000, Objective: -993.2998657226562\n",
      "Min step 635/1000, Objective: -996.4188232421875\n",
      "Min step 636/1000, Objective: -999.5418090820312\n",
      "Min step 637/1000, Objective: -1002.6698608398438\n",
      "Min step 638/1000, Objective: -1005.8031616210938\n",
      "Min step 639/1000, Objective: -1008.9395751953125\n",
      "Min step 640/1000, Objective: -1012.0825805664062\n",
      "Min step 641/1000, Objective: -1015.2288208007812\n",
      "Min step 642/1000, Objective: -1018.3792724609375\n",
      "Min step 643/1000, Objective: -1021.5347900390625\n",
      "Min step 644/1000, Objective: -1024.6944580078125\n",
      "Min step 645/1000, Objective: -1027.859375\n",
      "Min step 646/1000, Objective: -1031.02734375\n",
      "Min step 647/1000, Objective: -1034.201416015625\n",
      "Min step 648/1000, Objective: -1037.3790283203125\n",
      "Min step 649/1000, Objective: -1040.561767578125\n",
      "Min step 650/1000, Objective: -1043.7491455078125\n",
      "Min step 651/1000, Objective: -1046.9407958984375\n",
      "Min step 652/1000, Objective: -1050.137939453125\n",
      "Min step 653/1000, Objective: -1053.3377685546875\n",
      "Min step 654/1000, Objective: -1056.54345703125\n",
      "Min step 655/1000, Objective: -1059.7540283203125\n",
      "Min step 656/1000, Objective: -1062.967529296875\n",
      "Min step 657/1000, Objective: -1066.1871337890625\n",
      "Min step 658/1000, Objective: -1069.410400390625\n",
      "Min step 659/1000, Objective: -1072.6397705078125\n",
      "Min step 660/1000, Objective: -1075.870849609375\n",
      "Min step 661/1000, Objective: -1079.107421875\n",
      "Min step 662/1000, Objective: -1082.349365234375\n",
      "Min step 663/1000, Objective: -1085.595458984375\n",
      "Min step 664/1000, Objective: -1088.8465576171875\n",
      "Min step 665/1000, Objective: -1092.100341796875\n",
      "Min step 666/1000, Objective: -1095.3604736328125\n",
      "Min step 667/1000, Objective: -1098.6240234375\n",
      "Min step 668/1000, Objective: -1101.8936767578125\n",
      "Min step 669/1000, Objective: -1105.1669921875\n",
      "Min step 670/1000, Objective: -1108.4429931640625\n",
      "Min step 671/1000, Objective: -1111.7261962890625\n",
      "Min step 672/1000, Objective: -1115.01318359375\n",
      "Min step 673/1000, Objective: -1118.3037109375\n",
      "Min step 674/1000, Objective: -1121.6014404296875\n",
      "Min step 675/1000, Objective: -1124.8994140625\n",
      "Min step 676/1000, Objective: -1128.2047119140625\n",
      "Min step 677/1000, Objective: -1131.5135498046875\n",
      "Min step 678/1000, Objective: -1134.8271484375\n",
      "Min step 679/1000, Objective: -1138.14599609375\n",
      "Min step 680/1000, Objective: -1141.4688720703125\n",
      "Min step 681/1000, Objective: -1144.7952880859375\n",
      "Min step 682/1000, Objective: -1148.1256103515625\n",
      "Min step 683/1000, Objective: -1151.463134765625\n",
      "Min step 684/1000, Objective: -1154.8033447265625\n",
      "Min step 685/1000, Objective: -1158.1484375\n",
      "Min step 686/1000, Objective: -1161.49755859375\n",
      "Min step 687/1000, Objective: -1164.8514404296875\n",
      "Min step 688/1000, Objective: -1168.20947265625\n",
      "Min step 689/1000, Objective: -1171.5726318359375\n",
      "Min step 690/1000, Objective: -1174.94091796875\n",
      "Min step 691/1000, Objective: -1178.3115234375\n",
      "Min step 692/1000, Objective: -1181.6871337890625\n",
      "Min step 693/1000, Objective: -1185.06884765625\n",
      "Min step 694/1000, Objective: -1188.453369140625\n",
      "Min step 695/1000, Objective: -1191.84375\n",
      "Min step 696/1000, Objective: -1195.2381591796875\n",
      "Min step 697/1000, Objective: -1198.6363525390625\n",
      "Min step 698/1000, Objective: -1202.0391845703125\n",
      "Min step 699/1000, Objective: -1205.4464111328125\n",
      "Min step 700/1000, Objective: -1208.85888671875\n",
      "Min step 701/1000, Objective: -1212.2740478515625\n",
      "Min step 702/1000, Objective: -1215.69580078125\n",
      "Min step 703/1000, Objective: -1219.1212158203125\n",
      "Min step 704/1000, Objective: -1222.5518798828125\n",
      "Min step 705/1000, Objective: -1225.984130859375\n",
      "Min step 706/1000, Objective: -1229.4244384765625\n",
      "Min step 707/1000, Objective: -1232.8685302734375\n",
      "Min step 708/1000, Objective: -1236.3153076171875\n",
      "Min step 709/1000, Objective: -1239.765625\n",
      "Min step 710/1000, Objective: -1243.2236328125\n",
      "Min step 711/1000, Objective: -1246.6856689453125\n",
      "Min step 712/1000, Objective: -1250.151611328125\n",
      "Min step 713/1000, Objective: -1253.619140625\n",
      "Min step 714/1000, Objective: -1257.092041015625\n",
      "Min step 715/1000, Objective: -1260.5726318359375\n",
      "Min step 716/1000, Objective: -1264.0562744140625\n",
      "Min step 717/1000, Objective: -1267.542724609375\n",
      "Min step 718/1000, Objective: -1271.03466796875\n",
      "Min step 719/1000, Objective: -1274.531005859375\n",
      "Min step 720/1000, Objective: -1278.0322265625\n",
      "Min step 721/1000, Objective: -1281.536376953125\n",
      "Min step 722/1000, Objective: -1285.0478515625\n",
      "Min step 723/1000, Objective: -1288.5604248046875\n",
      "Min step 724/1000, Objective: -1292.07958984375\n",
      "Min step 725/1000, Objective: -1295.6004638671875\n",
      "Min step 726/1000, Objective: -1299.13037109375\n",
      "Min step 727/1000, Objective: -1302.660400390625\n",
      "Min step 728/1000, Objective: -1306.1973876953125\n",
      "Min step 729/1000, Objective: -1309.7376708984375\n",
      "Min step 730/1000, Objective: -1313.28271484375\n",
      "Min step 731/1000, Objective: -1316.831298828125\n",
      "Min step 732/1000, Objective: -1320.3839111328125\n",
      "Min step 733/1000, Objective: -1323.94287109375\n",
      "Min step 734/1000, Objective: -1327.505126953125\n",
      "Min step 735/1000, Objective: -1331.0723876953125\n",
      "Min step 736/1000, Objective: -1334.642578125\n",
      "Min step 737/1000, Objective: -1338.2200927734375\n",
      "Min step 738/1000, Objective: -1341.7991943359375\n",
      "Min step 739/1000, Objective: -1345.3843994140625\n",
      "Min step 740/1000, Objective: -1348.973876953125\n",
      "Min step 741/1000, Objective: -1352.5672607421875\n",
      "Min step 742/1000, Objective: -1356.165771484375\n",
      "Min step 743/1000, Objective: -1359.7655029296875\n",
      "Min step 744/1000, Objective: -1363.372314453125\n",
      "Min step 745/1000, Objective: -1366.984619140625\n",
      "Min step 746/1000, Objective: -1370.5980224609375\n",
      "Min step 747/1000, Objective: -1374.21630859375\n",
      "Min step 748/1000, Objective: -1377.84033203125\n",
      "Min step 749/1000, Objective: -1381.4683837890625\n",
      "Min step 750/1000, Objective: -1385.1026611328125\n",
      "Min step 751/1000, Objective: -1388.739501953125\n",
      "Min step 752/1000, Objective: -1392.38134765625\n",
      "Min step 753/1000, Objective: -1396.027099609375\n",
      "Min step 754/1000, Objective: -1399.67724609375\n",
      "Min step 755/1000, Objective: -1403.3299560546875\n",
      "Min step 756/1000, Objective: -1406.9913330078125\n",
      "Min step 757/1000, Objective: -1410.6527099609375\n",
      "Min step 758/1000, Objective: -1414.3193359375\n",
      "Min step 759/1000, Objective: -1417.991943359375\n",
      "Min step 760/1000, Objective: -1421.6688232421875\n",
      "Min step 761/1000, Objective: -1425.3494873046875\n",
      "Min step 762/1000, Objective: -1429.0379638671875\n",
      "Min step 763/1000, Objective: -1432.725830078125\n",
      "Min step 764/1000, Objective: -1436.4173583984375\n",
      "Min step 765/1000, Objective: -1440.1153564453125\n",
      "Min step 766/1000, Objective: -1443.8194580078125\n",
      "Min step 767/1000, Objective: -1447.5260009765625\n",
      "Min step 768/1000, Objective: -1451.2384033203125\n",
      "Min step 769/1000, Objective: -1454.9541015625\n",
      "Min step 770/1000, Objective: -1458.67236328125\n",
      "Min step 771/1000, Objective: -1462.3956298828125\n",
      "Min step 772/1000, Objective: -1466.1253662109375\n",
      "Min step 773/1000, Objective: -1469.858642578125\n",
      "Min step 774/1000, Objective: -1473.5965576171875\n",
      "Min step 775/1000, Objective: -1477.3350830078125\n",
      "Min step 776/1000, Objective: -1481.0819091796875\n",
      "Min step 777/1000, Objective: -1484.8331298828125\n",
      "Min step 778/1000, Objective: -1488.587158203125\n",
      "Min step 779/1000, Objective: -1492.3466796875\n",
      "Min step 780/1000, Objective: -1496.109619140625\n",
      "Min step 781/1000, Objective: -1499.8760986328125\n",
      "Min step 782/1000, Objective: -1503.648193359375\n",
      "Min step 783/1000, Objective: -1507.4244384765625\n",
      "Min step 784/1000, Objective: -1511.2054443359375\n",
      "Min step 785/1000, Objective: -1514.9901123046875\n",
      "Min step 786/1000, Objective: -1518.7783203125\n",
      "Min step 787/1000, Objective: -1522.572509765625\n",
      "Min step 788/1000, Objective: -1526.368896484375\n",
      "Min step 789/1000, Objective: -1530.1728515625\n",
      "Min step 790/1000, Objective: -1533.9798583984375\n",
      "Min step 791/1000, Objective: -1537.78857421875\n",
      "Min step 792/1000, Objective: -1541.6051025390625\n",
      "Min step 793/1000, Objective: -1545.4232177734375\n",
      "Min step 794/1000, Objective: -1549.2471923828125\n",
      "Min step 795/1000, Objective: -1553.0750732421875\n",
      "Min step 796/1000, Objective: -1556.90625\n",
      "Min step 797/1000, Objective: -1560.7432861328125\n",
      "Min step 798/1000, Objective: -1564.5819091796875\n",
      "Min step 799/1000, Objective: -1568.429443359375\n",
      "Min step 800/1000, Objective: -1572.279541015625\n",
      "Min step 801/1000, Objective: -1576.130859375\n",
      "Min step 802/1000, Objective: -1579.9906005859375\n",
      "Min step 803/1000, Objective: -1583.8494873046875\n",
      "Min step 804/1000, Objective: -1587.71728515625\n",
      "Min step 805/1000, Objective: -1591.587890625\n",
      "Min step 806/1000, Objective: -1595.46484375\n",
      "Min step 807/1000, Objective: -1599.343017578125\n",
      "Min step 808/1000, Objective: -1603.2275390625\n",
      "Min step 809/1000, Objective: -1607.116943359375\n",
      "Min step 810/1000, Objective: -1611.00830078125\n",
      "Min step 811/1000, Objective: -1614.90771484375\n",
      "Min step 812/1000, Objective: -1618.806884765625\n",
      "Min step 813/1000, Objective: -1622.710693359375\n",
      "Min step 814/1000, Objective: -1626.618896484375\n",
      "Min step 815/1000, Objective: -1630.5323486328125\n",
      "Min step 816/1000, Objective: -1634.454833984375\n",
      "Min step 817/1000, Objective: -1638.373779296875\n",
      "Min step 818/1000, Objective: -1642.303466796875\n",
      "Min step 819/1000, Objective: -1646.2314453125\n",
      "Min step 820/1000, Objective: -1650.1666259765625\n",
      "Min step 821/1000, Objective: -1654.10595703125\n",
      "Min step 822/1000, Objective: -1658.0494384765625\n",
      "Min step 823/1000, Objective: -1661.9976806640625\n",
      "Min step 824/1000, Objective: -1665.947265625\n",
      "Min step 825/1000, Objective: -1669.9053955078125\n",
      "Min step 826/1000, Objective: -1673.8662109375\n",
      "Min step 827/1000, Objective: -1677.829345703125\n",
      "Min step 828/1000, Objective: -1681.8023681640625\n",
      "Min step 829/1000, Objective: -1685.7730712890625\n",
      "Min step 830/1000, Objective: -1689.7498779296875\n",
      "Min step 831/1000, Objective: -1693.733642578125\n",
      "Min step 832/1000, Objective: -1697.7208251953125\n",
      "Min step 833/1000, Objective: -1701.709716796875\n",
      "Min step 834/1000, Objective: -1705.7041015625\n",
      "Min step 835/1000, Objective: -1709.703857421875\n",
      "Min step 836/1000, Objective: -1713.70556640625\n",
      "Min step 837/1000, Objective: -1717.7109375\n",
      "Min step 838/1000, Objective: -1721.72412109375\n",
      "Min step 839/1000, Objective: -1725.7410888671875\n",
      "Min step 840/1000, Objective: -1729.75927734375\n",
      "Min step 841/1000, Objective: -1733.7857666015625\n",
      "Min step 842/1000, Objective: -1737.8135986328125\n",
      "Min step 843/1000, Objective: -1741.8465576171875\n",
      "Min step 844/1000, Objective: -1745.884521484375\n",
      "Min step 845/1000, Objective: -1749.9217529296875\n",
      "Min step 846/1000, Objective: -1753.969482421875\n",
      "Min step 847/1000, Objective: -1758.01611328125\n",
      "Min step 848/1000, Objective: -1762.0733642578125\n",
      "Min step 849/1000, Objective: -1766.1307373046875\n",
      "Min step 850/1000, Objective: -1770.1895751953125\n",
      "Min step 851/1000, Objective: -1774.25732421875\n",
      "Min step 852/1000, Objective: -1778.3280029296875\n",
      "Min step 853/1000, Objective: -1782.4046630859375\n",
      "Min step 854/1000, Objective: -1786.484619140625\n",
      "Min step 855/1000, Objective: -1790.5673828125\n",
      "Min step 856/1000, Objective: -1794.6561279296875\n",
      "Min step 857/1000, Objective: -1798.7457275390625\n",
      "Min step 858/1000, Objective: -1802.840576171875\n",
      "Min step 859/1000, Objective: -1806.9425048828125\n",
      "Min step 860/1000, Objective: -1811.046875\n",
      "Min step 861/1000, Objective: -1815.156494140625\n",
      "Min step 862/1000, Objective: -1819.2657470703125\n",
      "Min step 863/1000, Objective: -1823.38427734375\n",
      "Min step 864/1000, Objective: -1827.5068359375\n",
      "Min step 865/1000, Objective: -1831.6337890625\n",
      "Min step 866/1000, Objective: -1835.760009765625\n",
      "Min step 867/1000, Objective: -1839.8966064453125\n",
      "Min step 868/1000, Objective: -1844.0347900390625\n",
      "Min step 869/1000, Objective: -1848.174072265625\n",
      "Min step 870/1000, Objective: -1852.322509765625\n",
      "Min step 871/1000, Objective: -1856.4736328125\n",
      "Min step 872/1000, Objective: -1860.6280517578125\n",
      "Min step 873/1000, Objective: -1864.788330078125\n",
      "Min step 874/1000, Objective: -1868.951171875\n",
      "Min step 875/1000, Objective: -1873.116943359375\n",
      "Min step 876/1000, Objective: -1877.28857421875\n",
      "Min step 877/1000, Objective: -1881.4661865234375\n",
      "Min step 878/1000, Objective: -1885.642822265625\n",
      "Min step 879/1000, Objective: -1889.8297119140625\n",
      "Min step 880/1000, Objective: -1894.0157470703125\n",
      "Min step 881/1000, Objective: -1898.2080078125\n",
      "Min step 882/1000, Objective: -1902.4052734375\n",
      "Min step 883/1000, Objective: -1906.6065673828125\n",
      "Min step 884/1000, Objective: -1910.8096923828125\n",
      "Min step 885/1000, Objective: -1915.021240234375\n",
      "Min step 886/1000, Objective: -1919.23388671875\n",
      "Min step 887/1000, Objective: -1923.45166015625\n",
      "Min step 888/1000, Objective: -1927.675537109375\n",
      "Min step 889/1000, Objective: -1931.9013671875\n",
      "Min step 890/1000, Objective: -1936.128662109375\n",
      "Min step 891/1000, Objective: -1940.3603515625\n",
      "Min step 892/1000, Objective: -1944.6029052734375\n",
      "Min step 893/1000, Objective: -1948.84423828125\n",
      "Min step 894/1000, Objective: -1953.089599609375\n",
      "Min step 895/1000, Objective: -1957.338623046875\n",
      "Min step 896/1000, Objective: -1961.59521484375\n",
      "Min step 897/1000, Objective: -1965.85498046875\n",
      "Min step 898/1000, Objective: -1970.11669921875\n",
      "Min step 899/1000, Objective: -1974.38623046875\n",
      "Min step 900/1000, Objective: -1978.6546630859375\n",
      "Min step 901/1000, Objective: -1982.9326171875\n",
      "Min step 902/1000, Objective: -1987.2103271484375\n",
      "Min step 903/1000, Objective: -1991.4962158203125\n",
      "Min step 904/1000, Objective: -1995.7822265625\n",
      "Min step 905/1000, Objective: -2000.075439453125\n",
      "Min step 906/1000, Objective: -2004.368896484375\n",
      "Min step 907/1000, Objective: -2008.6719970703125\n",
      "Min step 908/1000, Objective: -2012.9766845703125\n",
      "Min step 909/1000, Objective: -2017.289794921875\n",
      "Min step 910/1000, Objective: -2021.60009765625\n",
      "Min step 911/1000, Objective: -2025.913818359375\n",
      "Min step 912/1000, Objective: -2030.2376708984375\n",
      "Min step 913/1000, Objective: -2034.5601806640625\n",
      "Min step 914/1000, Objective: -2038.89208984375\n",
      "Min step 915/1000, Objective: -2043.22509765625\n",
      "Min step 916/1000, Objective: -2047.5634765625\n",
      "Min step 917/1000, Objective: -2051.90478515625\n",
      "Min step 918/1000, Objective: -2056.2509765625\n",
      "Min step 919/1000, Objective: -2060.60009765625\n",
      "Min step 920/1000, Objective: -2064.956298828125\n",
      "Min step 921/1000, Objective: -2069.31103515625\n",
      "Min step 922/1000, Objective: -2073.67626953125\n",
      "Min step 923/1000, Objective: -2078.039306640625\n",
      "Min step 924/1000, Objective: -2082.412109375\n",
      "Min step 925/1000, Objective: -2086.787353515625\n",
      "Min step 926/1000, Objective: -2091.16748046875\n",
      "Min step 927/1000, Objective: -2095.54736328125\n",
      "Min step 928/1000, Objective: -2099.933837890625\n",
      "Min step 929/1000, Objective: -2104.329833984375\n",
      "Min step 930/1000, Objective: -2108.725341796875\n",
      "Min step 931/1000, Objective: -2113.118408203125\n",
      "Min step 932/1000, Objective: -2117.526123046875\n",
      "Min step 933/1000, Objective: -2121.9326171875\n",
      "Min step 934/1000, Objective: -2126.34423828125\n",
      "Min step 935/1000, Objective: -2130.75439453125\n",
      "Min step 936/1000, Objective: -2135.177734375\n",
      "Min step 937/1000, Objective: -2139.60400390625\n",
      "Min step 938/1000, Objective: -2144.03076171875\n",
      "Min step 939/1000, Objective: -2148.4638671875\n",
      "Min step 940/1000, Objective: -2152.89892578125\n",
      "Min step 941/1000, Objective: -2157.340087890625\n",
      "Min step 942/1000, Objective: -2161.787841796875\n",
      "Min step 943/1000, Objective: -2166.235107421875\n",
      "Min step 944/1000, Objective: -2170.685302734375\n",
      "Min step 945/1000, Objective: -2175.14453125\n",
      "Min step 946/1000, Objective: -2179.60546875\n",
      "Min step 947/1000, Objective: -2184.0673828125\n",
      "Min step 948/1000, Objective: -2188.535888671875\n",
      "Min step 949/1000, Objective: -2193.010498046875\n",
      "Min step 950/1000, Objective: -2197.48583984375\n",
      "Min step 951/1000, Objective: -2201.96533203125\n",
      "Min step 952/1000, Objective: -2206.453125\n",
      "Min step 953/1000, Objective: -2210.942626953125\n",
      "Min step 954/1000, Objective: -2215.434814453125\n",
      "Min step 955/1000, Objective: -2219.932861328125\n",
      "Min step 956/1000, Objective: -2224.43408203125\n",
      "Min step 957/1000, Objective: -2228.939697265625\n",
      "Min step 958/1000, Objective: -2233.453125\n",
      "Min step 959/1000, Objective: -2237.96630859375\n",
      "Min step 960/1000, Objective: -2242.483642578125\n",
      "Min step 961/1000, Objective: -2247.00048828125\n",
      "Min step 962/1000, Objective: -2251.525390625\n",
      "Min step 963/1000, Objective: -2256.062744140625\n",
      "Min step 964/1000, Objective: -2260.59326171875\n",
      "Min step 965/1000, Objective: -2265.130859375\n",
      "Min step 966/1000, Objective: -2269.671875\n",
      "Min step 967/1000, Objective: -2274.221435546875\n",
      "Min step 968/1000, Objective: -2278.7646484375\n",
      "Min step 969/1000, Objective: -2283.3232421875\n",
      "Min step 970/1000, Objective: -2287.88134765625\n",
      "Min step 971/1000, Objective: -2292.445068359375\n",
      "Min step 972/1000, Objective: -2297.00927734375\n",
      "Min step 973/1000, Objective: -2301.579833984375\n",
      "Min step 974/1000, Objective: -2306.15625\n",
      "Min step 975/1000, Objective: -2310.7333984375\n",
      "Min step 976/1000, Objective: -2315.31884765625\n",
      "Min step 977/1000, Objective: -2319.902587890625\n",
      "Min step 978/1000, Objective: -2324.493896484375\n",
      "Min step 979/1000, Objective: -2329.090576171875\n",
      "Min step 980/1000, Objective: -2333.689697265625\n",
      "Min step 981/1000, Objective: -2338.288330078125\n",
      "Min step 982/1000, Objective: -2342.898681640625\n",
      "Min step 983/1000, Objective: -2347.507080078125\n",
      "Min step 984/1000, Objective: -2352.12109375\n",
      "Min step 985/1000, Objective: -2356.7412109375\n",
      "Min step 986/1000, Objective: -2361.365966796875\n",
      "Min step 987/1000, Objective: -2365.990234375\n",
      "Min step 988/1000, Objective: -2370.622314453125\n",
      "Min step 989/1000, Objective: -2375.260009765625\n",
      "Min step 990/1000, Objective: -2379.901123046875\n",
      "Min step 991/1000, Objective: -2384.5419921875\n",
      "Min step 992/1000, Objective: -2389.18798828125\n",
      "Min step 993/1000, Objective: -2393.843017578125\n",
      "Min step 994/1000, Objective: -2398.493408203125\n",
      "Min step 995/1000, Objective: -2403.150634765625\n",
      "Min step 996/1000, Objective: -2407.817138671875\n",
      "Min step 997/1000, Objective: -2412.485107421875\n",
      "Min step 998/1000, Objective: -2417.155029296875\n",
      "Min step 999/1000, Objective: -2421.83203125\n",
      "Min step 1000/1000, Objective: -2426.508056640625\n",
      "Final Objective: -2426.508056640625\n",
      "Optimized T: tensor([[ 15.3223,  15.8779,  15.4220],\n",
      "        [-15.1867, -16.7795, -15.8909]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Run optimization\n",
    "num_steps = 1000\n",
    "seed      = 42\n",
    "\n",
    "final_objective, optimized_T = optimize_min(mu_bary_L, Sigma_bary_L, mu_bary_H, Sigma_bary_H, num_steps, seed)\n",
    "\n",
    "print(f\"Final Objective: {final_objective}\")\n",
    "print(f\"Optimized T: {optimized_T}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e173d85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_U_hl_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "37af1901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_bary_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a11a091",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
