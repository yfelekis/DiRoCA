{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d1ca742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import joblib\n",
    "import pickle \n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import seaborn as sns\n",
    "import random \n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from src.CBN import CausalBayesianNetwork as CBN\n",
    "import modularised_utils as mut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "import evaluation_utils as evut\n",
    "import opt_utils as oput\n",
    "import params\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28cc3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_base = joblib.load('batteries/scms/M_WMG_bins_5_avg_2.pkl')\n",
    "M_abst = joblib.load('batteries/scms/M_LRCS_bins_5.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a46c5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base-level interventions (new style)\n",
    "iota0 = None\n",
    "iota1 = ops.Intervention({'CG': 75.})\n",
    "iota2 = ops.Intervention({'CG': 110.})\n",
    "iota3 = ops.Intervention({'CG': 180.})\n",
    "iota4 = ops.Intervention({'CG': 200.})\n",
    "\n",
    "# Abstract-level interventions (new style)\n",
    "iota0_prime = None\n",
    "iota1_prime = ops.Intervention({'CG': 75.})\n",
    "iota2_prime = ops.Intervention({'CG': 100.})\n",
    "iota3_prime = ops.Intervention({'CG': 200.})\n",
    "\n",
    "# Mapping\n",
    "omega = {\n",
    "    iota0: iota0_prime,\n",
    "    iota1: iota1_prime,\n",
    "    iota2: iota2_prime,\n",
    "    iota3: iota3_prime,\n",
    "    iota4: iota3_prime\n",
    "}\n",
    "\n",
    "Ill = list(set(omega.keys()))\n",
    "Ihl = list(set(omega.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e25336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = joblib.load('batteries/dfs/df_WMG_bins_5_avg_2.pkl')\n",
    "df_abst = joblib.load('batteries/dfs/df_LRCS_bins_5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaba6ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.drop(df_base.columns[[1,2]], axis=1, inplace=True)\n",
    "df_base.replace({75:0, 110:1, 150:2, 170:3, 180:4, 200:5}, inplace=True)\n",
    "\n",
    "df_abst.drop(df_abst.columns[[1]], axis=1, inplace=True)\n",
    "df_abst.replace({75:0, 100:1, 200:2}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "451f8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match graph\n",
    "df_base = df_base.rename(columns={\n",
    "    'binned ML_avg0': 'ML0',\n",
    "    'binned ML_avg1': 'ML1'\n",
    "})\n",
    "# Rename columns to match graph\n",
    "df_abst = df_abst.rename(columns={\n",
    "    'Comma gap (µm)': 'CG', 'binned ML': 'ML'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163802c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_coeffs = {}\n",
    "\n",
    "for child in M_base.nodes():\n",
    "    parents = M_base.get_parents(child)\n",
    "    if not parents:\n",
    "        continue  # skip root nodes\n",
    "    X = df_base[parents].values\n",
    "    y = df_base[child].values\n",
    "    coef = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    for i, parent in enumerate(parents):\n",
    "        ll_coeffs[(parent, child)] = coef[i]\n",
    "\n",
    "Gll = CBN(list(ll_coeffs.keys()))\n",
    "\n",
    "hl_coeffs = {}\n",
    "\n",
    "for child in M_abst.nodes():\n",
    "    parents = M_abst.get_parents(child)\n",
    "    if not parents:\n",
    "        continue  # skip root nodes\n",
    "    X = df_abst[parents].values\n",
    "    y = df_abst[child].values\n",
    "    coef = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    for i, parent in enumerate(parents):\n",
    "        hl_coeffs[(parent, child)] = coef[i]\n",
    "\n",
    "Ghl = CBN(list(hl_coeffs.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc918853",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = min(df_base.shape[0], df_abst.shape[0])\n",
    "df_base = df_base[:min_samples]\n",
    "df_abst = df_abst[:min_samples]\n",
    "\n",
    "df_base= df_base.to_numpy()\n",
    "df_abst= df_abst.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c72360",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_llsamples = df_base.shape[0]\n",
    "num_hlsamples = df_abst.shape[0]\n",
    "l = len(Gll.nodes())\n",
    "h = len(Ghl.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d37b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_ll_hat, mu_U_ll_hat, Sigma_U_ll_hat = mut.lan_abduction(df_base, Gll, ll_coeffs)\n",
    "U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat = mut.lan_abduction(df_abst, Ghl, hl_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed952751",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLmodels = {}\n",
    "for iota in Ill:\n",
    "    LLmodels[iota] = lanm.LinearAddSCM(Gll, ll_coeffs, iota)\n",
    "    \n",
    "HLmodels, Dhl_samples = {}, {}\n",
    "for eta in Ihl:\n",
    "    HLmodels[eta] = lanm.LinearAddSCM(Ghl, hl_coeffs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0aac533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_matrices = oput.compute_struc_matrices(LLmodels, Ill)\n",
    "H_matrices = oput.compute_struc_matrices(HLmodels, Ihl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da0a8b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_empirical_radius(N, eta, c1=1.0, c2=1.0, alpha=2.0, m=3):\n",
    "    \"\"\"\n",
    "    Compute epsilon_N(eta) for empirical Wasserstein case.\n",
    "\n",
    "    Parameters:\n",
    "    - N: int, number of samples\n",
    "    - eta: float, confidence level (0 < eta < 1)\n",
    "    - c1: float, constant from theorem (default 1.0, adjust if needed)\n",
    "    - c2: float, constant from theorem (default 1.0, adjust if needed)\n",
    "    - alpha: float, light-tail exponent (P[exp(||ξ||^α)] ≤ A)\n",
    "    - m: int, ambient dimension\n",
    "\n",
    "    Returns:\n",
    "    - epsilon: float, the concentration radius\n",
    "    \"\"\"\n",
    "    assert 0 < eta < 1, \"eta must be in (0,1)\"\n",
    "    threshold = np.log(c1 / eta) / c2\n",
    "    if N >= threshold:\n",
    "        exponent = min(1/m, 0.5)\n",
    "    else:\n",
    "        exponent = 1 / alpha\n",
    "\n",
    "    epsilon = (np.log(c1 / eta) / (c2 * N)) ** exponent\n",
    "    return epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bdb4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_bound = round(compute_empirical_radius(N=num_llsamples, eta=0.05, c1=1000.0, c2=1.0, alpha=2.0, m=l), 3)\n",
    "hl_bound = round(compute_empirical_radius(N=num_hlsamples, eta=0.05, c1=1000.0, c2=1.0, alpha=2.0, m=h), 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ae69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon, delta = ll_bound, hl_bound\n",
    "\n",
    "eta_max = 0.001\n",
    "eta_min = 0.001\n",
    "\n",
    "max_iter = 1000\n",
    "num_steps_min = 5\n",
    "num_steps_max = 5\n",
    "\n",
    "robust_L = True \n",
    "robust_H = True\n",
    "\n",
    "initialization = 'random'\n",
    "\n",
    "tol  = 1e-4\n",
    "seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "526c1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_erica = {\n",
    "                        'U_L': U_ll_hat,\n",
    "                        'U_H': U_hl_hat,\n",
    "                        'L_models': LLmodels,\n",
    "                        'H_models': HLmodels,\n",
    "                        'omega': omega,\n",
    "                        'epsilon': epsilon,\n",
    "                        'delta': delta,\n",
    "                        'eta_min': eta_min,\n",
    "                        'eta_max': eta_max,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'num_steps_max': num_steps_max,\n",
    "                        'max_iter': max_iter,\n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'robust_L': robust_L,\n",
    "                        'robust_H': robust_H,\n",
    "                        'initialization': initialization,\n",
    "                        'experiment': 'battery_discrete'\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca15028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ε=δ = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 158/1000 [00:03<00:19, 43.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 159\n",
      "Training for ε=δ = 0.537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 272/1000 [00:06<00:17, 42.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 273\n",
      "Training for ε=δ = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 266/1000 [00:05<00:15, 47.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 267\n",
      "Training for ε=δ = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 158/1000 [00:03<00:17, 46.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 159\n",
      "Training for ε=δ = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 158/1000 [00:03<00:20, 40.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 159\n",
      "\n",
      "Training completed. T matrices stored in trained_results dictionary.\n",
      "Available ε=δ values: ['T_8', 'T_0.537-0.393', 'T_1', 'T_2', 'T_4']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define different epsilon=delta values\n",
    "eps_delta_values     = [8, ll_bound, 1, 2, 4]\n",
    "diroca_train_results_empirical = {}\n",
    "\n",
    "# For each epsilon=delta value\n",
    "for eps_delta in eps_delta_values:\n",
    "    print(f\"Training for ε=δ = {eps_delta}\")\n",
    "    # Update theta parameters\n",
    "    if eps_delta == ll_bound:\n",
    "        opt_params_erica['epsilon'] = ll_bound\n",
    "        opt_params_erica['delta']   = hl_bound\n",
    "    \n",
    "    else:\n",
    "        opt_params_erica['epsilon'] = eps_delta\n",
    "        opt_params_erica['delta']   = eps_delta\n",
    "    \n",
    "    # Run ERICA optimization\n",
    "    params_empirical, T_empirical = oput.run_empirical_erica_optimization(**opt_params_erica)\n",
    "    \n",
    "    # Store results including optimization parameters and transformation matrix\n",
    "    if eps_delta == ll_bound:\n",
    "        diroca_train_results_empirical['T_'+str(ll_bound)+'-'+str(hl_bound)] = {\n",
    "                                                    'optimization_params': params_empirical,\n",
    "                                                    'T_matrix': T_empirical\n",
    "                                                }\n",
    "    else:\n",
    "        diroca_train_results_empirical['T_'+str(eps_delta)] = {\n",
    "                                                    'optimization_params': params_empirical,\n",
    "                                                    'T_matrix': T_empirical\n",
    "                                                }\n",
    "\n",
    "print(\"\\nTraining completed. T matrices stored in trained_results dictionary.\")\n",
    "print(\"Available ε=δ values:\", list(diroca_train_results_empirical.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c2b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 589.21it/s]\n"
     ]
    }
   ],
   "source": [
    "params_enrico, T_enrico = oput.run_empirical_erica_optimization(**{**opt_params_erica, 'robust_L': False, 'robust_H': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58c4424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_0.00'] = {\n",
    "                                'optimization_params': params_enrico,\n",
    "                                'T_matrix': T_enrico\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca07a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_bary = {\n",
    "                        'U_ll_hat':U_ll_hat,\n",
    "                        'U_hl_hat':U_hl_hat,\n",
    "                        'L_matrices':L_matrices,\n",
    "                        'H_matrices':H_matrices,\n",
    "                        'max_iter':max_iter,\n",
    "                        'tol':tol,\n",
    "                        'seed':seed\n",
    "                    }\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ae0e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2549.54it/s]\n"
     ]
    }
   ],
   "source": [
    "T_bary = oput.run_empirical_bary_optim(**opt_params_bary)\n",
    "params_bary = {'L':{}, 'H':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "042aeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_b'] = {\n",
    "                                'optimization_params': params_bary,\n",
    "                                'T_matrix': T_bary\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdb53936",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_smooth = {\n",
    "                        'U_L': U_ll_hat,\n",
    "                        'U_H': U_hl_hat,\n",
    "                        'L_models': LLmodels,\n",
    "                        'H_models': HLmodels,\n",
    "                        'omega': omega,\n",
    "                        'eta_min': eta_min,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'max_iter': max_iter,\n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'noise_sigma': 0.1,\n",
    "                        'num_noise_samples': 10\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e3110da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:56<00:00, 17.84it/s]\n"
     ]
    }
   ],
   "source": [
    "params_smooth, T_smooth = oput.run_empirical_smooth_optimization(**opt_params_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd9c6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_s'] = {\n",
    "                                'optimization_params': params_smooth,\n",
    "                                'T_matrix': T_smooth\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5da17060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"data/'battery_discrete'/diroca_train_results_empirical.pkl\"]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(diroca_train_results_empirical, f\"data/'battery_discrete'/diroca_train_results_empirical.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "227dc1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream_evaluation(T, df_base, df_abst):\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.model_selection import LeaveOneGroupOut\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "\n",
    "    tau_samples  = T @ df_base.T\n",
    "    abst_samples = df_abst.T\n",
    "\n",
    "    # Step 1: Transpose to get (N, dim)\n",
    "    X_real = abst_samples.T\n",
    "    X_gen  = tau_samples.T\n",
    "\n",
    "    # Step 2: Define target labels and intervention groupings\n",
    "    y = df_abst[:, 1]\n",
    "    groups = df_abst[:, 0]\n",
    "\n",
    "    assert X_real.shape[0] == len(y) == len(groups), \"Mismatch in number of samples\"\n",
    "\n",
    "    # Step 3: Combine real and generated data\n",
    "    X_all = np.concatenate([X_real, X_gen], axis=0)\n",
    "    y_all = np.concatenate([y, y], axis=0)\n",
    "    groups_all  = np.concatenate([groups, groups], axis=0)\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    # Mode 1: Real → Real\n",
    "    mse_real = []\n",
    "    for train_idx, test_idx in logo.split(X_real, y, groups=groups):\n",
    "        model = Lasso().fit(X_real[train_idx], y[train_idx])\n",
    "        y_pred = model.predict(X_real[test_idx])\n",
    "        mse_real.append(mean_squared_error(y[test_idx], y_pred))\n",
    "\n",
    "    # Mode 2: Augmented → Real\n",
    "    mse_aug = []\n",
    "    for train_idx, test_idx in logo.split(X_real, y, groups=groups):\n",
    "        model = Lasso().fit(X_gen[train_idx], y[train_idx])\n",
    "        y_pred = model.predict(X_real[test_idx])\n",
    "        mse_aug.append(mean_squared_error(y[test_idx], y_pred))\n",
    "\n",
    "    # Mode 3: Real + Augmented → Real\n",
    "    mse_mix = []\n",
    "    for test_group in np.unique(groups):\n",
    "        test_mask = (groups == test_group)\n",
    "        test_idx_real = np.where(test_mask)[0]\n",
    "\n",
    "        train_mask_real = (groups != test_group)\n",
    "        train_idx_real = np.where(train_mask_real)[0]\n",
    "        train_idx_gen = np.arange(len(y)) + len(y)\n",
    "        train_idx_all = np.concatenate([train_idx_real, train_idx_gen])\n",
    "\n",
    "        model = Lasso().fit(X_all[train_idx_all], y_all[train_idx_all])\n",
    "        y_pred = model.predict(X_real[test_idx_real])\n",
    "        mse_mix.append(mean_squared_error(y[test_idx_real], y_pred))\n",
    "\n",
    "    return {\n",
    "        \"Real\": (np.mean(mse_real), np.std(mse_real)),\n",
    "        \"Aug\": (np.mean(mse_aug), np.std(mse_aug)),\n",
    "        \"AugReal\": (np.mean(mse_mix), np.std(mse_mix))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8c3fc5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: T_8\n",
      "{'Real': (5.309079989742723, 2.7255673735214216), 'Aug': (5.55593643707483, 2.387732017528672), 'AugReal': (3.350116487661396, 2.577474204135139)}\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_0.537-0.393\n",
      "{'Real': (5.309079989742723, 2.7255673735214216), 'Aug': (5.55593643707483, 2.387732017528672), 'AugReal': (3.5333412472364345, 2.425124596371633)}\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_1\n",
      "{'Real': (5.309079989742723, 2.7255673735214216), 'Aug': (5.55593643707483, 2.387732017528672), 'AugReal': (3.5513524000111096, 2.4111322810427374)}\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_2\n",
      "{'Real': (5.309079989742723, 2.7255673735214216), 'Aug': (5.55593643707483, 2.387732017528672), 'AugReal': (3.350116487661396, 2.577474204135139)}\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_4\n",
      "{'Real': (5.309079989742723, 2.7255673735214216), 'Aug': (5.55593643707483, 2.387732017528672), 'AugReal': (3.350116487661396, 2.577474204135139)}\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_0.00\n",
      "{'Real': (5.309079989742723, 2.7255673735214216), 'Aug': (5.55593643707483, 2.387732017528672), 'AugReal': (3.339976851851852, 2.5864012673963357)}\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_b\n",
      "{'Real': (5.309079989742723, 2.7255673735214216), 'Aug': (5.55593643707483, 2.387732017528672), 'AugReal': (3.3736059979561275, 2.5569829509182944)}\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_s\n",
      "{'Real': (5.309079989742723, 2.7255673735214216), 'Aug': (5.55593643707483, 2.387732017528672), 'AugReal': (3.339976851851852, 2.5864012673963357)}\n",
      "-------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method in list(diroca_train_results_empirical.keys()):\n",
    "    print(f'Method: {method}')\n",
    "    T = diroca_train_results_empirical[method]['T_matrix']\n",
    "    d = downstream_evaluation(T, df_base, df_abst)\n",
    "    print(d)\n",
    "    print('-------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e2b89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ddd87e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "436efafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream_evaluation_with_noise(T, df_base, df_abst, noise_level=0.1, noise_in='base'):\n",
    "    \"\"\"\n",
    "    Evaluate abstraction robustness with added noise.\n",
    "\n",
    "    Args:\n",
    "        T (np.ndarray): transformation matrix (h, d)\n",
    "        df_base (np.ndarray): base-level data (N, d)\n",
    "        df_abst (np.ndarray): abstract-level data (N, >=2) [0: group, 1: label, 2+: features]\n",
    "        noise_level (float): standard deviation of Gaussian noise\n",
    "        noise_in (str): where to add noise: 'base', 'both', or 'abst'\n",
    "\n",
    "    Returns:\n",
    "        dict: evaluation results (mean ± std for each mode)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Copy inputs\n",
    "    df_base_noisy = df_base.copy()\n",
    "    df_abst_noisy = df_abst.copy()\n",
    "    df_abst_noisy = df_abst_noisy.astype(float)\n",
    "\n",
    "\n",
    "    if noise_in in ['base', 'both']:\n",
    "        df_base_noisy += np.random.normal(0, noise_level, df_base.shape)\n",
    "\n",
    "    if noise_in in ['abst', 'both']:\n",
    "        df_abst_noisy += np.random.normal(0, noise_level, df_abst.shape)\n",
    "\n",
    "    # Generate transformed and real abstract samples\n",
    "    tau_samples  = T @ df_base_noisy.T\n",
    "    #abst_samples = df_abst_noisy[:, 2:].T\n",
    "    abst_samples = df_abst_noisy.T\n",
    "\n",
    "\n",
    "    X_real = abst_samples.T\n",
    "    X_gen  = tau_samples.T\n",
    "    \n",
    "    y = df_abst_noisy[:, 1]\n",
    "    groups = df_abst_noisy[:, 0]\n",
    "\n",
    "    assert X_real.shape[0] == len(y) == len(groups), \"Mismatch in sample counts\"\n",
    "\n",
    "    X_all = np.concatenate([X_real, X_gen], axis=0)\n",
    "    y_all = np.concatenate([y, y], axis=0)\n",
    "    groups_all = np.concatenate([groups, groups], axis=0)\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    # Mode 1: Real → Real\n",
    "    mse_real = []\n",
    "    for train_idx, test_idx in logo.split(X_real, y, groups=groups):\n",
    "        model = Lasso().fit(X_real[train_idx], y[train_idx])\n",
    "        y_pred = model.predict(X_real[test_idx])\n",
    "        mse_real.append(mean_squared_error(y[test_idx], y_pred))\n",
    "\n",
    "    # Mode 2: Augmented → Real\n",
    "    mse_aug = []\n",
    "    for train_idx, test_idx in logo.split(X_real, y, groups=groups):\n",
    "        model = Lasso().fit(X_gen[train_idx], y[train_idx])\n",
    "        y_pred = model.predict(X_real[test_idx])\n",
    "        mse_aug.append(mean_squared_error(y[test_idx], y_pred))\n",
    "\n",
    "    # Mode 3: Real + Augmented → Real\n",
    "    mse_mix = []\n",
    "    for test_group in np.unique(groups):\n",
    "        test_mask = (groups == test_group)\n",
    "        test_idx_real = np.where(test_mask)[0]\n",
    "\n",
    "        train_mask_real = (groups != test_group)\n",
    "        train_idx_real = np.where(train_mask_real)[0]\n",
    "        train_idx_gen = np.arange(len(y)) + len(y)\n",
    "        train_idx_all = np.concatenate([train_idx_real, train_idx_gen])\n",
    "\n",
    "        model = Lasso().fit(X_all[train_idx_all], y_all[train_idx_all])\n",
    "        y_pred = model.predict(X_real[test_idx_real])\n",
    "        mse_mix.append(mean_squared_error(y[test_idx_real], y_pred))\n",
    "\n",
    "    return {\n",
    "        \"Real\": (np.mean(mse_real), np.std(mse_real)),\n",
    "        \"Aug\": (np.mean(mse_aug), np.std(mse_aug)),\n",
    "        \"AugReal\": (np.mean(mse_mix), np.std(mse_mix))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ead46a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: T_8\n",
      "(1.3246280648705357, 1.9357229836589438)\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_0.537-0.393\n",
      "(1.4662915245116084, 2.235598606696959)\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_1\n",
      "(1.3204628707649662, 2.0077542145624254)\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_2\n",
      "(1.3596850290595017, 2.001499776578738)\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_4\n",
      "(1.36985055408596, 1.999388245161991)\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_0.00\n",
      "(1.4314357777070637, 2.257912829013462)\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_b\n",
      "(1.3947828570843153, 2.007051436628062)\n",
      "-------------------------------- \n",
      "\n",
      "Method: T_s\n",
      "(1.3426993754464802, 2.184303951144872)\n",
      "-------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for method in list(diroca_train_results_empirical.keys()):\n",
    "    print(f'Method: {method}')\n",
    "    T = diroca_train_results_empirical[method]['T_matrix']\n",
    "    d = downstream_evaluation_with_noise(T, df_base, df_abst, noise_level=0.2, noise_in='both')\n",
    "\n",
    "    print(d['AugReal'])\n",
    "    print('-------------------------------- \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e941e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cff6b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_frobenius_ball(params, radius_type, boundary, rand_rad):\n",
    "    \"\"\"\n",
    "    Initialize a matrix inside the Frobenius ball with ||X||_F^2 <= N*epsilon^2\n",
    "    \"\"\"\n",
    "    num_samples, num_vars = params['pert_U'].shape\n",
    "    if radius_type == 'worst_case':\n",
    "        radius = params['radius_worst']\n",
    "\n",
    "    elif radius_type == 'hat_case':\n",
    "        radius = params['radius']\n",
    "\n",
    "    elif radius_type == 'random':\n",
    "        radius = rand_rad\n",
    "        \n",
    "    matrix           = np.random.randn(num_samples, num_vars)  \n",
    "    squared_norm     = np.linalg.norm(matrix, 'fro')**2\n",
    "    max_squared_norm = num_samples * radius**2\n",
    "    \n",
    "    if boundary == True:\n",
    "        scaling_factor = np.sqrt(max_squared_norm / squared_norm) * np.random.rand(1)\n",
    "    else:\n",
    "        scaling_factor = np.sqrt(max_squared_norm / squared_norm)\n",
    "    return matrix * scaling_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "adb73c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pertubation(pert_type, pert_level, experiment, rad=None):\n",
    "    \n",
    "    params = load_empirical_optimization_params(experiment, pert_level)\n",
    "    \n",
    "    if pert_type == 'sample_radius':\n",
    "        P = sample_from_frobenius_ball(params, 'hat_case', boundary=False, rand_rad=rad)\n",
    "    \n",
    "    elif pert_type == 'sample_radius_worst':\n",
    "        P = sample_from_frobenius_ball(params, 'worst_case', boundary=False, rand_rad=rad)\n",
    "\n",
    "    elif pert_type == 'boundary_worst':\n",
    "        P = params['pert_U']\n",
    "        \n",
    "    elif pert_type == 'boundary_hat':\n",
    "        P = sample_from_frobenius_ball(params, 'hat_case', boundary=True, rand_rad=rad)\n",
    "\n",
    "    elif pert_type == 'random_hat':\n",
    "        P = sample_from_frobenius_ball(params, 'hat_case', boundary=False, rand_rad=rad)\n",
    "\n",
    "    elif pert_type == 'random_worst':\n",
    "        P = sample_from_frobenius_ball(params, 'worst_case', boundary=False, rand_rad=rad)\n",
    "\n",
    "    elif pert_type == 'boundary_random_hat':\n",
    "        P = sample_from_frobenius_ball(params, 'hat_case', boundary=True, rand_rad=rad)\n",
    "\n",
    "    elif pert_type == 'boundary_random_worst':\n",
    "        P = sample_from_frobenius_ball(params, 'worst_case', boundary=True, rand_rad=rad)\n",
    "\n",
    "    elif pert_type == 'random_normal':\n",
    "        P = np.random.randn(*params['pert_U'].shape)\n",
    "\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f3ee78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream_evaluation_with_structured_noise(\n",
    "    T, df_base, df_abst,\n",
    "    noise_type='gaussian',  # or 'frobenius'\n",
    "    noise_level=0.1,\n",
    "    noise_in='base',  # 'base', 'abst', or 'both'\n",
    "    pert_type=None,\n",
    "    experiment=None,\n",
    "    radius_L=None,\n",
    "    radius_H=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Evaluate abstraction robustness with either Gaussian or Frobenius-ball structured noise.\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.linear_model import Lasso\n",
    "    from sklearn.model_selection import LeaveOneGroupOut\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "\n",
    "    df_base_noisy = df_base.copy().astype(float)\n",
    "    df_abst_noisy = df_abst.copy().astype(float)\n",
    "\n",
    "    if noise_type == 'gaussian':\n",
    "        if noise_in in ['base', 'both']:\n",
    "            df_base_noisy += np.random.normal(0, noise_level, df_base.shape)\n",
    "        if noise_in in ['abst', 'both']:\n",
    "            df_abst_noisy += np.random.normal(0, noise_level, df_abst.shape)\n",
    "\n",
    "    elif noise_type == 'frobenius':\n",
    "\n",
    "        if noise_in in ['base', 'both']:\n",
    "            assert pert_type is not None and experiment is not None\n",
    "            pert_L = generate_pertubation(pert_type, 'L', experiment, rad=radius_L)\n",
    "            df_base_noisy += pert_L\n",
    "        if noise_in in ['abst', 'both']:\n",
    "            assert pert_type is not None and experiment is not None\n",
    "            pert_H = generate_pertubation(pert_type, 'H', experiment, rad=radius_H)\n",
    "            df_abst_noisy += pert_H\n",
    "\n",
    "    tau_samples = T @ df_base_noisy.T\n",
    "    abst_samples = df_abst_noisy.T\n",
    "\n",
    "    X_real = abst_samples.T\n",
    "    X_gen = tau_samples.T\n",
    "\n",
    "    y = df_abst_noisy[:, 1]\n",
    "    groups = df_abst_noisy[:, 0]\n",
    "\n",
    "    assert X_real.shape[0] == len(y) == len(groups), \"Mismatch in sample counts\"\n",
    "\n",
    "    X_all = np.concatenate([X_real, X_gen], axis=0)\n",
    "    y_all = np.concatenate([y, y], axis=0)\n",
    "    groups_all = np.concatenate([groups, groups], axis=0)\n",
    "\n",
    "    logo = LeaveOneGroupOut()\n",
    "\n",
    "    mse_real = []\n",
    "    for train_idx, test_idx in logo.split(X_real, y, groups=groups):\n",
    "        model = Lasso().fit(X_real[train_idx], y[train_idx])\n",
    "        y_pred = model.predict(X_real[test_idx])\n",
    "        mse_real.append(mean_squared_error(y[test_idx], y_pred))\n",
    "\n",
    "    mse_aug = []\n",
    "    for train_idx, test_idx in logo.split(X_real, y, groups=groups):\n",
    "        model = Lasso().fit(X_gen[train_idx], y[train_idx])\n",
    "        y_pred = model.predict(X_real[test_idx])\n",
    "        mse_aug.append(mean_squared_error(y[test_idx], y_pred))\n",
    "\n",
    "    mse_mix = []\n",
    "    for test_group in np.unique(groups):\n",
    "        test_mask = (groups == test_group)\n",
    "        test_idx_real = np.where(test_mask)[0]\n",
    "\n",
    "        train_mask_real = (groups != test_group)\n",
    "        train_idx_real = np.where(train_mask_real)[0]\n",
    "        train_idx_gen = np.arange(len(y)) + len(y)\n",
    "        train_idx_all = np.concatenate([train_idx_real, train_idx_gen])\n",
    "\n",
    "        model = Lasso().fit(X_all[train_idx_all], y_all[train_idx_all])\n",
    "        y_pred = model.predict(X_real[test_idx_real])\n",
    "        mse_mix.append(mean_squared_error(y[test_idx_real], y_pred))\n",
    "\n",
    "    return {\n",
    "        \"Real→Real\": (np.mean(mse_real), np.std(mse_real)),\n",
    "        \"Aug→Real\": (np.mean(mse_aug), np.std(mse_aug)),\n",
    "        \"Real+Aug→Real\": (np.mean(mse_mix), np.std(mse_mix))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "29e50549",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_empirical_optimization_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[119], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m downstream_evaluation_with_structured_noise(T, df_base, df_abst, noise_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgaussian\u001b[39m\u001b[38;5;124m'\u001b[39m, noise_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, noise_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Frobenius-ball structured noise (requires experiment + params)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m downstream_evaluation_with_structured_noise(\n\u001b[1;32m      6\u001b[0m     T, df_base, df_abst,\n\u001b[1;32m      7\u001b[0m     noise_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrobenius\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     noise_in\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     pert_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_worst\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m     experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMyExperiment\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     radius_L\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     12\u001b[0m     radius_H\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     13\u001b[0m )\n",
      "Cell \u001b[0;32mIn[118], line 33\u001b[0m, in \u001b[0;36mdownstream_evaluation_with_structured_noise\u001b[0;34m(T, df_base, df_abst, noise_type, noise_level, noise_in, pert_type, experiment, radius_L, radius_H)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m noise_in \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m pert_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     pert_L \u001b[38;5;241m=\u001b[39m generate_pertubation(pert_type, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m'\u001b[39m, experiment, rad\u001b[38;5;241m=\u001b[39mradius_L)\n\u001b[1;32m     34\u001b[0m     df_base_noisy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pert_L\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m noise_in \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabst\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "Cell \u001b[0;32mIn[115], line 3\u001b[0m, in \u001b[0;36mgenerate_pertubation\u001b[0;34m(pert_type, pert_level, experiment, rad)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_pertubation\u001b[39m(pert_type, pert_level, experiment, rad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 3\u001b[0m     params \u001b[38;5;241m=\u001b[39m load_empirical_optimization_params(experiment, pert_level)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pert_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_radius\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m         P \u001b[38;5;241m=\u001b[39m sample_from_frobenius_ball(params, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhat_case\u001b[39m\u001b[38;5;124m'\u001b[39m, boundary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rand_rad\u001b[38;5;241m=\u001b[39mrad)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_empirical_optimization_params' is not defined"
     ]
    }
   ],
   "source": [
    "# Gaussian noise in base-level only\n",
    "downstream_evaluation_with_structured_noise(T, df_base, df_abst, noise_type='gaussian', noise_level=0.5, noise_in='base')\n",
    "\n",
    "# Frobenius-ball structured noise (requires experiment + params)\n",
    "downstream_evaluation_with_structured_noise(\n",
    "    T, df_base, df_abst,\n",
    "    noise_type='frobenius',\n",
    "    noise_in='both',\n",
    "    pert_type='random_worst',\n",
    "    experiment='MyExperiment',\n",
    "    radius_L=3,\n",
    "    radius_H=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83169eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
