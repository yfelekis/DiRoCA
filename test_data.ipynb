{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ac483de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[KeOps] Warning : There were warnings or errors :\n",
      "/bin/sh: brew: command not found\n",
      "\n",
      "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "# Make sure your 'models' and 'utilities' files are in the same directory\n",
    "# or in a path that Python can find.\n",
    "from models import LinearAddSCM, NonlinearAddSCM, CausalBayesianNetwork, Intervention\n",
    "import utilities as ut\n",
    "\n",
    "def create_intervention(spec):\n",
    "    \"\"\"Helper to create Intervention objects from the config definitions.\"\"\"\n",
    "    if spec is None or spec == 'None':\n",
    "        return None\n",
    "    return Intervention(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e23b55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration for experiment 'lilucas' loaded successfully.\n",
      "Model type: linear_anm\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load and Unpack Configuration ---\n",
    "\n",
    "# Specify the path to your configuration file\n",
    "config_path = 'configs/lilucas_config.yaml'\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "np.random.seed(config['seed'])\n",
    "\n",
    "# Unpack main config parameters\n",
    "experiment = config['experiment_name']\n",
    "model_type = config['model_type']\n",
    "ll_config = config['low_level_model']\n",
    "hl_config = config['high_level_model']\n",
    "abs_config = config['abstraction']\n",
    "num_llsamples = config['num_llsamples']\n",
    "num_hlsamples = config['num_hlsamples']\n",
    "\n",
    "print(f\"Configuration for experiment '{experiment}' loaded successfully.\")\n",
    "print(f\"Model type: {model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e1c3698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating data for linear_anm model: lilucas ---\n",
      "✓ Linear low-level sampling complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Low-Level Model Setup & Sampling ---\n",
    "\n",
    "print(f\"--- Generating data for {model_type} model: {experiment} ---\")\n",
    "\n",
    "# Initialize containers for data and noise\n",
    "Dll_samples, Dll_noise = {}, {}\n",
    "ll_causal_graph = None\n",
    "\n",
    "# Get shared noise parameters\n",
    "ll_mu_hat = np.array(ll_config['noise_params']['mu'])\n",
    "ll_Sigma_hat = np.diag(ll_config['noise_params']['sigma_diag'])\n",
    "\n",
    "# Create intervention objects and map\n",
    "interventions = {name: create_intervention(spec) for name, spec in abs_config.get('interventions', {}).items()}\n",
    "omega = {interventions[ll_name]: interventions[hl_name] for ll_name, hl_name in abs_config.get('omega_map', {}).items()}\n",
    "Ill_relevant = list(set(omega.keys()))\n",
    "\n",
    "if model_type == 'linear_anm':\n",
    "    ll_coeffs_list = ll_config['coefficients']\n",
    "    ll_endogenous_coeff_dict = {tuple(item[0]): item[1] for item in ll_coeffs_list}\n",
    "    ll_causal_graph = CausalBayesianNetwork(list(ll_endogenous_coeff_dict.keys()))\n",
    "    \n",
    "    for iota in Ill_relevant:\n",
    "        llcm = LinearAddSCM(ll_causal_graph, ll_endogenous_coeff_dict, iota)\n",
    "        noise = np.random.multivariate_normal(mean=ll_mu_hat, cov=ll_Sigma_hat, size=num_llsamples)\n",
    "        Dll_noise[iota] = noise\n",
    "        Dll_samples[iota] = llcm.simulate(Dll_noise[iota])\n",
    "    print(\"✓ Linear low-level sampling complete.\")\n",
    "\n",
    "elif model_type == 'continuous_nonlinear_anm':\n",
    "    ll_causal_graph = CausalBayesianNetwork(ll_config['graph_edges'])\n",
    "    safe_eval_scope = {'np': np} \n",
    "    functions = {var: eval(func_str, safe_eval_scope) for var, func_str in ll_config['structural_functions'].items()}\n",
    "\n",
    "    for iota in Ill_relevant:\n",
    "        llcm = NonlinearAddSCM(ll_causal_graph, functions, iota)\n",
    "        noise = np.random.multivariate_normal(mean=ll_mu_hat, cov=ll_Sigma_hat, size=num_llsamples)\n",
    "        Dll_noise[iota] = noise\n",
    "        Dll_samples[iota] = llcm.simulate(Dll_noise[iota])\n",
    "    print(\"✓ Non-linear low-level sampling complete.\")\n",
    "\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model_type in config: {model_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380f3f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ High-level model inferred.\n",
      "✓ High-level sampling complete.\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Abstraction & High-Level Model Inference ---\n",
    "\n",
    "hl_initial_coeff_dict = {tuple(item[0]): item[1] for item in hl_config['initial_coefficients']}\n",
    "hl_causal_graph = CausalBayesianNetwork(list(hl_initial_coeff_dict.keys()))\n",
    "\n",
    "# The set of relevant high-level interventions\n",
    "Ihl_relevant = list(set(omega.values()))\n",
    "\n",
    "# Apply the abstraction to get observational HL data\n",
    "T = np.array(abs_config['T_matrix'])\n",
    "data_observational_hl = Dll_samples[None] @ T.T\n",
    "\n",
    "# Infer HL model coefficients and noise from the abstracted data\n",
    "hl_endogenous_coeff_dict, U_hl = ut.get_coefficients(data_observational_hl, hl_causal_graph, return_noise=True)\n",
    "hl_mu_hat = np.mean(U_hl, axis=0)\n",
    "hl_Sigma_hat = np.diag(np.var(U_hl, axis=0))\n",
    "print(\"✓ High-level model inferred.\")\n",
    "\n",
    "# --- 4. High-Level Sampling ---\n",
    "Dhl_samples, Dhl_noise = {}, {}\n",
    "for eta in Ihl_relevant:\n",
    "    if eta is not None:\n",
    "        hlcm = LinearAddSCM(hl_causal_graph, hl_endogenous_coeff_dict, eta)\n",
    "        Dhl_noise[eta] = np.random.multivariate_normal(mean=hl_mu_hat, cov=hl_Sigma_hat, size=num_hlsamples)\n",
    "        Dhl_samples[eta] = hlcm.simulate(Dhl_noise[eta])\n",
    "    else: # Observational case\n",
    "        Dhl_noise[eta] = U_hl\n",
    "        Dhl_samples[eta] = data_observational_hl\n",
    "print(\"✓ High-level sampling complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e121ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Package and Save the Data ---\n",
    "\n",
    "# Create SCM model instances for saving\n",
    "if model_type == 'linear_anm':\n",
    "    LLmodels = {iota: LinearAddSCM(ll_causal_graph, ll_endogenous_coeff_dict, iota) for iota in Ill_relevant}\n",
    "    HLmodels = {eta: LinearAddSCM(hl_causal_graph, hl_endogenous_coeff_dict, eta) for eta in Ihl_relevant}\n",
    "elif model_type == 'continuous_nonlinear_anm':\n",
    "    LLmodels = {iota: NonlinearAddSCM(ll_causal_graph, functions, iota) for iota in Ill_relevant}\n",
    "    HLmodels = {eta: LinearAddSCM(hl_causal_graph, hl_endogenous_coeff_dict, eta) for eta in Ihl_relevant}\n",
    "\n",
    "# Package LL model results\n",
    "LLmodel = {\n",
    "    'graph': ll_causal_graph, 'intervention_set': Ill_relevant,\n",
    "    'noise_dist': {'mu': ll_mu_hat, 'sigma': ll_Sigma_hat}, 'data': Dll_samples,\n",
    "    'scm_instances': LLmodels, 'noise': Dll_noise\n",
    "}\n",
    "if model_type == 'linear_anm':\n",
    "    LLmodel['coeffs'] = {tuple(item[0]): item[1] for item in ll_config['coefficients']}\n",
    "elif model_type == 'continuous_nonlinear_anm':\n",
    "    LLmodel['functions'] = ll_config['structural_functions']\n",
    "\n",
    "# Package HL model results\n",
    "HLmodel = {\n",
    "    'graph': hl_causal_graph, 'intervention_set': Ihl_relevant, 'coeffs': hl_endogenous_coeff_dict,\n",
    "    'noise_dist': {'mu': hl_mu_hat, 'sigma': hl_Sigma_hat}, 'data': Dhl_samples,\n",
    "    'scm_instances': HLmodels, 'noise': Dhl_noise\n",
    "}\n",
    "\n",
    "# Package abstraction data\n",
    "abstraction_data = {'T': T, 'omega': omega}\n",
    "\n",
    "# # Define save path and create directory\n",
    "# path = f\"data/{experiment}\"\n",
    "# os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# # Save files\n",
    "# joblib.dump(LLmodel, f\"{path}/LLmodel.pkl\")\n",
    "# joblib.dump(HLmodel, f\"{path}/HLmodel.pkl\")\n",
    "# joblib.dump(abstraction_data, f\"{path}/abstraction_data.pkl\")\n",
    "\n",
    "# print(f\"✓ Data saved successfully to {path}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f9c777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40546106,  1.24453144, -0.45683386,  1.04889911, -0.63583581,\n",
       "         1.65775053],\n",
       "       [ 0.34753562, -0.32013581,  0.15567814, -0.92655593, -0.35468084,\n",
       "        -1.87339703],\n",
       "       [ 1.6001979 ,  0.30434081,  1.78249075,  2.64308345,  2.30183702,\n",
       "         4.69729223],\n",
       "       ...,\n",
       "       [-0.23311753,  0.78759165,  0.70520622,  1.53486053,  0.94908158,\n",
       "         2.07418142],\n",
       "       [-1.0859671 ,  1.06390896, -0.94316974,  0.34968928, -0.18103679,\n",
       "         1.0683677 ],\n",
       "       [-1.25025069,  1.45092703, -0.0950871 , -0.52694629, -0.42468992,\n",
       "        -0.98621291]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLmodel['data'][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a5e7d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.40546106,  1.24453144, -0.45683386,  1.04889911, -0.63583581,\n",
       "         1.65775053],\n",
       "       [ 0.34753562, -0.32013581,  0.15567814, -0.92655593, -0.35468084,\n",
       "        -1.87339703],\n",
       "       [ 1.6001979 ,  0.30434081,  1.78249075,  2.64308345,  2.30183702,\n",
       "         4.69729223],\n",
       "       ...,\n",
       "       [-0.23311753,  0.78759165,  0.70520622,  1.53486053,  0.94908158,\n",
       "         2.07418142],\n",
       "       [-1.0859671 ,  1.06390896, -0.94316974,  0.34968928, -0.18103679,\n",
       "         1.0683677 ],\n",
       "       [-1.25025069,  1.45092703, -0.0950871 , -0.52694629, -0.42468992,\n",
       "        -0.98621291]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLmodel['data'][None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06409379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
