{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1ca742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import joblib\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import product\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Local modules\n",
    "import modularised_utils as mut\n",
    "import opt_utils as oput\n",
    "import evaluation_utils as evut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "import params\n",
    "from src.CBN import CausalBayesianNetwork as CBN\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe511603",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'battery_discrete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47b1fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_results_emp = joblib.load(f\"data/{experiment}/diroca_train_results_empirical.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cccbb0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_estimation = False\n",
    "\n",
    "Dll_obs = joblib.load(f\"data/{experiment}/df_base_test.pkl\").to_numpy() \n",
    "Dhl_obs = joblib.load(f\"data/{experiment}/df_abst_test.pkl\").to_numpy() \n",
    "\n",
    "LLmodels = joblib.load(f\"data/{experiment}/LLmodels.pkl\")\n",
    "HLmodels = joblib.load(f\"data/{experiment}/HLmodels.pkl\")\n",
    "\n",
    "Gll, Ill = mut.load_model(experiment, 'LL')\n",
    "Ghl, Ihl = mut.load_model(experiment, 'HL')\n",
    "\n",
    "n_varsll, n_varshl = len(Gll.nodes()), len(Ghl.nodes())\n",
    "\n",
    "omega    = mut.load_omega_map(experiment)\n",
    "\n",
    "if coeff_estimation == True:\n",
    "    ll_coeffs = mut.get_coefficients(Dll_obs, Gll)\n",
    "    hl_coeffs = mut.get_coefficients(Dhl_obs, Ghl) \n",
    "else:\n",
    "    ll_coeffs = mut.load_coeffs(experiment, 'LL')\n",
    "    hl_coeffs = mut.load_coeffs(experiment, 'HL')\n",
    "\n",
    "U_ll_hat, mu_U_ll_hat, Sigma_U_ll_hat = mut.lan_abduction(Dll_obs, Gll, ll_coeffs)\n",
    "U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat = mut.lan_abduction(Dhl_obs, Ghl, hl_coeffs)\n",
    "\n",
    "num_llsamples, l = U_ll_hat.shape\n",
    "num_hlsamples, h = U_hl_hat.shape\n",
    "min_samples = min(num_llsamples, num_hlsamples)\n",
    "\n",
    "U_ll_hat = U_ll_hat[:min_samples]\n",
    "U_hl_hat = U_hl_hat[:min_samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7790261",
   "metadata": {},
   "source": [
    "### 0-shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0814c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_single = {method: {'errors': [], 'mean': 0, 'ci': 0} for method in T_results_emp.keys()}\n",
    "\n",
    "for name, method_data in T_results_emp.items():\n",
    "    T = method_data['T_matrix']\n",
    "    errors = []  # Store errors for each intervention\n",
    "    scale_factor = 1/np.sqrt(len(Ill))\n",
    "\n",
    "    for iota in Ill:\n",
    "        L_i = LLmodels[iota].F\n",
    "        H_i = HLmodels[omega[iota]].F\n",
    "        if iota is not None:\n",
    "            D_l = L_i @ evut.mod_noise(U_ll_hat, iota).T\n",
    "            D_h = H_i @ evut.mod_noise(U_hl_hat, omega[iota]).T\n",
    "        else:\n",
    "            D_l = L_i @ U_ll_hat.T\n",
    "            D_h = H_i @ U_hl_hat.T\n",
    "        \n",
    "        base_norm = D_l \n",
    "        abst_norm = D_h \n",
    "        \n",
    "        tau_base = T @ base_norm\n",
    "        dist = evut.compute_empirical_distance(tau_base, abst_norm, 'fro')\n",
    "        errors.append(dist)  \n",
    "\n",
    "    # Calculate mean and CI\n",
    "    mean_error = np.mean(errors)\n",
    "    std_error = np.std(errors)\n",
    "    ci = std_error\n",
    "\n",
    "    # Store all statistics\n",
    "    results_single[name] = {\n",
    "        'errors': errors,\n",
    "        'mean': mean_error,\n",
    "        'ci': ci\n",
    "    }\n",
    "\n",
    "# Scale the final results\n",
    "max_mean = max(v['mean'] for v in results_single.values())\n",
    "scale_factor = 1/max_mean\n",
    "\n",
    "results_single = dict(sorted(results_single.items(), key=lambda x: x[1]['mean']))\n",
    "\n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"{'Method':<15} {'Error (mean ± CI)':<35}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for method, stats in results_single.items():\n",
    "    print(f\"{method:<15} {stats['mean']:>8.4f} ± {stats['ci']:<8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7fe65",
   "metadata": {},
   "source": [
    "### ρ-shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "315d0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_values   = np.arange(0.05, 10.05, 2.5).tolist()  \n",
    "sample_forms = ['sample']\n",
    "\n",
    "hat_dict = {'L': U_ll_hat, 'H': U_hl_hat}\n",
    "worst = 'T_8'\n",
    "\n",
    "U_worst_L = T_results_emp[worst]['optimization_params']['L']['pert_U']\n",
    "U_worst_H = T_results_emp[worst]['optimization_params']['H']['pert_U']\n",
    "\n",
    "target_samplesL = U_ll_hat.shape[0]\n",
    "target_samplesH = U_hl_hat.shape[0]\n",
    "\n",
    "indicesL = np.random.choice(U_worst_L.shape[0], size=target_samplesL, replace=False)\n",
    "indicesH = np.random.choice(U_worst_H.shape[0], size=target_samplesH, replace=False)\n",
    "\n",
    "U_worst_L = U_worst_L[indicesL]\n",
    "U_worst_H = U_worst_H[indicesH]\n",
    "\n",
    "worst_dict = {'L': U_worst_L, 'H': U_worst_H}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afeaf54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "center = 'hat'\n",
    "if center == 'hat':\n",
    "    center_matrix = hat_dict\n",
    "elif center == 'worst':\n",
    "    center_matrix = worst_dict\n",
    "\n",
    "coverage_type='uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "588eab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate perturbation families\n",
    "pert_family_L = evut.generate_perturbation_family(\n",
    "    np.zeros_like(hat_dict['L']),\n",
    "    k=100,  # Number of perturbations\n",
    "    r_mu=0.0,\n",
    "    r_sigma=1.0,\n",
    "    coverage=coverage_type\n",
    ")\n",
    "\n",
    "pert_family_H = evut.generate_perturbation_family(\n",
    "    np.zeros_like(hat_dict['H']),\n",
    "    k=100,\n",
    "    r_mu=0.0,\n",
    "    r_sigma=1.0,\n",
    "    coverage=coverage_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c2c69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize results structure to store individual distances\n",
    "results = {\n",
    "    sample_form: {\n",
    "        'empirical': {method: [] for method in T_results_emp.keys()}\n",
    "    } for sample_form in sample_forms\n",
    "}\n",
    "\n",
    "for pert_L, pert_H in zip(pert_family_L, pert_family_H):\n",
    "    for sample_form in sample_forms:\n",
    "        for name, method_data in T_results_emp.items():\n",
    "            T = method_data['T_matrix']\n",
    "            \n",
    "            # Store individual distances for this perturbation\n",
    "            distances = []\n",
    "            \n",
    "            for iota in Ill:\n",
    "                L_i = LLmodels[iota].F\n",
    "                H_i = HLmodels[omega[iota]].F\n",
    "                \n",
    "                if iota is not None:\n",
    "                    D_l = L_i @ evut.mod_noise(center_matrix['L'].T + pert_L.T, iota)\n",
    "                    D_h = H_i @ evut.mod_noise(center_matrix['H'].T + pert_H.T, omega[iota])\n",
    "                else:\n",
    "                    D_l = L_i @ (center_matrix['L'].T + pert_L.T)\n",
    "                    D_h = H_i @ (center_matrix['H'].T + pert_H.T)\n",
    "                \n",
    "                base_norm = D_l \n",
    "                abst_norm = D_h \n",
    "                \n",
    "                tau_base = T @ base_norm\n",
    "                dist = evut.compute_empirical_distance(tau_base, abst_norm, 'fro')\n",
    "                distances.append(dist)\n",
    "            \n",
    "            results[sample_form]['empirical'][name].extend(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a553a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"{'Rank':<5} {'Method':<15} {'Empirical Distance (mean ± CI)':<35}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for sample_form in sample_forms:\n",
    "    print(f\"\\nSample form: {sample_form}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # Calculate means and stds for all methods\n",
    "    method_stats = {}\n",
    "    for method in T_results_emp.keys():\n",
    "        distances = results[sample_form]['empirical'][method]\n",
    "        mean = np.mean(distances)\n",
    "        std = np.std(distances)\n",
    "        method_stats[method] = (mean, std)\n",
    "    \n",
    "    # Sort methods by mean error (worst to best)\n",
    "    sorted_methods = sorted(method_stats.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    \n",
    "    # Print ranked results\n",
    "    for rank, (method, (mean, std)) in enumerate(sorted_methods, 1):\n",
    "        print(f\"{rank:<5} {method:<15} \"\n",
    "              f\"{mean:>8.4f} ± {std/10:<8.4f}\")\n",
    "\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Print summary of best and worst methods\n",
    "for sample_form in sample_forms:\n",
    "    print(f\"\\nSummary for {sample_form} sampling:\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # Get sorted methods\n",
    "    method_stats = {method: (np.mean(results[sample_form]['empirical'][method]),\n",
    "                           np.std(results[sample_form]['empirical'][method]))\n",
    "                   for method in T_results_emp.keys()}\n",
    "    sorted_methods = sorted(method_stats.items(), key=lambda x: x[1][0], reverse=True)\n",
    "    \n",
    "    # Print worst and best\n",
    "    worst_method, (worst_error, worst_std) = sorted_methods[0]\n",
    "    best_method, (best_error, best_std) = sorted_methods[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1488b0df",
   "metadata": {},
   "source": [
    "# F-contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b6cd88f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contaminate_structural_matrix(M, contamination_fraction, contamination_type, num_segments=10, seed=None):\n",
    "   \"\"\"\n",
    "   Contaminates a linear transformation matrix M to break its strict linearity.\n",
    "  \n",
    "   Args:\n",
    "       M (np.ndarray): Original linear transformation matrix (n x m).\n",
    "       contamination_fraction (float): Magnitude of contamination (e.g., between 0.05 and 1.0).\n",
    "       contamination_type (str): Type of contamination to apply. Options are:\n",
    "                                 'multiplicative', 'nonlinear', or 'piecewise'.\n",
    "       num_segments (int): Number of segments for piecewise linear contamination (default: 3).\n",
    "       seed (int, optional): Random seed for reproducibility.\n",
    "      \n",
    "   Returns:\n",
    "       np.ndarray: The contaminated matrix.\n",
    "   \"\"\"\n",
    "   rng = np.random.default_rng(seed)\n",
    "   M_cont = M.copy() \n",
    "   n, m = M.shape\n",
    "\n",
    "\n",
    "   if contamination_type == \"multiplicative\":\n",
    "       # Apply element-wise multiplicative noise (preserving zeros below the main diagonal)\n",
    "       # Only perturb the upper-triangular part.\n",
    "       noise = rng.uniform(low=1.0 - contamination_fraction, high=1.0 + contamination_fraction, size=M.shape)\n",
    "       # Create a mask for the upper triangular (including diagonal)\n",
    "       mask = np.triu(np.ones_like(M))\n",
    "       M_cont = M * (1 - mask + mask * noise)\n",
    "  \n",
    "   elif contamination_type == \"nonlinear\":\n",
    "       # Apply a nonlinear function to L: for instance, add a sine-based perturbation.\n",
    "       M_cont = M + contamination_fraction * np.sin(M)\n",
    "  \n",
    "   elif contamination_type == \"piecewise\":\n",
    "       # Contaminate each row with a piecewise linear function.\n",
    "       def piecewise_contaminate_row(row, cont_frac, segments, rng):\n",
    "           n_elem = len(row)\n",
    "           # Choose random breakpoints among indices\n",
    "           if segments < 2:\n",
    "               return row  # nothing to do\n",
    "           breakpoints = np.sort(rng.integers(low=1, high=n_elem, size=segments - 1))\n",
    "           breakpoints = np.concatenate(([0], breakpoints, [n_elem]))\n",
    "           contaminated_row = np.empty_like(row)\n",
    "           # For each segment, assign a random multiplicative factor.\n",
    "           for j in range(len(breakpoints) - 1):\n",
    "               start = breakpoints[j]\n",
    "               end = breakpoints[j+1]\n",
    "               factor = 1.0 + rng.uniform(low=-cont_frac, high=cont_frac)\n",
    "               contaminated_row[start:end] = row[start:end] * factor\n",
    "           return contaminated_row\n",
    "      \n",
    "       # Apply the piecewise contamination row-by-row.\n",
    "       for i in range(n):\n",
    "           M_cont[i, :] = piecewise_contaminate_row(M[i, :], contamination_fraction, num_segments, rng)\n",
    "  \n",
    "   else:\n",
    "       raise ValueError(\"Unknown contamination type. Choose among 'multiplicative', 'nonlinear', or 'piecewise'.\")\n",
    "  \n",
    "   return M_cont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bdc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contamination levels to test\n",
    "contamination_levels = np.linspace(0.0, 1.0, 100)\n",
    "\n",
    "for cont_type in ['piecewise']:\n",
    "    print(f\"\\nContamination type: {cont_type}\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Store results for plotting\n",
    "    plot_results = {method: {'means': [], 'stds': []} for method in T_results_emp.keys()}\n",
    "\n",
    "    # Run experiment for each contamination level\n",
    "    for cont_frac in tqdm(contamination_levels):\n",
    "        abstraction_error = {name: [] for name in T_results_emp.keys()}\n",
    "        \n",
    "        for _ in range(1):  \n",
    "            for name, res in T_results_emp.items():\n",
    "                T = res['T_matrix']\n",
    "                total = 0\n",
    "                \n",
    "                for iota in Ill:\n",
    "                    L_i = LLmodels[iota].F\n",
    "                    L_i = contaminate_structural_matrix(L_i, contamination_fraction=cont_frac, contamination_type=cont_type)\n",
    "                    H_i = HLmodels[omega[iota]].F\n",
    "                    H_i = contaminate_structural_matrix(H_i, contamination_fraction=cont_frac, contamination_type=cont_type)\n",
    "                    \n",
    "                    if iota is not None:\n",
    "                        D_l = L_i @ evut.mod_noise(hat_dict['L'].T, iota)\n",
    "                        D_h = H_i @ evut.mod_noise(hat_dict['H'].T, omega[iota])\n",
    "                    else:\n",
    "                        D_l = L_i @ hat_dict['L'].T\n",
    "                        D_h = H_i @ hat_dict['H'].T\n",
    "                    \n",
    "                    # Normalize\n",
    "                    base_norm = D_l#/ np.linalg.norm(D_l, 'fro')\n",
    "                    abst_norm = D_h#/ np.linalg.norm(D_h, 'fro')\n",
    "                    \n",
    "                    tau_base = T @ base_norm\n",
    "                    dist = evut.compute_empirical_distance(tau_base, abst_norm, 'fro')\n",
    "                    d = tau_base.shape[0] * tau_base.shape[1]  # number of entries\n",
    "                    dist /= np.sqrt(d)\n",
    "                    # dist *= 100\n",
    "                    total += dist\n",
    "                \n",
    "                # Store average error for this iteration\n",
    "                iter_avg = total / len(Ill)\n",
    "                abstraction_error[name].append(iter_avg)\n",
    "        \n",
    "        # Store results for this contamination level\n",
    "        for method in T_results_emp.keys():\n",
    "            mean_e = np.mean(abstraction_error[method])\n",
    "            std_e = np.std(abstraction_error[method])\n",
    "            plot_results[method]['means'].append(mean_e)\n",
    "            plot_results[method]['stds'].append(std_e)\n",
    "\n",
    "    # Compute and print the overall averages\n",
    "    print(f\"{'Method':<15} {'Mean ± CI (95%)':<35}\")\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # Compute averages for each method\n",
    "    method_averages = []\n",
    "    for method in T_results_emp.keys():\n",
    "        mean = np.mean(plot_results[method]['means'])\n",
    "        std = np.std(plot_results[method]['means'])\n",
    "        method_averages.append((method, mean, std))\n",
    "    \n",
    "    # Sort by mean (worst to best)\n",
    "    method_averages.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Print sorted averages\n",
    "    for method, mean, std in method_averages:\n",
    "        ci = std\n",
    "        print(f\"{method:<15} {mean:>8.4f} ± {ci:<8.4f}\")\n",
    "    \n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf58723",
   "metadata": {},
   "source": [
    "### ω-contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "597a107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contaminate_omega_map(original_omega, num_misalignments):\n",
    "    \"\"\"\n",
    "    Randomly corrupt a subset of entries in the ω map to simulate mapping misspecification.\n",
    "    \n",
    "    Args:\n",
    "        original_omega (dict): Original intervention mapping.\n",
    "            For example: {None: None, iota1: H_i1, iota2: H_i1, iota3: H_i2, ...}\n",
    "        num_misalignments (int): Desired number of misaligned mappings.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A new ω mapping with up to num_misalignments entries altered.\n",
    "    \"\"\"\n",
    "    # Exclude keys or values that are None if desired.\n",
    "    omega_keys = [k for k in original_omega.keys() if k is not None]\n",
    "    omega_vals = [original_omega[k] for k in omega_keys if original_omega[k] is not None]\n",
    "    \n",
    "    # Start with a copy of the original mapping.\n",
    "    contaminated_omega = original_omega.copy()\n",
    "    \n",
    "    # Bound the number of misalignments by the number of eligible keys.\n",
    "    num_to_corrupt = min(num_misalignments, len(omega_keys))\n",
    "    \n",
    "    # Randomly select keys to corrupt.\n",
    "    to_corrupt = random.sample(omega_keys, k=num_to_corrupt)\n",
    "    \n",
    "    # Create a random permutation of available targets (ensuring change)\n",
    "    # Use the set of targets from eligible keys.\n",
    "    all_targets = list(set(omega_vals))\n",
    "    \n",
    "    for key in to_corrupt:\n",
    "        original_target = original_omega[key]\n",
    "        # Only corrupt if there's an alternative available.\n",
    "        available_targets = [t for t in all_targets if t != original_target]\n",
    "        if available_targets:\n",
    "            new_target = random.choice(available_targets)\n",
    "            contaminated_omega[key] = new_target\n",
    "            \n",
    "    return contaminated_omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1acd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define misalignment levels to test\n",
    "misalignment_levels = range(0, len(Ill))  # Test 0 to 15 misalignments\n",
    "# Store results for plotting\n",
    "omega_plot_results = {method: {'means': [], 'stds': []} for method in T_results_emp.keys()}\n",
    "\n",
    "# Run experiment for each misalignment level\n",
    "for num_mis in tqdm(misalignment_levels):\n",
    "    abstraction_error = {name: [] for name in T_results_emp.keys()}\n",
    "    \n",
    "    for _ in range(10):  # Multiple runs for each misalignment level\n",
    "        # Contaminate the omega map\n",
    "        omega_cont = contaminate_omega_map(omega, num_mis)\n",
    "        \n",
    "        \n",
    "        for name, res in T_results_emp.items():\n",
    "            T = res['T_matrix']\n",
    "            \n",
    "            total = 0\n",
    "            for iota in Ill:\n",
    "                L_i = LLmodels[iota].F\n",
    "                H_i = HLmodels[omega_cont[iota]].F\n",
    "                \n",
    "                if iota is not None:\n",
    "                    D_l = L_i @ evut.mod_noise(hat_dict['L'].T, iota)\n",
    "                    D_h = H_i @ evut.mod_noise(hat_dict['H'].T, omega_cont[iota])\n",
    "                else:\n",
    "                    D_l = L_i @ hat_dict['L'].T\n",
    "                    D_h = H_i @ hat_dict['H'].T\n",
    "                \n",
    "                # Normalize\n",
    "                base_norm = D_l #/ np.linalg.norm(D_l, 'fro')\n",
    "                abst_norm = D_h #/ np.linalg.norm(D_h, 'fro')\n",
    "                \n",
    "                tau_base = T @ base_norm\n",
    "                dist = evut.compute_empirical_distance(tau_base, abst_norm, 'fro')\n",
    "                total += dist\n",
    "            # Store average error for this iteration\n",
    "            iter_avg = total / len(Ill)\n",
    "            abstraction_error[name].append(iter_avg)\n",
    "    \n",
    "    # Store results for this misalignment level\n",
    "    for method in T_results_emp.keys():\n",
    "        mean_e = np.mean(abstraction_error[method])\n",
    "        std_e = np.std(abstraction_error[method])\n",
    "        omega_plot_results[method]['means'].append(mean_e)\n",
    "        omega_plot_results[method]['stds'].append(std_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f18a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the overall averages across all misalignment levels\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"AVERAGE ERROR ACROSS ALL OMEGA MISALIGNMENTS (EMPIRICAL)\")\n",
    "print(\"=\"*100)\n",
    "print(f\"{'Method':<15} {'Mean ± CI (95%)':<35}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Compute averages for each method\n",
    "method_averages = []\n",
    "for method in T_results_emp.keys():\n",
    "    # Get all means across misalignment levels\n",
    "    all_means = omega_plot_results[method]['means']\n",
    "    # Compute overall mean and std\n",
    "    overall_mean = np.mean(all_means)\n",
    "    overall_std = np.std(all_means)\n",
    "    method_averages.append((method, overall_mean, overall_std))\n",
    "\n",
    "# Sort methods by mean (worst to best)\n",
    "method_averages.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted averages\n",
    "for method, mean, std in method_averages:\n",
    "    ci = std\n",
    "    print(f\"{method:<15} {mean:>8.4f} ± {ci:<8.4f}\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13637e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
