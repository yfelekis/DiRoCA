{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1765d7",
   "metadata": {},
   "source": [
    "### Next steps (10/09)\n",
    "\n",
    "1. Understand difference between reduced form and adjacency matrix.\n",
    "    \n",
    "2. Sample abstraction tau T (given omega?).\n",
    "\n",
    "3. Save/Load model logic \n",
    "\n",
    "4. CVXPY implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28ac6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import joblib\n",
    "import pickle \n",
    "import os\n",
    "import cvxpy\n",
    "\n",
    "from itertools import chain, combinations\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import wishart\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.linalg import sqrtm\n",
    "from scipy.special import rel_entr\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "from src.CBN import CausalBayesianNetwork as CBN\n",
    "import modularised_utils as mut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "\n",
    "import params\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce898cd9",
   "metadata": {},
   "source": [
    "### Define low-level DCM \"LL\" and high-level DCM \"HL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0575feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'synth1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10230e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 'Smoking'\n",
    "T = 'Tar'\n",
    "C = 'Cancer'\n",
    "\n",
    "S_ = 'Smoking_'\n",
    "C_ = 'Cancer_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afb18cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_endogenous_coeff_dict = {(S, T): 0.3, (T, C): 0.2}\n",
    "ll_causal_graph          = CBN(list(ll_endogenous_coeff_dict.keys()))\n",
    "#nx.draw(nx.DiGraph(ll_causal_graph.edges()),with_labels=True)\n",
    "\n",
    "hl_endogenous_coeff_dict = {(S_, C_): 0.6}\n",
    "hl_causal_graph          = CBN(list(hl_endogenous_coeff_dict.keys()))\n",
    "#nx.draw(nx.DiGraph(hl_causal_graph.edges()),with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b57b88",
   "metadata": {},
   "source": [
    "### Construct the empirical nominal distribution/ environment\n",
    "This should be later infered from the endogenous samples (with or without abduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "942ffe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_mu_hat       = np.array([0, 0, 0])  \n",
    "ll_Sigma_hat    = np.diag([1, 2, 1]) \n",
    "\n",
    "\n",
    "hl_mu_hat       = np.array([0, 0])  \n",
    "hl_Sigma_hat    = np.diag([1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba255d",
   "metadata": {},
   "source": [
    "### Define the sets of relevant interventions and the (total) surjective and order-preserving function $Ï‰:I^{L} \\mapsto I^{H}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc02d782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iota0 = None\n",
    "iota1 = ops.Intervention({S:0})\n",
    "iota2 = ops.Intervention({S:0, T:1})\n",
    "iota3 = ops.Intervention({S:1})\n",
    "iota4 = ops.Intervention({S:1, T:0})\n",
    "iota5 = ops.Intervention({S:1, T:1})\n",
    "\n",
    "eta0 = None\n",
    "eta1 = ops.Intervention({S_:0})\n",
    "eta2 = ops.Intervention({S_:1})\n",
    "\n",
    "omega = {   \n",
    "            iota0: eta0,\n",
    "            iota1: eta1,\n",
    "            iota2: eta1,\n",
    "            iota3: eta2,\n",
    "            iota4: eta2,\n",
    "            iota5: eta2\n",
    "        }\n",
    "\n",
    "Ill_relevant = list(set(omega.keys()))\n",
    "Ihl_relevant = list(set(omega.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d71d01",
   "metadata": {},
   "source": [
    "### Construct the Ambiguity sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66c8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the radius of the Wasserstein balls (epsilon, delta) and the size for both models.\n",
    "epsilon         = params.radius[experiment][0]\n",
    "ll_num_envs     = params.n_envs[experiment][0]\n",
    "\n",
    "delta           = params.radius[experiment][1]\n",
    "hl_num_envs     = params.n_envs[experiment][1]\n",
    "\n",
    "# Define the number of samples per environment. Currently every environment has the same number of samples\n",
    "num_llsamples   = params.n_samples[experiment][0]\n",
    "num_hlsamples   = params.n_samples[experiment][1]\n",
    "\n",
    "distance_err    = 'wass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78a4d837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambiguity set construction: Based on epsilon and delta include distribution (as many as the num_envs) that\n",
    "# pass the \"gelbrich\" test.\n",
    "ll_moments = mut.sample_moments_U(mu_hat    = ll_mu_hat,\n",
    "                                  Sigma_hat = ll_Sigma_hat,\n",
    "                                  bound     = epsilon,\n",
    "                                  num_envs  = ll_num_envs)\n",
    "\n",
    "A_ll       = mut.sample_distros_Gelbrich(ll_moments) #Low-level: A_epsilon\n",
    "\n",
    "\n",
    "hl_moments = mut.sample_moments_U(mu_hat    = hl_mu_hat,\n",
    "                                  Sigma_hat = hl_Sigma_hat,\n",
    "                                  bound     = delta,\n",
    "                                  num_envs  = hl_num_envs)\n",
    "\n",
    "A_hl       = mut.sample_distros_Gelbrich(hl_moments) #High-level A_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "960324d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giofelekis/opt/anaconda3/lib/python3.9/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "abstraction_errors             = {}\n",
    "abstraction_env_errors         = {}\n",
    "max_env_avg_interv_error_value = -np.inf\n",
    "max_env_avg_interv_error_key   = None\n",
    "\n",
    "for lenv in A_ll:\n",
    "\n",
    "    Dll_noise      = lenv.sample(num_llsamples)[0]\n",
    "    ll_environment = mut.get_exogenous_distribution(Dll_noise)\n",
    "\n",
    "    LLmodels, Dll_samples = {}, {}\n",
    "    for iota in Ill_relevant:\n",
    "\n",
    "        LLmodels[iota]      = lanm.LinearAddSCM(ll_causal_graph, ll_endogenous_coeff_dict, iota)\n",
    "        Dll_samples[iota]   = LLmodels[iota].sample_settings(Dll_noise)\n",
    "\n",
    "    for henv in A_hl:\n",
    "        Dhl_noise      = henv.sample(num_hlsamples)[0]\n",
    "        hl_environment = mut.get_exogenous_distribution(Dhl_noise)\n",
    "\n",
    "        HLmodels, Dhl_samples = {}, {}\n",
    "        for eta in Ihl_relevant:\n",
    "\n",
    "            HLmodels[eta]      = lanm.LinearAddSCM(hl_causal_graph, hl_endogenous_coeff_dict, eta)\n",
    "            Dhl_samples[eta]   = HLmodels[eta].sample_settings(Dhl_noise)\n",
    "\n",
    "\n",
    "        pairs = mut.create_pairs(Ill_relevant, omega, LLmodels, HLmodels)\n",
    "\n",
    "        total_ui_error = 0\n",
    "        num_distros    = len(pairs)\n",
    "\n",
    "        n, m  = len(LLmodels[None].endogenous_vars), len(HLmodels[None].endogenous_vars)\n",
    "\n",
    "        T     = mut.sample_stoch_matrix(n, m) #np.random.rand(n, m) #sample_abstraction(LLmodels, HLmodels)\n",
    "\n",
    "        for iota in Ill_relevant:\n",
    "            llcm   = LLmodels[iota]\n",
    "            hlcm   = HLmodels[omega[iota]]\n",
    "            llmech = llcm.compute_mechanism()\n",
    "            hlmech = hlcm.compute_mechanism()\n",
    "            #error = mut.ui_error_dist(distance_err, ll_environment, hl_environment, llmech, hlmech, T)\n",
    "            error = mut.ui_error_dist(distance_err, lenv, henv, llmech, hlmech, T)\n",
    "\n",
    "            total_ui_error += error\n",
    "\n",
    "        avg_interv_error = total_ui_error/num_distros\n",
    "\n",
    "        if avg_interv_error > max_env_avg_interv_error_value:\n",
    "            max_env_avg_interv_error_value = avg_interv_error\n",
    "            max_env_avg_interv_error_key   = (lenv, henv)\n",
    "\n",
    "        abstraction_errors[str(T)] = avg_interv_error\n",
    "        abstraction_env_errors['ll: '+str(ll_environment.means_)+' hl: '+str(hl_environment.means_)] = avg_interv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce31a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstraction: [[0.27398458 0.72601542]\n",
      " [0.41617667 0.58382333]\n",
      " [0.23448161 0.76551839]], Error: 1.0887962854471707\n",
      "==============================================================================\n",
      "max LL mean vector = [[0.04438632 0.03336743 0.14940791]]\n",
      "max LL covariance = [[[0.84730977 0.         0.        ]\n",
      "  [0.         2.05596841 0.        ]\n",
      "  [0.         0.         0.85734131]]]\n",
      "\n",
      "max HL mean vector = [[-0.02051583  0.00334389]]\n",
      "max HL covariance = [[[0.96586478 0.        ]\n",
      "  [0.         0.90582224]]]\n",
      "==============================================================================\n",
      "max environment, average interventional abstraction error = 1.0887962854471707\n"
     ]
    }
   ],
   "source": [
    "max_tau   = max(abstraction_errors, key=abstraction_errors.get)\n",
    "max_error = abstraction_errors[max_tau]\n",
    "\n",
    "print(f\"Abstraction: {max_tau}, Error: {max_error}\")\n",
    "print('==============================================================================' )\n",
    "max_lenv = max_env_avg_interv_error_key[0]\n",
    "max_henv = max_env_avg_interv_error_key[1]\n",
    "\n",
    "print(f\"max LL mean vector = {max_lenv.means_}\")\n",
    "print(f\"max LL covariance = {max_lenv.covariances_}\")\n",
    "print( )\n",
    "\n",
    "print(f\"max HL mean vector = {max_henv.means_}\")\n",
    "print(f\"max HL covariance = {max_henv.covariances_}\")\n",
    "print('==============================================================================' )\n",
    "print(f\"max environment, average interventional abstraction error = {max_env_avg_interv_error_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97cb72f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3983a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstraction_errors             = {}\n",
    "abstraction_env_errors         = {}\n",
    "max_env_avg_interv_error_value = -np.inf\n",
    "max_env_avg_interv_error_key   = None\n",
    "\n",
    "for lenv in A_ll:\n",
    "\n",
    "    Dll_noise      = lenv.sample(num_llsamples)[0]\n",
    "    ll_environment = mut.get_exogenous_distribution(Dll_noise)\n",
    "\n",
    "    LLmodels, Dll_samples = {}, {}\n",
    "    for iota in Ill_relevant:\n",
    "\n",
    "        LLmodels[iota]      = lanm.LinearAddSCM(ll_causal_graph, ll_endogenous_coeff_dict, iota)\n",
    "        Dll_samples[iota]   = LLmodels[iota].sample_settings(Dll_noise)\n",
    "\n",
    "    for henv in A_hl:\n",
    "        Dhl_noise      = henv.sample(num_hlsamples)[0]\n",
    "        hl_environment = mut.get_exogenous_distribution(Dhl_noise)\n",
    "\n",
    "        HLmodels, Dhl_samples = {}, {}\n",
    "        for eta in Ihl_relevant:\n",
    "\n",
    "            HLmodels[eta]      = lanm.LinearAddSCM(hl_causal_graph, hl_endogenous_coeff_dict, eta)\n",
    "            Dhl_samples[eta]   = HLmodels[eta].sample_settings(Dhl_noise)\n",
    "\n",
    "\n",
    "        pairs = mut.create_pairs(Ill_relevant, omega, LLmodels, HLmodels)\n",
    "\n",
    "        total_i_error = 0\n",
    "        num_distros   = len(pairs)\n",
    "\n",
    "        n, m  = len(LLmodels[None].endogenous_vars), len(HLmodels[None].endogenous_vars)\n",
    "\n",
    "        T     = mut.sample_stoch_matrix(n, m) #np.random.rand(n, m) #sample_abstraction(LLmodels, HLmodels)\n",
    "\n",
    "        for iota in Ill_relevant:\n",
    "            llcm   = LLmodels[iota]\n",
    "            hlcm   = HLmodels[omega[iota]]\n",
    "            llmech = llcm.compute_mechanism()\n",
    "            hlmech = hlcm.compute_mechanism()\n",
    "            dllcm  = mut.get_endogenous_distribution(Dll_samples[iota])\n",
    "            dhlcm  = mut.get_endogenous_distribution(Dhl_samples[omega[iota]]) \n",
    "            error = mut.i_error_dist(distance_err, dllcm, dhlcm, T)\n",
    "\n",
    "            total_i_error += error\n",
    "\n",
    "        avg_interv_error = total_i_error/num_distros\n",
    "\n",
    "        if avg_interv_error > max_env_avg_interv_error_value:\n",
    "            max_env_avg_interv_error_value = avg_interv_error\n",
    "            max_env_avg_interv_error_key   = (lenv, henv)\n",
    "\n",
    "        abstraction_errors[str(T)] = avg_interv_error\n",
    "        abstraction_env_errors['ll: '+str(ll_environment.means_)+' hl: '+str(hl_environment.means_)] = avg_interv_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10be8fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstraction: [[0.00734027 0.99265973]\n",
      " [0.19427353 0.80572647]\n",
      " [0.23078559 0.76921441]], Error: 3.083806808649351\n",
      "==============================================================================\n",
      "max LL mean vector = [[0.04438632 0.03336743 0.14940791]]\n",
      "max LL covariance = [[[0.84730977 0.         0.        ]\n",
      "  [0.         2.05596841 0.        ]\n",
      "  [0.         0.         0.85734131]]]\n",
      "\n",
      "max HL mean vector = [[-0.02051583  0.00334389]]\n",
      "max HL covariance = [[[0.96586478 0.        ]\n",
      "  [0.         0.90582224]]]\n",
      "==============================================================================\n",
      "max environment, average interventional abstraction error = 3.083806808649351\n"
     ]
    }
   ],
   "source": [
    "max_tau   = max(abstraction_errors, key=abstraction_errors.get)\n",
    "max_error = abstraction_errors[max_tau]\n",
    "\n",
    "print(f\"Abstraction: {max_tau}, Error: {max_error}\")\n",
    "print('==============================================================================' )\n",
    "max_lenv = max_env_avg_interv_error_key[0]\n",
    "max_henv = max_env_avg_interv_error_key[1]\n",
    "\n",
    "print(f\"max LL mean vector = {max_lenv.means_}\")\n",
    "print(f\"max LL covariance = {max_lenv.covariances_}\")\n",
    "print( )\n",
    "\n",
    "print(f\"max HL mean vector = {max_henv.means_}\")\n",
    "print(f\"max HL covariance = {max_henv.covariances_}\")\n",
    "print('==============================================================================' )\n",
    "print(f\"max environment, average interventional abstraction error = {max_env_avg_interv_error_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f60aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
