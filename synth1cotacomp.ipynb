{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28ac6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from src.CBN import CausalBayesianNetwork as CBN\n",
    "import modularised_utils as mut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "import evaluation_utils as evut\n",
    "import params\n",
    "\n",
    "import itertools\n",
    "import joblib\n",
    "import pickle \n",
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "\n",
    "from pgmpy import inference\n",
    "\n",
    "import ot\n",
    "import ot.plot\n",
    "from ot.datasets import make_1D_gauss as gauss\n",
    "\n",
    "import scipy.optimize as optimize\n",
    "from scipy.spatial.distance import cdist, squareform, pdist\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.optimize import linprog\n",
    "from scipy import stats\n",
    "\n",
    "from collections import Counter\n",
    "from IPython.utils import io\n",
    "from cvxpy.error import SolverError\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.collections import PolyCollection\n",
    "from itertools import chain, combinations\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from pgmpy.models import BayesianNetwork as CBN\n",
    "from pgmpy.factors.discrete import TabularCPD as cpd\n",
    "\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(precision=4,suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bd8c300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46288966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# 1. Create low-level model\n",
    "M_STC = M_pgmpy_chain_STC_gaussian()\n",
    "\n",
    "# 2. Generate some samples from the low-level model\n",
    "Dll = Dll_samples[None]\n",
    "# Define the abstraction map\n",
    "Tau = np.array([[1, 2, 1],  # Maps to high-level state 1 (smoking causes cancer)\n",
    "              [0, 1, 0]]) # Maps to high-level state 0 (no smoking, no cancer)\n",
    "\n",
    "# 3. Create high-level model using the abstraction\n",
    "M_SC = M_pgmpy_chain_SC_from_data(Dll, Tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed10068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(samples, variables=None):\n",
    "    \n",
    "    if variables is None:\n",
    "        raise ValueError(\"variables must be specified\")\n",
    "        \n",
    "    df = (samples.groupby(variables).size() / samples.shape[0]).to_frame()\n",
    "    return df\n",
    "\n",
    "def df_to_dict(df):\n",
    "    d = {}\n",
    "    for mi, row in df.iterrows():\n",
    "        d[mi] = row.iloc[0]\n",
    "    return d\n",
    "\n",
    "def fillout(dict_, model):\n",
    "\n",
    "    # Determine the length of the binary tuples\n",
    "    n = len(list(dict_.keys())[0])\n",
    "    \n",
    "    # Generate all possible binary tuples of length n\n",
    "    #keys = list(itertools.product([0, 1], repeat=n))\n",
    "    cards = (np.arange(model.get_cardinality(n)) for n in model.nodes)\n",
    "    keys = list(itertools.product(*cards))\n",
    "    # Create a new dictionary with all keys from keys list and 0 as the default value\n",
    "    # If the key exists in the original dictionary, use its value instead of the default\n",
    "    \n",
    "    return {key: dict_.get(key, 0) for key in keys}\n",
    "\n",
    "\n",
    "def create_pairs(n_samples, I_relevant, omega, M_base, M_abst):\n",
    "    pairs = []\n",
    "    \n",
    "    for iota in I_relevant:\n",
    "        # Skip None values\n",
    "        with io.capture_output() as captured:\n",
    "            if iota is None or iota.intervention == {None: None}:\n",
    "                # Handle the case where there's no intervention\n",
    "                D_base = M_base.simulate(n_samples=n_samples)\n",
    "                D_abst = M_abst.simulate(n_samples=n_samples)\n",
    "            else:\n",
    "                # Get intervention variables\n",
    "                intervention_vars = iota.Phi()\n",
    "                \n",
    "                # Apply intervention to base model\n",
    "                D_base = M_base.do(intervention_vars).simulate(\n",
    "                    n_samples=n_samples, \n",
    "                    evidence=iota.vv()\n",
    "                )\n",
    "                D_abst = M_abst.do(omega[iota].Phi()).simulate(\n",
    "                    n_samples=n_samples, \n",
    "                    evidence=omega[iota].vv()\n",
    "                )\n",
    "        \n",
    "            # Get distributions\n",
    "            df_base = get_distribution(D_base, variables=list(M_base.nodes))\n",
    "            df_abst = get_distribution(D_abst, variables=list(M_abst.nodes))\n",
    "\n",
    "            p_base = fillout(df_to_dict(df_base), M_base)\n",
    "            p_abst = fillout(df_to_dict(df_abst), M_abst)\n",
    "                \n",
    "            pairs.append(ops.Pair(p_base, p_abst, iota, omega[iota]))\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09a50c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = create_pairs(num_llsamples, Ill_relevant, omega, M_STC, M_SC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6291e076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_omega_cost_matrix(pairs):\n",
    "    \n",
    "    lst_base = pairs[0].base_labels\n",
    "    lst_abst = pairs[0].abst_labels\n",
    "    df = pd.DataFrame(0, index=lst_abst, columns=lst_base)\n",
    "    print(df)\n",
    "    for pair in pairs:\n",
    "        p = pair.get_domain('base')\n",
    "        q = pair.get_domain('abst')\n",
    "        df.loc[q, p] = df.loc[q, p] - 1\n",
    "    cost_matrix = df.values.astype(float)  # convert to float array\n",
    "    \n",
    "    reg = np.abs(np.min(cost_matrix))\n",
    "    cost_matrix += reg\n",
    "    cost_matrix +=  np.ones_like(cost_matrix)\n",
    "    \n",
    "    return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ce172b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ee36f962",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_variable'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate_omega_cost_matrix(pairs, Ill_relevant)\n",
      "Cell \u001b[0;32mIn[67], line 10\u001b[0m, in \u001b[0;36mgenerate_omega_cost_matrix\u001b[0;34m(pairs, interventions)\u001b[0m\n\u001b[1;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;241m0\u001b[39m, index\u001b[38;5;241m=\u001b[39mlst_abst, columns\u001b[38;5;241m=\u001b[39mlst_base)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pair, iota \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(pairs, interventions):\n\u001b[0;32m---> 10\u001b[0m     p \u001b[38;5;241m=\u001b[39m pair\u001b[38;5;241m.\u001b[39mget_domain(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m     q \u001b[38;5;241m=\u001b[39m pair\u001b[38;5;241m.\u001b[39mget_domain(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabst\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Handle both None and {None: None} cases\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ERiCA/operations.py:186\u001b[0m, in \u001b[0;36mPair.get_domain\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    184\u001b[0m dom \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miota_base\u001b[38;5;241m.\u001b[39mget_variable() \u001b[38;5;241m==\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_labels\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_labels:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_variable'"
     ]
    }
   ],
   "source": [
    "generate_omega_cost_matrix(pairs, Ill_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e90ef865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 0),\n",
       " (0, 0, 1),\n",
       " (0, 1, 0),\n",
       " (0, 1, 1),\n",
       " (1, 0, 0),\n",
       " (1, 0, 1),\n",
       " (1, 1, 0),\n",
       " (1, 1, 1)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[0].base_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dba1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00be39dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9cb47015",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Pair' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate_omega_cost_matrix(pairs)\n",
      "Cell \u001b[0;32mIn[47], line 9\u001b[0m, in \u001b[0;36mgenerate_omega_cost_matrix\u001b[0;34m(pairs)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mGenerate cost matrix for omega mapping using the new intervention structure.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    pairs: List of tuples (df_base, df_abst) from create_pairs\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Get labels from the first pair's dataframes\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m lst_base \u001b[38;5;241m=\u001b[39m pairs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Base model variables\u001b[39;00m\n\u001b[1;32m     10\u001b[0m lst_abst \u001b[38;5;241m=\u001b[39m pairs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# Abstract model variables\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Initialize cost matrix\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Pair' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "generate_omega_cost_matrix(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d557021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Poset: \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "\n",
    "    def to_path(self, current_path):\n",
    "        path = current_path[:]\n",
    "        path.append(self)\n",
    "        return path\n",
    "    \n",
    "    def get_child(self, current_path):\n",
    "        for i in range(len(current_path) - 1):\n",
    "            if current_path[i] == self:\n",
    "                return current_path[i + 1]\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "278e2291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_chains(pairs, tree_structure):\n",
    "    \n",
    "    plans = [Poset(pair) for pair in pairs]\n",
    "    \n",
    "    # Initialize parent-child relations\n",
    "    for parent_index, child_index in tree_structure:\n",
    "        plans[parent_index].add_child(plans[child_index])\n",
    "    \n",
    "    # Initialize variables\n",
    "    paths = []\n",
    "    current_path = []\n",
    "\n",
    "    def traverse_paths(node):\n",
    "        nonlocal current_path\n",
    "\n",
    "        current_path.append(node)\n",
    "\n",
    "        if not node.children:\n",
    "            paths.append(current_path[:])\n",
    "\n",
    "        for i, child in enumerate(node.children):\n",
    "            traverse_paths(child)\n",
    "\n",
    "        current_path.pop()\n",
    "\n",
    "    # Traverse paths starting from each root node\n",
    "    for plan in plans:\n",
    "        if not any(node for node in plans if plan in node.children):\n",
    "            traverse_paths(plan)\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def drop1omega(omega, key):\n",
    "    modified_omega = omega.copy()\n",
    "    if key in modified_omega:\n",
    "        del modified_omega[key]\n",
    "    return modified_omega\n",
    "\n",
    "def interventional_order(iota_i, iota_j):\n",
    "    i_variables = set(iota_i.intervention.keys())\n",
    "    j_variables = set(iota_j.intervention.keys())\n",
    "\n",
    "    if None in i_variables and not None in j_variables:\n",
    "        return True\n",
    "    elif i_variables <= j_variables and all(iota_i.intervention[var] == iota_j.intervention[var] for var in i_variables):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def build_poset(Iota):\n",
    "    \n",
    "    edges = []\n",
    "    tree = {}\n",
    "\n",
    "    for i in Iota:\n",
    "        tree[i] = []\n",
    "    \n",
    "    for i in range(len(Iota)):\n",
    "        for j in range(i + 1, len(Iota)):\n",
    "            if interventional_order(Iota[i], Iota[j]):\n",
    "                edges.append((i, j))\n",
    "                tree[Iota[i]].append(Iota[j])\n",
    "    \n",
    "    return edges, tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f832061",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "struc, tree = build_poset(Ill_relevant[1:])\n",
    "chains      = to_chains(pairs, struc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "241f7e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.Poset object at 0x17c29b1a0>]\n",
      "\n",
      "[<__main__.Poset object at 0x17c29b110>]\n",
      "\n",
      "[<__main__.Poset object at 0x17c29aab0>]\n",
      "\n",
      "[<__main__.Poset object at 0x17c29b020>, <__main__.Poset object at 0x17c29a7b0>]\n",
      "\n",
      "[<__main__.Poset object at 0x17c29ba10>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chain in chains:\n",
    "    print(chain)\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0871af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce898cd9",
   "metadata": {},
   "source": [
    "### Define low-level DCM \"LL\" and high-level DCM \"HL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0575feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'synth1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10230e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = 'Smoking'\n",
    "T = 'Tar'\n",
    "C = 'Cancer'\n",
    "\n",
    "S_ = 'Smoking_'\n",
    "C_ = 'Cancer_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb18cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_endogenous_coeff_dict = {(S, T): 0.3, (T, C): 0.2}\n",
    "#ll_endogenous_coeff_dict = {(S, T): 1.0, (T, C): .3} \n",
    "#ll_endogenous_coeff_dict = {(S, T): 4.0, (T, C): 3} \n",
    "#ll_endogenous_coeff_dict = {(S, T): 10.0, (T, C): 8.0} \n",
    "\n",
    "ll_causal_graph          = CBN(list(ll_endogenous_coeff_dict.keys()))\n",
    "#nx.draw(nx.DiGraph(ll_causal_graph.edges()),with_labels=True)\n",
    "\n",
    "hl_endogenous_coeff_dict = {(S_, C_): 0.0}\n",
    "hl_causal_graph          = CBN(list(hl_endogenous_coeff_dict.keys()))\n",
    "# #nx.draw(nx.DiGraph(hl_causal_graph.edges()),with_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d66c8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of samples from the low-level environment.\n",
    "num_llsamples   = params.n_samples['synth1'][0]\n",
    "num_hlsamples   = params.n_samples['synth1'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b57b88",
   "metadata": {},
   "source": [
    "### Construct the empirical nominal distribution for the low-level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "942ffe6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_mu_hat    = np.array([0, 0, 0])  \n",
    "ll_Sigma_hat = np.diag([1, 1, 1])  #np.diag([1, 2, 1]) \n",
    "\n",
    "hl_mu_hat    = np.array([0, 0]) \n",
    "hl_Sigma_hat = np.diag([1, 1]) #np.diag([1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba255d",
   "metadata": {},
   "source": [
    "### Define the sets of relevant interventions and the (total) surjective and order-preserving function $ω:I^{L} \\mapsto I^{H}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc02d782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iota0 = None\n",
    "iota1 = ops.Intervention({S:0})\n",
    "iota2 = ops.Intervention({S:0, T:1})\n",
    "iota3 = ops.Intervention({S:1})\n",
    "iota4 = ops.Intervention({S:1, T:0})\n",
    "iota5 = ops.Intervention({S:1, T:1})\n",
    "\n",
    "eta0 = None\n",
    "eta1 = ops.Intervention({S_:0})\n",
    "eta2 = ops.Intervention({S_:1})\n",
    "\n",
    "omega = {   \n",
    "            iota0: eta0,\n",
    "            iota1: eta1,\n",
    "            iota2: eta1,\n",
    "            iota3: eta2,\n",
    "            iota4: eta2,\n",
    "            iota5: eta2\n",
    "        }\n",
    "\n",
    "Ill_relevant = list(set(omega.keys()))\n",
    "Ihl_relevant = list(set(omega.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d71d01",
   "metadata": {},
   "source": [
    "### Sampling and Pair construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39858720",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dll_samples, Dll_noise = {}, {}\n",
    "for iota in Ill_relevant:\n",
    "\n",
    "    llcm              = lanm.LinearAddSCM(ll_causal_graph, ll_endogenous_coeff_dict, iota)\n",
    "    #Different Dll_noise for each iota\n",
    "    lenv_iota         = mut.sample_distros_Gelbrich([(ll_mu_hat, ll_Sigma_hat)])[0] \n",
    "    Dll_noise[iota]   = lenv_iota.sample(num_llsamples)[0]\n",
    "    Dll_samples[iota] = llcm.simulate(Dll_noise[iota], iota)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1184c205",
   "metadata": {},
   "source": [
    "### Define the abstraction T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac14aca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#T = np.array([[.1, .6, .2], [.6, .2, .7]])\n",
    "T = np.array([[1, 2, 1], [0, 1, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df10ad18",
   "metadata": {},
   "source": [
    "### Compute the empirical nominal distribution for the high-level model and the linear coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7afaa6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_observational_hl         = Dll_samples[None]@ T.T\n",
    "hl_endogenous_coeff_dict      = mut.get_coefficients(data_observational_hl, hl_causal_graph) \n",
    "U_hl, hl_mu_hat, hl_Sigma_hat = mut.lan_abduction(data_observational_hl, hl_causal_graph, hl_endogenous_coeff_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4db58f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_observational_hl    = Dll_samples[None]@ T.T\n",
    "# U_hl                     = np.random.multivariate_normal(mean=hl_mu_hat, cov=hl_Sigma_hat, size=num_hlsamples)\n",
    "# hl_endogenous_coeff_dict = mut.get_coefficients_with_known_noise(data_observational_hl, U_hl, hl_causal_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb6b0fa",
   "metadata": {},
   "source": [
    "### Generate samples for the high-level model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9ba90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dhl_samples, Dhl_noise = {}, {}\n",
    "for eta in Ihl_relevant:\n",
    "\n",
    "    if eta is not None:\n",
    "        hlcm             = lanm.LinearAddSCM(hl_causal_graph, hl_endogenous_coeff_dict, eta)\n",
    "        #Different Dll_noise for each iota\n",
    "        lenv_eta         = mut.sample_distros_Gelbrich([(hl_mu_hat, hl_Sigma_hat)])[0] \n",
    "        Dhl_noise[eta]   = lenv_eta.sample(num_hlsamples)[0]\n",
    "        Dhl_samples[eta] = hlcm.simulate(Dhl_noise[eta], eta)\n",
    "\n",
    "    else:\n",
    "        Dhl_noise[eta]   = U_hl\n",
    "        Dhl_samples[eta] = data_observational_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd56aadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Closer to exact abstraction\n",
    "# Dhl_samples = {}\n",
    "# list_of_iotas = []\n",
    "# for iota in Ill_relevant:\n",
    "    \n",
    "#     if iota not in list_of_iotas:\n",
    "#         list_of_iotas.append(omega[iota])\n",
    "#         if iota is not None:\n",
    "#             Dhl_samples[omega[iota]] = Dll_samples[iota] @ T.T\n",
    "#         else:\n",
    "#             Dhl_samples[omega[iota]] = data_observational_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b871678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = {}\n",
    "for iota in Ill_relevant:\n",
    "    Ds[iota] = (Dll_samples[iota], Dhl_samples[omega[iota]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfe34d1",
   "metadata": {},
   "source": [
    "### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6dcae3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/synth1/exogenous_HL.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((ll_causal_graph, Ill_relevant), f\"data/{experiment}/LL.pkl\")\n",
    "joblib.dump(ll_endogenous_coeff_dict, f\"data/{experiment}/ll_coeffs.pkl\")\n",
    "\n",
    "joblib.dump((hl_causal_graph, Ihl_relevant), f\"data/{experiment}/HL.pkl\")\n",
    "joblib.dump(hl_endogenous_coeff_dict, f\"data/{experiment}/hl_coeffs.pkl\")\n",
    "\n",
    "joblib.dump(Ds, f\"data/{experiment}/Ds.pkl\")\n",
    "\n",
    "joblib.dump(T, f\"data/{experiment}/Tau.pkl\")\n",
    "joblib.dump(omega, f\"data/{experiment}/omega.pkl\")\n",
    "\n",
    "joblib.dump((Dll_noise[None], ll_mu_hat, ll_Sigma_hat), f\"data/{experiment}/exogenous_LL.pkl\")\n",
    "joblib.dump((U_hl, hl_mu_hat, hl_Sigma_hat), f\"data/{experiment}/exogenous_HL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47650fa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
