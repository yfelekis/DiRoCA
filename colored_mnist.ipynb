{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import networkx as nx\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from src.CBN import CausalBayesianNetwork as CBN\n",
    "import modularised_utils as mut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "import evaluation_utils as evut\n",
    "import params\n",
    "import torchvision\n",
    "import random\n",
    "import joblib\n",
    "import opt_utils as oput\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import ot\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 32\n",
    "correlation = 0.85\n",
    "\n",
    "experiment_map = {\n",
    "    2: 'cm2f2',\n",
    "    4: 'cm4f2',\n",
    "    8: 'cm8f2',\n",
    "    16: 'cm16f2',\n",
    "    32: 'cm32f2'\n",
    "}\n",
    "\n",
    "experiment = experiment_map.get(resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable names\n",
    "D = 'Digit'\n",
    "C = 'Color'\n",
    "I = 'Image'\n",
    "\n",
    "D_ = 'Digit_'\n",
    "C_ = 'Color_'\n",
    "I_ = 'Image_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_llsamples = params.n_samples[experiment][0] if experiment in params.n_samples else 1500\n",
    "num_hlsamples = params.n_samples[experiment][1] if experiment in params.n_samples else 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorMNISTDataGenerator:\n",
    "    def __init__(self, image_size=resolution, correlation=correlation):\n",
    "        self.correlation = correlation\n",
    "        self.colors = {\n",
    "            0: (1.0, 0.0, 0.0),  # Red\n",
    "            1: (1.0, 0.6, 0.0),  # Orange\n",
    "            2: (0.8, 1.0, 0.0),  # Yellow-Green\n",
    "            3: (0.2, 1.0, 0.0),  # Green\n",
    "            4: (0.0, 1.0, 0.4),  # Blue-Green\n",
    "            5: (0.0, 1.0, 1.0),  # Cyan\n",
    "            6: (0.0, 0.4, 1.0),  # Light Blue\n",
    "            7: (0.2, 0.0, 1.0),  # Blue\n",
    "            8: (0.8, 0.0, 1.0),  # Purple\n",
    "            9: (1.0, 0.0, 0.6)   # Pink\n",
    "        }\n",
    "        # self.transform = transforms.Compose([\n",
    "        #     transforms.ToPILImage(),\n",
    "        #     transforms.Resize(image_size),\n",
    "        #     transforms.ToTensor(),\n",
    "        #     transforms.Normalize((0.5,), (0.5,))\n",
    "        # ])\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize(image_size),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        mnist = torchvision.datasets.MNIST('data/', train=True, download=True)\n",
    "        self.mnist_data = {}\n",
    "        for i in range(len(mnist)):\n",
    "            if mnist.targets[i].item() not in self.mnist_data:\n",
    "                self.mnist_data[mnist.targets[i].item()] = []\n",
    "            self.mnist_data[mnist.targets[i].item()].append(mnist.data[i])\n",
    "\n",
    "    def generate_samples(self, n, intervention=None, pad_to_length=None):\n",
    "        images = []\n",
    "        digits = []\n",
    "        colors = []\n",
    "        original_lengths = []\n",
    "        for _ in range(n):\n",
    "            u_conf = np.random.randint(10)\n",
    "            if intervention is None:\n",
    "                digit = u_conf if np.random.random() < self.correlation else np.random.randint(10)\n",
    "                color = u_conf if np.random.random() < self.correlation else np.random.randint(10)\n",
    "            else:\n",
    "                intervention_dict = intervention.vv()\n",
    "                digit = intervention_dict['digit'] if 'digit' in intervention_dict else (u_conf if np.random.random() < self.correlation else np.random.randint(10))\n",
    "                color = intervention_dict['color'] if 'color' in intervention_dict else (u_conf if np.random.random() < self.correlation else np.random.randint(10))\n",
    "            idx = np.random.randint(len(self.mnist_data[digit]))\n",
    "            img = self.mnist_data[digit][idx]\n",
    "            color_rgb = self.colors[color]\n",
    "            img_color = torch.tensor(img).float().unsqueeze(0).repeat(3, 1, 1)\n",
    "            for c in range(3):\n",
    "                img_color[c] *= color_rgb[c]\n",
    "            img_final = self.transform(img_color)  # (3, H, W)\n",
    "            img_np = img_final.numpy()\n",
    "            img_np = np.transpose(img_np, (1, 2, 0))  # (H, W, 3)\n",
    "            if pad_to_length is None:\n",
    "                # Flatten the entire image (including background)\n",
    "                images.append(img_np.flatten())\n",
    "                original_lengths.append(len(img_np.flatten()))\n",
    "            else:\n",
    "                # Mask for non-background pixels (assuming background is -1 after normalization)\n",
    "                mask = ~np.all(np.abs(img_np + 1) < 1e-4, axis=2)\n",
    "                non_bg_pixels = img_np[mask]  # shape: (num_non_bg_pixels, 3)\n",
    "                images.append(non_bg_pixels.flatten())\n",
    "                original_lengths.append(len(non_bg_pixels.flatten()))\n",
    "            digits.append(digit)\n",
    "            colors.append(color)\n",
    "        images = np.array(images)\n",
    "        digits = np.array(digits)\n",
    "        colors = np.array(colors)\n",
    "        digits_onehot = np.eye(10)[digits]\n",
    "        colors_onehot = np.eye(10)[colors]\n",
    "        if pad_to_length is None:\n",
    "            samples = np.concatenate([images, digits_onehot, colors_onehot], axis=1)\n",
    "            return samples  \n",
    "        else:\n",
    "            # Pad to pad_to_length as before\n",
    "            n = len(images)\n",
    "            max_len = pad_to_length\n",
    "            images_padded = np.zeros((n, max_len))\n",
    "            padding_info = []\n",
    "            for i, img in enumerate(images):\n",
    "                images_padded[i, :len(img)] = img\n",
    "                padding_amount = max_len - len(img)\n",
    "                padding_info.append({\n",
    "                    'original_length': len(img),\n",
    "                    'padded_length': max_len,\n",
    "                    'padding_added': padding_amount,\n",
    "                    'digit': digits[i],\n",
    "                    'color': colors[i]\n",
    "                })\n",
    "            samples = np.concatenate([images_padded, digits_onehot, colors_onehot], axis=1)\n",
    "            return samples, padding_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iota0 = None  # observational\n",
    "iota1 = ops.Intervention({'digit': 6})\n",
    "iota2 = ops.Intervention({'digit': 8})\n",
    "iota3 = ops.Intervention({'digit': 4})\n",
    "iota4 = ops.Intervention({'color': 7})  \n",
    "iota5 = ops.Intervention({'color': 0})\n",
    "iota6 = ops.Intervention({'color': 4})\n",
    "iota7 = ops.Intervention({'digit': 6, 'color': 7})\n",
    "iota8 = ops.Intervention({'digit': 8, 'color': 0})\n",
    "iota9 = ops.Intervention({'digit': 4, 'color': 4})\n",
    "\n",
    "eta0 = None  # observational\n",
    "eta1 = ops.Intervention({'D_': 6})\n",
    "eta2 = ops.Intervention({'D_': 8})\n",
    "eta3 = ops.Intervention({'D_': 4})\n",
    "eta4 = ops.Intervention({'C_': 7})\n",
    "eta5 = ops.Intervention({'C_': 0})\n",
    "eta6 = ops.Intervention({'C_': 4})\n",
    "eta7 = ops.Intervention({'D_': 6, 'C_': 7})\n",
    "eta8 = ops.Intervention({'D_': 8, 'C_': 0})\n",
    "eta9 = ops.Intervention({'D_': 4, 'C_': 4})\n",
    "\n",
    "# omega mapping\n",
    "omega = {\n",
    "    iota0: eta0,\n",
    "    iota1: eta1,\n",
    "    iota2: eta2,\n",
    "    iota3: eta3,\n",
    "    iota4: eta4,\n",
    "    iota5: eta5,\n",
    "    iota6: eta6,\n",
    "    iota7: eta7,\n",
    "    iota8: eta8,\n",
    "    iota9: eta9\n",
    "}\n",
    "\n",
    "Ill_relevant = list(set(omega.keys()))\n",
    "Ihl_relevant = list(set(omega.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_components(samples):\n",
    "    \"\"\"\n",
    "    Extract image, digit, and color components from samples array\n",
    "    For new structure: images are flat arrays of non-background pixels (padded).\n",
    "    \"\"\"\n",
    "    image_pixels = samples.shape[1] - 20  \n",
    "    images = samples[:, :image_pixels]  \n",
    "    digits_onehot = samples[:, image_pixels:image_pixels+10]\n",
    "    colors_onehot = samples[:, image_pixels+10:]\n",
    "    digits = np.argmax(digits_onehot, axis=1)\n",
    "    colors = np.argmax(colors_onehot, axis=1)\n",
    "    return {\n",
    "        'images': images,  \n",
    "        'digits': digits,\n",
    "        'colors': colors,\n",
    "        'digits_onehot': digits_onehot,\n",
    "        'colors_onehot': colors_onehot\n",
    "    }\n",
    "\n",
    "def show_samples(components, num_samples=3):\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(2*num_samples, 2))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        img = components['images'][i].transpose(1,2,0)\n",
    "        img = (img + 1) / 2  \n",
    "        \n",
    "        if num_samples == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes[i]\n",
    "            \n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'D:{components[\"digits\"][i]}\\nC:{components[\"colors\"][i]}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_to_high_level(samples):\n",
    "    \"\"\"\n",
    "    Transform low-level samples to high-level by clustering non-background pixels into one variable I.\n",
    "    D and C remain unchanged as they are already high-level variables.\n",
    "\n",
    "    Args:\n",
    "    - samples: Low level samples with shape (n_samples, padded_length+20) where:\n",
    "        - First padded_length: non-background image pixels (padded)\n",
    "        - Next 10: digit one-hot (D)\n",
    "        - Last 10: color one-hot (C)\n",
    "    \"\"\"\n",
    "    image_pixels = samples.shape[1] - 20\n",
    "    # Split into components\n",
    "    images = samples[:, :image_pixels]  # Non-background image features (padded)\n",
    "    D = samples[:, image_pixels:image_pixels+10]   # Digit one-hot\n",
    "    C = samples[:, image_pixels+10:]       # Color one-hot\n",
    "\n",
    "    I = images.mean(axis=1, keepdims=True) \n",
    "\n",
    "    high_level_samples = np.concatenate([D, C, I], axis=1)\n",
    "\n",
    "    return high_level_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator = ColorMNISTDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples\n",
    "Dll_samples = {}\n",
    "for iota in Ill_relevant:\n",
    "    Dll_samples[iota] = data_generator.generate_samples(num_llsamples, iota)\n",
    "\n",
    "\n",
    "# Generate high-level samples\n",
    "Dhl_samples = {}\n",
    "for eta in Ihl_relevant:\n",
    "    if eta is not None:\n",
    "        # Find corresponding low-level intervention\n",
    "        iota = [i for i, e in omega.items() if e == eta][0]\n",
    "        Dhl_samples[eta] = low_to_high_level(Dll_samples[iota])\n",
    "    else:\n",
    "        # For observational distribution\n",
    "        Dhl_samples[eta] = low_to_high_level(Dll_samples[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.CBN import CausalBayesianNetwork\n",
    "\n",
    "def create_cmnist_graphs():\n",
    "    # Low-level causal graph (VL)\n",
    "    ll_edges = [('digit', 'pixels'), ('color', 'pixels')]  \n",
    "    ll_causal_graph = CausalBayesianNetwork(ll_edges)\n",
    "    \n",
    "    # High-level causal graph (VH)\n",
    "    hl_edges = [('D_', 'I_'), ('C_', 'I_')]  \n",
    "    hl_causal_graph = CausalBayesianNetwork(hl_edges)\n",
    "    \n",
    "    return ll_causal_graph, hl_causal_graph\n",
    "\n",
    "# Create the graphs as CausalBayesianNetwork objects\n",
    "ll_causal_graph, hl_causal_graph = create_cmnist_graphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "\n",
    "data_observational_ll, Dll_obs_test = train_test_split(Dll_samples[None], test_size=test_size, random_state=42)\n",
    "data_observational_hl, Dhl_obs_test = train_test_split(Dhl_samples[None], test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ll_coefficients(data, img_dim=None, n_channels=3, use_ridge=False, alpha=1.0):\n",
    "    \"\"\"\n",
    "    For each channel (R, G, B), fit a linear regression to predict pixel values using:\n",
    "      - One-hot digit (10 features)\n",
    "      - One-hot color (10 features)\n",
    "      - x-coordinate (1 feature)\n",
    "      - y-coordinate (1 feature)\n",
    "    Returns:\n",
    "      - coeffs: dict mapping channel index to regression coefficients\n",
    "      - residuals: dict mapping channel index to residuals (1D array, one per pixel sample)\n",
    "    \"\"\"\n",
    "    img_size = data.shape[1] - 20\n",
    "    if img_dim is None:\n",
    "        img_dim = int(np.sqrt(img_size / n_channels))\n",
    "    \n",
    "    digit_onehot = data[:, img_size:img_size+10]\n",
    "    color_onehot = data[:, img_size+10:img_size+20]\n",
    "    \n",
    "    n_samples = data.shape[0]\n",
    "    coeffs = {}\n",
    "    residuals = {}\n",
    "\n",
    "    for channel in range(n_channels):\n",
    "        X_list = []\n",
    "        y_list = []\n",
    "        for i in range(n_samples):\n",
    "            img_flat = data[i, :img_size]\n",
    "            img = img_flat.reshape((img_dim, img_dim, n_channels))\n",
    "            for x in range(img_dim):\n",
    "                for y in range(img_dim):\n",
    "                    # Predictors: [digit_onehot, color_onehot, x, y]\n",
    "                    predictors = np.concatenate([\n",
    "                        digit_onehot[i],         # shape (10,)\n",
    "                        color_onehot[i],         # shape (10,)\n",
    "                        [x], [y]                 # shape (2,)\n",
    "                    ])\n",
    "                    X_list.append(predictors)\n",
    "                    y_list.append(img[x, y, channel])\n",
    "        X = np.vstack(X_list)  \n",
    "        y = np.array(y_list)   \n",
    "\n",
    "        model = Ridge(alpha=alpha) if use_ridge else LinearRegression()\n",
    "        model.fit(X, y)\n",
    "        coeffs[channel] = model.coef_  \n",
    "        residuals[channel] = y - model.predict(X) \n",
    "\n",
    "    return coeffs, residuals\n",
    "\n",
    "def get_hl_coefficients(data, use_ridge=False, alpha=1.0):\n",
    "    \"\"\"\n",
    "    For the high-level data (aggregated image), fit a linear regression to predict\n",
    "    the aggregated image value using:\n",
    "      - One-hot digit\n",
    "      - One-hot color \n",
    "    Returns:\n",
    "      - coeffs: 1D numpy array of regression coefficients \n",
    "      - residuals: 1D array of residuals (noise) for the high-level image variable\n",
    "    \"\"\"\n",
    "    D = data[:, :10][:, :-1]  \n",
    "    C = data[:, 10:20][:, :-1] \n",
    "    I = data[:, 20]\n",
    "    X = np.column_stack((D, C)) \n",
    "    y = I\n",
    "    model = Ridge(alpha=alpha) if use_ridge else LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    residuals = y - model.predict(X)\n",
    "    coeffs = model.coef_  \n",
    "    return coeffs, residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_coeffs, ll_residuals = get_ll_coefficients(data_observational_ll)\n",
    "hl_coeffs, hl_residuals = get_hl_coefficients(data_observational_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For low-level: concatenate all residuals for all images and all channels\n",
    "U_L = np.column_stack([\n",
    "    ll_residuals[0],  \n",
    "    ll_residuals[1],\n",
    "    ll_residuals[2]\n",
    "])  \n",
    "\n",
    "N = data_observational_ll.shape[0]\n",
    "img_dim = 32\n",
    "n_pixels = img_dim * img_dim\n",
    "U_L = U_L.reshape(N, n_pixels * 3)  \n",
    "\n",
    "# For high-level: all residuals for all images\n",
    "U_H = hl_residuals.reshape(-1, 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(U_L, f\"data/{experiment}/U_L.pkl\")\n",
    "joblib.dump(U_H, f\"data/{experiment}/U_H.pkl\")\n",
    "\n",
    "joblib.dump(data_observational_ll, f\"data/{experiment}/data_observational_ll.pkl\")\n",
    "joblib.dump(data_observational_hl, f\"data/{experiment}/data_observational_hl.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = {}\n",
    "for iota in Ill_relevant:\n",
    "    Ds[iota] = (Dll_samples[iota], Dhl_samples[omega[iota]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/cm32f2/exogenous_HL.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump((ll_causal_graph, Ill_relevant), f\"data/{experiment}/LL.pkl\")\n",
    "joblib.dump(ll_coeffs, f\"data/{experiment}/ll_coeffs.pkl\")\n",
    "\n",
    "joblib.dump((hl_causal_graph, Ihl_relevant), f\"data/{experiment}/HL.pkl\")\n",
    "joblib.dump(hl_coeffs, f\"data/{experiment}/hl_coeffs.pkl\")\n",
    "\n",
    "joblib.dump(Ds, f\"data/{experiment}/Ds.pkl\")\n",
    "\n",
    "joblib.dump(omega, f\"data/{experiment}/omega.pkl\")\n",
    "\n",
    "joblib.dump(data_observational_ll, f\"data/{experiment}/Dll_obs_train.pkl\")\n",
    "joblib.dump(data_observational_hl, f\"data/{experiment}/Dhl_obs_train.pkl\")\n",
    "\n",
    "joblib.dump(Dll_obs_test, f\"data/{experiment}/Dll_obs_test.pkl\")\n",
    "joblib.dump(Dhl_obs_test, f\"data/{experiment}/Dhl_obs_test.pkl\")\n",
    "\n",
    "joblib.dump(ll_coeffs, f\"data/{experiment}/ll_endogenous_coeff_dict.pkl\")\n",
    "joblib.dump(hl_coeffs, f\"data/{experiment}/hl_endogenous_coeff_dict.pkl\")\n",
    "\n",
    "joblib.dump(ll_residuals, f\"data/{experiment}/exogenous_LL.pkl\")\n",
    "joblib.dump(hl_residuals, f\"data/{experiment}/exogenous_HL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_ll_func(parent_info_ll, iota):\n",
    "    # parent_info_ll: dict with keys 'digit_onehot', 'color_onehot', 'x', 'y', 'coeffs'\n",
    "    digit_onehot = parent_info_ll['digit_onehot'].copy()  # Add copy\n",
    "    color_onehot = parent_info_ll['color_onehot'].copy()  # Add copy\n",
    "    x_coords = parent_info_ll['x']\n",
    "    y_coords = parent_info_ll['y']\n",
    "    coeffs = parent_info_ll['coeffs']  # dict: channel -> 22-dim vector\n",
    "\n",
    "    # Add intervention handling\n",
    "    if iota is not None:\n",
    "        intervention_dict = iota.vv()\n",
    "        if 'digit' in intervention_dict:\n",
    "            digit_onehot = np.zeros_like(digit_onehot)\n",
    "            digit_onehot[:, intervention_dict['digit']] = 1\n",
    "        if 'color' in intervention_dict:\n",
    "            color_onehot = np.zeros_like(color_onehot)\n",
    "            color_onehot[:, intervention_dict['color']] = 1\n",
    "\n",
    "    N = digit_onehot.shape[0]\n",
    "    img_dim = len(x_coords)\n",
    "    n_channels = len(coeffs)\n",
    "    det = np.zeros((N, img_dim * img_dim * n_channels))\n",
    "    for i in range(N):\n",
    "        det_i = []\n",
    "        for c in range(n_channels):\n",
    "            det_img = []\n",
    "            for x in range(img_dim):\n",
    "                for y in range(img_dim):\n",
    "                    predictors = np.concatenate([digit_onehot[i], color_onehot[i], [x], [y]])\n",
    "                    det_img.append(np.dot(coeffs[c], predictors))\n",
    "            det_i.append(det_img)\n",
    "        det[i, :] = np.concatenate(det_i)\n",
    "    return torch.tensor(det, dtype=torch.float32)\n",
    "\n",
    "def det_hl_func(parent_info_hl, omega_iota):\n",
    "    # parent_info_hl: dict with keys 'digit_onehot', 'color_onehot', 'coeffs'\n",
    "    digit_onehot = parent_info_hl['digit_onehot'].copy()  \n",
    "    color_onehot = parent_info_hl['color_onehot'].copy()  \n",
    "    coeffs = parent_info_hl['coeffs']  \n",
    "\n",
    "    if omega_iota is not None:\n",
    "        intervention_dict = omega_iota.vv()\n",
    "        if 'D_' in intervention_dict:\n",
    "            digit_onehot = np.zeros_like(digit_onehot)\n",
    "            digit_onehot[:, intervention_dict['D_']] = 1\n",
    "        if 'C_' in intervention_dict:\n",
    "            color_onehot = np.zeros_like(color_onehot)\n",
    "            color_onehot[:, intervention_dict['C_']] = 1\n",
    "\n",
    "    N = digit_onehot.shape[0]\n",
    "    det = []\n",
    "    for i in range(N):\n",
    "        predictors = np.concatenate([digit_onehot[i][:-1], color_onehot[i][:-1]])  \n",
    "        det.append(np.dot(coeffs, predictors))\n",
    "    return torch.tensor(np.array(det).reshape(-1, 1), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_info_ll = {\n",
    "    'digit_onehot': data_observational_ll[:, -20:-10],\n",
    "    'color_onehot': data_observational_ll[:, -10:],\n",
    "    'x': np.arange(img_dim),\n",
    "    'y': np.arange(img_dim),\n",
    "    'coeffs': ll_coeffs\n",
    "}\n",
    "parent_info_hl = {\n",
    "    'digit_onehot': data_observational_hl[:, :10],\n",
    "    'color_onehot': data_observational_hl[:, 10:20],\n",
    "    'coeffs': hl_coeffs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_ll_dict = {}\n",
    "for iota in Ill_relevant:\n",
    "    det_ll_dict[iota] = det_ll_func(parent_info_ll, iota)\n",
    "\n",
    "det_hl_dict = {}\n",
    "for eta in Ihl_relevant:\n",
    "    det_hl_dict[eta] = det_hl_func(parent_info_hl, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(det_ll_dict, f\"data/{experiment}/det_ll_dict.pkl\")\n",
    "joblib.dump(det_hl_dict, f\"data/{experiment}/det_hl_dict.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_onehotL = data_observational_ll[:, 3072:3082]  \n",
    "color_onehotL = data_observational_ll[:, 3082:3092]  \n",
    "\n",
    "digit_onehotH = data_observational_hl[:, :10]  \n",
    "color_onehotH = data_observational_hl[:, 10:20]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DIROCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_empirical_radius(N, eta, c1=1.0, c2=1.0, alpha=2.0, m=3):\n",
    "    \"\"\"\n",
    "    Compute epsilon_N(eta) for empirical Wasserstein case.\n",
    "\n",
    "    Parameters:\n",
    "    - N: int, number of samples\n",
    "    - eta: float, confidence level (0 < eta < 1)\n",
    "    - c1: float, constant from theorem (default 1.0, adjust if needed)\n",
    "    - c2: float, constant from theorem (default 1.0, adjust if needed)\n",
    "    - alpha: float, light-tail exponent (P[exp(||ξ||^α)] ≤ A)\n",
    "    - m: int, ambient dimension\n",
    "\n",
    "    Returns:\n",
    "    - epsilon: float, the concentration radius\n",
    "    \"\"\"\n",
    "    assert 0 < eta < 1, \"eta must be in (0,1)\"\n",
    "    threshold = np.log(c1 / eta) / c2\n",
    "    if N >= threshold:\n",
    "        exponent = min(1/m, 0.5)\n",
    "    else:\n",
    "        exponent = 1 / alpha\n",
    "\n",
    "    epsilon = (np.log(c1 / eta) / (c2 * N)) ** exponent\n",
    "    return epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(ll_causal_graph.nodes())\n",
    "h = len(hl_causal_graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_bound = round(compute_empirical_radius(N=num_llsamples, eta=0.05, c1=1000.0, c2=1.0, alpha=2.0, m=l), 3)\n",
    "hl_bound = round(compute_empirical_radius(N=num_hlsamples, eta=0.05, c1=1000.0, c2=1.0, alpha=2.0, m=h), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon, delta = ll_bound, hl_bound\n",
    "\n",
    "eta_max = 0.001\n",
    "eta_min = 0.001\n",
    "\n",
    "max_iter = 5000\n",
    "num_steps_min = 5\n",
    "num_steps_max = 2\n",
    "\n",
    "robust_L = True \n",
    "robust_H = True\n",
    "\n",
    "initialization = 'random'\n",
    "\n",
    "tol  = 1e-4\n",
    "seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_erica = {\n",
    "                        'U_L': U_L,\n",
    "                        'U_H': U_H,\n",
    "                        'Ill': Ill_relevant,\n",
    "                        'parent_info_ll': parent_info_ll,\n",
    "                        'parent_info_hl': parent_info_hl,\n",
    "                        'digit_onehotL': digit_onehotL,\n",
    "                        'color_onehotL': color_onehotL,\n",
    "                        'digit_onehotH': digit_onehotH,\n",
    "                        'color_onehotH': color_onehotH,\n",
    "                        'omega': omega,\n",
    "                        'epsilon': epsilon,\n",
    "                        'delta': delta,\n",
    "                        'eta_min': eta_min,\n",
    "                        'eta_max': eta_max,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'num_steps_max': num_steps_max,\n",
    "                        'max_iter': max_iter,\n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'robust_L': robust_L,\n",
    "                        'robust_H': robust_H,\n",
    "                        'initialization': initialization,\n",
    "                        'experiment': experiment\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_objective_cm(\n",
    "    U_L, U_H, T, Theta, Phi, Ill, omega,\n",
    "    det_ll_dict, det_hl_dict, \n",
    "    parent_info_ll, parent_info_hl,\n",
    "    digit_onehot, color_onehot, digit_onehotH, color_onehotH  \n",
    "):\n",
    "    loss_iota = 0\n",
    "    N = U_L.shape[0]\n",
    "    for iota in Ill:\n",
    "        det_ll = det_ll_dict[iota]\n",
    "        det_hl = det_hl_dict[omega[iota]]\n",
    "        endo_ll = det_ll + (U_L + Theta)  \n",
    "        endo_ll_full = torch.cat([\n",
    "            endo_ll, \n",
    "            torch.tensor(digit_onehot, dtype=endo_ll.dtype, device=endo_ll.device),\n",
    "            torch.tensor(color_onehot, dtype=endo_ll.dtype, device=endo_ll.device)\n",
    "        ], dim=1) \n",
    "        endo_hl = det_hl + (U_H + Phi)  \n",
    "        endo_hl_full = torch.cat([\n",
    "            endo_hl,\n",
    "            torch.tensor(digit_onehotH, dtype=endo_hl.dtype, device=endo_hl.device),\n",
    "            torch.tensor(color_onehotH, dtype=endo_hl.dtype, device=endo_hl.device)\n",
    "        ], dim=1) \n",
    "        mapped_ll = (T @ endo_ll_full.T).T  \n",
    "        diff = mapped_ll - endo_hl_full\n",
    "        loss_iota += torch.norm(diff, p='fro')**2 / diff.numel()\n",
    "    loss = loss_iota / len(Ill)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_empirical_erica_optimization(\n",
    "    U_L, U_H, Ill, omega, epsilon, delta, eta_min, eta_max,\n",
    "    num_steps_min, num_steps_max, max_iter, tol, seed, robust_L, robust_H, initialization, experiment,\n",
    "    det_ll_dict, det_hl_dict, parent_info_ll, parent_info_hl, digit_onehotL, color_onehotL, digit_onehotH, color_onehotH\n",
    "):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    method  = 'erica' if robust_L or robust_H else 'enrico'\n",
    "    num_steps_min = 1 if method == 'enrico' else num_steps_min\n",
    "\n",
    "    U_L = torch.as_tensor(U_L, dtype=torch.float32)\n",
    "    U_H = torch.as_tensor(U_H, dtype=torch.float32)\n",
    "    \n",
    "    N, l = U_L.shape\n",
    "    _, h = U_H.shape\n",
    "\n",
    "    T = torch.randn(21, 3092, requires_grad=True)\n",
    "    if initialization == 'random':\n",
    "        Theta = torch.randn(N, l, requires_grad=True)\n",
    "        Phi   = torch.randn(N, h, requires_grad=True)\n",
    "    elif initialization == 'projected':\n",
    "        Theta = oput.init_in_frobenius_ball((N, l), epsilon)\n",
    "        Phi   = oput.init_in_frobenius_ball((N, h), delta)\n",
    "\n",
    "    # Create optimizers\n",
    "    optimizer_T   = torch.optim.Adam([T], lr=eta_min)\n",
    "    optimizer_max = torch.optim.Adam([Theta, Phi], lr=eta_max)\n",
    "    \n",
    "    prev_T_objective = float('inf')\n",
    "    \n",
    "    for iteration in tqdm(range(max_iter)):\n",
    "        objs_T, objs_max = [], []\n",
    "        # Step 1: Minimize with respect to T\n",
    "        for _ in range(num_steps_min):\n",
    "            optimizer_T.zero_grad()\n",
    "            T_objective = empirical_objective_cm(\n",
    "                U_L, U_H, T, Theta, Phi, Ill, omega,\n",
    "                det_ll_dict, det_hl_dict, parent_info_ll, parent_info_hl, digit_onehotL, color_onehotL, digit_onehotH, color_onehotH\n",
    "            )\n",
    "            objs_T.append(T_objective.item())\n",
    "            T_objective.backward()\n",
    "            optimizer_T.step()\n",
    "        # Step 2: Maximize with respect to Theta and Phi\n",
    "        if method == 'erica':\n",
    "            for _ in range(num_steps_max):\n",
    "                optimizer_max.zero_grad()\n",
    "                max_objective = -empirical_objective_cm(\n",
    "                    U_L, U_H, T, Theta, Phi, Ill, omega,\n",
    "                    det_ll_dict, det_hl_dict, parent_info_ll, parent_info_hl, digit_onehotL, color_onehotL, digit_onehotH, color_onehotH\n",
    "                )\n",
    "                max_objective.backward()\n",
    "                optimizer_max.step()\n",
    "                # Project onto constraint sets\n",
    "                with torch.no_grad():\n",
    "                    Theta.data = oput.project_onto_frobenius_ball(Theta, epsilon)\n",
    "                    Phi.data   = oput.project_onto_frobenius_ball(Phi, delta)\n",
    "                mobj = empirical_objective_cm(\n",
    "                    U_L, U_H, T, Theta, Phi, Ill, omega,\n",
    "                    det_ll_dict, det_hl_dict, parent_info_ll, parent_info_hl, digit_onehotL, color_onehotL, digit_onehotH, color_onehotH\n",
    "                )\n",
    "                objs_max.append(mobj.item())\n",
    "\n",
    "        with torch.no_grad():\n",
    "            current_T_objective = T_objective.item()\n",
    "            if abs(prev_T_objective - current_T_objective) < tol:\n",
    "                print(f\"Converged at iteration {iteration + 1}\")\n",
    "                break\n",
    "            prev_T_objective = current_T_objective\n",
    "            \n",
    "    T       = T.detach().numpy()\n",
    "    paramsL = {'pert_U': Theta.detach().numpy(), 'radius_worst': epsilon,\n",
    "                    'pert_hat': U_L, 'radius': epsilon}\n",
    "    paramsH = {'pert_U': Phi.detach().numpy(), 'radius_worst': delta,\n",
    "                    'pert_hat': U_H, 'radius': delta}\n",
    "    \n",
    "    if method == 'erica':\n",
    "        radius_worst_L          = evut.compute_empirical_worst_case_distance(paramsL)\n",
    "        paramsL['radius_worst'] = radius_worst_L\n",
    "        radius_worst_H          = evut.compute_empirical_worst_case_distance(paramsH)\n",
    "        paramsH['radius_worst'] = radius_worst_H\n",
    "\n",
    "    opt_params = {'L': paramsL, 'H': paramsH}\n",
    "\n",
    "    save_dir = f\"data/{experiment}/{method}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    joblib.dump(opt_params, f\"data/{experiment}/{method}/opt_params.pkl\")\n",
    "\n",
    "    return opt_params, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_delta_values = [100, 30, 8, 4, ll_bound, 2, 1]\n",
    "diroca_train_results_empirical = {}\n",
    "\n",
    "for eps_delta in eps_delta_values:\n",
    "    print(f\"Training for ε=δ = {eps_delta}\")\n",
    "    \n",
    "    if eps_delta == ll_bound:\n",
    "        opt_params_erica['epsilon'] = ll_bound\n",
    "        opt_params_erica['delta']   = hl_bound\n",
    "    else:\n",
    "        opt_params_erica['epsilon'] = eps_delta\n",
    "        opt_params_erica['delta']   = eps_delta\n",
    "    \n",
    "    opt_params_erica['det_ll_dict'] = det_ll_dict\n",
    "    opt_params_erica['det_hl_dict'] = det_hl_dict\n",
    "    \n",
    "    # Run DIROCA optimization\n",
    "    params_empirical, T_empirical = run_empirical_erica_optimization(**opt_params_erica)\n",
    "    \n",
    "    if eps_delta == ll_bound:\n",
    "        diroca_train_results_empirical['T_'+str(ll_bound)+'-'+str(hl_bound)] = {\n",
    "            'optimization_params': params_empirical,\n",
    "            'T_matrix': T_empirical\n",
    "        }\n",
    "    else:\n",
    "        diroca_train_results_empirical['T_'+str(eps_delta)] = {\n",
    "            'optimization_params': params_empirical,\n",
    "            'T_matrix': T_empirical\n",
    "        }\n",
    "\n",
    "print(\"\\nTraining completed. T matrices stored in trained_results dictionary.\")\n",
    "print(\"Available ε=δ values:\", list(diroca_train_results_empirical.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfect_abstraction(px_samples, py_samples, tau_threshold=1e-2):\n",
    "\n",
    "    tau_adj = np.linalg.pinv(px_samples) @ py_samples\n",
    "    tau_adj_mask = np.abs(tau_adj) > tau_threshold\n",
    "    tau_adj = tau_adj * tau_adj_mask\n",
    "\n",
    "    return tau_adj\n",
    "\n",
    "def noisy_abstraction(px_samples, py_samples, tau_threshold=1e-1, refit_coeff=False):\n",
    "\n",
    "    tau_adj_hat = np.linalg.pinv(px_samples) @ py_samples\n",
    "    tau_mask_hat = np.argmax(np.abs(tau_adj_hat), axis=1)\n",
    "    abs_nodes = py_samples.shape[1]\n",
    "    tau_mask_hat = np.eye(abs_nodes)[tau_mask_hat]\n",
    "    tau_mask_hat *= np.array(np.abs(tau_adj_hat) > tau_threshold, dtype=np.int32)\n",
    "    \n",
    "    if refit_coeff:\n",
    "        for y in range(tau_mask_hat.shape[1]):\n",
    "            block = np.where(tau_mask_hat[:, y] == 1)[0]\n",
    "            if len(block) > 0:\n",
    "                tau_adj_hat[block, y] = np.linalg.pinv(px_samples[:, block]) @ py_samples[:, y]\n",
    "    \n",
    "    tau_adj_hat = tau_mask_hat * tau_adj_hat\n",
    "    return tau_adj_hat\n",
    "\n",
    "def abs_lingam_reconstruction_v2_modified(df_base, df_abst, n_paired_samples=None, style=\"Perfect\", tau_threshold=1e-2):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        df_base: numpy array of concrete observations (pixels only)\n",
    "        df_abst: numpy array of abstract observations (image value only)\n",
    "    \"\"\"\n",
    "    # Get dimensions\n",
    "    n_samples_base, d = df_base.shape\n",
    "    n_samples_abst = df_abst.shape[0]\n",
    "    \n",
    "    \n",
    "    # Create joint dataset D_J by taking a subset of paired samples\n",
    "    if n_paired_samples is None:\n",
    "        n_paired_samples = min(n_samples_base, n_samples_abst)\n",
    "    \n",
    "    n_paired_samples = min(n_paired_samples, n_samples_base, n_samples_abst)\n",
    "    \n",
    "    # Create D_J using the first n_paired_samples\n",
    "    D_J_base = df_base[:n_paired_samples]  # pixels only\n",
    "    D_J_abst = df_abst[:n_paired_samples] \n",
    "    #D_J_abst = df_abst[:n_paired_samples].reshape(-1, 1)  # image value only, ensure 2D\n",
    "    \n",
    "    if style == \"Perfect\":\n",
    "        T = perfect_abstraction(D_J_base, D_J_abst, tau_threshold)\n",
    "    elif style == \"Noisy\":\n",
    "        T = noisy_abstraction(D_J_base, D_J_abst, tau_threshold, False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown style {style}\")\n",
    "\n",
    "    return T\n",
    "\n",
    "def run_abs_lingam_complete_modified(data_observational_ll, data_observational_hl, n_paired_samples=1000):\n",
    "\n",
    "    df_base = data_observational_ll\n",
    "    df_abst = data_observational_hl\n",
    "    \n",
    "    styles = [\"Perfect\", \"Noisy\"]\n",
    "    results = {}\n",
    "    \n",
    "    for style in styles:\n",
    "        T = abs_lingam_reconstruction_v2_modified(\n",
    "            df_base, \n",
    "            df_abst,\n",
    "            n_paired_samples=n_paired_samples,\n",
    "            style=style\n",
    "        )\n",
    "        results[style] = {'T': T}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "abslingam_results = run_abs_lingam_complete_modified(data_observational_ll, data_observational_hl)\n",
    "\n",
    "T_pa_pixels = abslingam_results['Perfect']['T']\n",
    "T_na_pixels = abslingam_results['Noisy']['T']\n",
    "\n",
    "diroca_train_results_empirical['T_pa'] = {\n",
    "    'optimization_params': {\n",
    "        'L': {'pert_U': U_L},\n",
    "        'H': {'pert_U': U_H}\n",
    "    }, \n",
    "    'T_matrix': T_pa_pixels.T\n",
    "}\n",
    "\n",
    "diroca_train_results_empirical['T_na'] = {\n",
    "    'optimization_params': {\n",
    "        'L': {'pert_U': U_L},\n",
    "        'H': {'pert_U': U_H}\n",
    "    }, \n",
    "    'T_matrix': T_na_pixels.T\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_enrico, T_enrico = run_empirical_erica_optimization(**{**opt_params_erica, 'robust_L': False, 'robust_H': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_0.00'] = {\n",
    "                                'optimization_params': params_enrico,\n",
    "                                'T_matrix': T_enrico\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BARYCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_empirical_bary_optim_new(\n",
    "    det_ll_dict,\n",
    "    det_hl_dict,\n",
    "    Ill_relevant,\n",
    "    omega,\n",
    "    U_L, U_H,\n",
    "    digit_onehotL, color_onehotL,\n",
    "    digit_onehotH, color_onehotH,\n",
    "    max_iter, tol, seed\n",
    "):\n",
    "    \"\"\"\n",
    "    Barycentric optimization using reconstructed endogenous samples.\n",
    "    Returns T of shape (21, 3092).\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    bary_L_list = []\n",
    "    bary_H_list = []\n",
    "\n",
    "    for iota in Ill_relevant:\n",
    "        # Reconstruct low-level and high-level endogenous samples\n",
    "        det_ll = det_ll_dict[iota]\n",
    "        det_hl = det_hl_dict[omega[iota]]\n",
    "\n",
    "        # Convert to torch tensors if needed\n",
    "        det_ll = torch.tensor(det_ll, dtype=torch.float32) if not torch.is_tensor(det_ll) else det_ll\n",
    "        det_hl = torch.tensor(det_hl, dtype=torch.float32) if not torch.is_tensor(det_hl) else det_hl\n",
    "        U_L_tensor = torch.tensor(U_L, dtype=torch.float32) if not torch.is_tensor(U_L) else U_L\n",
    "        U_H_tensor = torch.tensor(U_H, dtype=torch.float32) if not torch.is_tensor(U_H) else U_H\n",
    "\n",
    "        # Reconstruct full endogenous inputs\n",
    "        endo_ll = det_ll + U_L_tensor  # (N, 3072)\n",
    "        endo_ll_full = torch.cat([\n",
    "            endo_ll,\n",
    "            torch.tensor(digit_onehotL, dtype=endo_ll.dtype, device=endo_ll.device),\n",
    "            torch.tensor(color_onehotL, dtype=endo_ll.dtype, device=endo_ll.device)\n",
    "        ], dim=1)  # (N, 3092)\n",
    "\n",
    "        endo_hl = det_hl + U_H_tensor  # (N, 1)\n",
    "        endo_hl_full = torch.cat([\n",
    "            endo_hl,\n",
    "            torch.tensor(digit_onehotH, dtype=endo_hl.dtype, device=endo_hl.device),\n",
    "            torch.tensor(color_onehotH, dtype=endo_hl.dtype, device=endo_hl.device)\n",
    "        ], dim=1)  # (N, 21)\n",
    "\n",
    "        # Compute barycenters (mean over samples)\n",
    "        bary_L = endo_ll_full.mean(dim=0, keepdim=True)  # (1, 3092)\n",
    "        bary_H = endo_hl_full.mean(dim=0, keepdim=True)  # (1, 21)\n",
    "\n",
    "        bary_L_list.append(bary_L)\n",
    "        bary_H_list.append(bary_H)\n",
    "\n",
    "    # Stack all barycenters\n",
    "    bary_L = torch.cat(bary_L_list, dim=0)  # (num_interventions, 3092)\n",
    "    bary_H = torch.cat(bary_H_list, dim=0)  # (num_interventions, 21)\n",
    "\n",
    "    # Optimize T such that bary_H ≈ bary_L @ T.T, so T: (21, 3092)\n",
    "    h = bary_H.shape[1]\n",
    "    l = bary_L.shape[1]\n",
    "    T = torch.randn(h, l, requires_grad=True)\n",
    "    optimizer_T = torch.optim.Adam([T], lr=0.001)\n",
    "\n",
    "    previous_objective = float('inf')\n",
    "    for step in tqdm(range(int(max_iter))):\n",
    "        optimizer_T.zero_grad()\n",
    "        diff = bary_L @ T.T - bary_H  # (num_interventions, 21)\n",
    "        objective_T = torch.norm(diff, p='fro') ** 2 / diff.numel()\n",
    "\n",
    "        if abs(previous_objective - objective_T.item()) < tol:\n",
    "            print(f\"Converged at step {step + 1}/{max_iter} with objective: {objective_T.item()}\")\n",
    "            break\n",
    "\n",
    "        previous_objective = objective_T.item()\n",
    "        objective_T.backward()\n",
    "        optimizer_T.step()\n",
    "\n",
    "    return T.detach().cpu().numpy()  # (21, 3092)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_bary = {\n",
    "                        'U_L':U_L,\n",
    "                        'U_H':U_H,\n",
    "                        'Ill_relevant':Ill_relevant,\n",
    "                        'omega':omega,\n",
    "                        'digit_onehotL':digit_onehotL,\n",
    "                        'color_onehotL':color_onehotL,\n",
    "                        'digit_onehotH':digit_onehotH,\n",
    "                        'color_onehotH':color_onehotH,\n",
    "                        'det_ll_dict':det_ll_dict,\n",
    "                        'det_hl_dict':det_hl_dict,\n",
    "                        'max_iter':2000,\n",
    "                        'tol':tol,\n",
    "                        'seed':seed\n",
    "                    }\n",
    "                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 276/2000 [00:00<00:02, 722.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at step 277/2000 with objective: 0.007532527204602957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "T_bary = run_empirical_bary_optim_new(**opt_params_bary)\n",
    "params_bary = {'L':{}, 'H':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_b'] = {\n",
    "                                'optimization_params': params_bary,\n",
    "                                'T_matrix': T_bary\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSACA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empirical_objective_no_max(U_L, U_H, T, digit_onehotL, color_onehotL, digit_onehotH, color_onehotH, Ill, omega):\n",
    "\n",
    "    loss_iota = 0\n",
    "    for iota in Ill:\n",
    "       \n",
    "        det_ll = det_ll_dict[iota]\n",
    "        det_hl = det_hl_dict[omega[iota]]\n",
    "\n",
    "        endo_ll = det_ll + U_L  \n",
    "        endo_ll_full = torch.cat([\n",
    "            endo_ll, \n",
    "            torch.tensor(digit_onehotL, dtype=endo_ll.dtype, device=endo_ll.device),\n",
    "            torch.tensor(color_onehotL, dtype=endo_ll.dtype, device=endo_ll.device)\n",
    "        ], dim=1) \n",
    "        endo_hl = det_hl + U_H  \n",
    "        endo_hl_full = torch.cat([\n",
    "            endo_hl,\n",
    "            torch.tensor(digit_onehotH, dtype=endo_hl.dtype, device=endo_hl.device),\n",
    "            torch.tensor(color_onehotH, dtype=endo_hl.dtype, device=endo_hl.device)\n",
    "        ], dim=1) \n",
    "        mapped_ll = (T @ endo_ll_full.T).T  \n",
    "\n",
    "        diff = mapped_ll - endo_hl_full\n",
    "\n",
    "        loss_iota += torch.norm(diff, p='fro')**2 / (diff.shape[0] * diff.shape[1])\n",
    "\n",
    "    loss = loss_iota / len(Ill)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_empirical_smooth_optimization(U_L, U_H, Ill, digit_onehotL, color_onehotL, digit_onehotH, color_onehotH, omega, eta_min,\n",
    "                                    num_steps_min, max_iter, tol, seed,\n",
    "                                    noise_sigma, num_noise_samples):\n",
    "    \"\"\"\n",
    "    Run empirical optimization with randomized smoothing.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    U_L = torch.as_tensor(U_L, dtype=torch.float32)\n",
    "    U_H = torch.as_tensor(U_H, dtype=torch.float32)\n",
    "    \n",
    "    N, l = U_L.shape\n",
    "    _, h = U_H.shape\n",
    "    \n",
    "    T = torch.randn(21, 3092, requires_grad=True)\n",
    "    optimizer_T = torch.optim.Adam([T], lr=eta_min)\n",
    "    \n",
    "    prev_T_objective = float('inf')\n",
    "    \n",
    "    for iteration in tqdm(range(max_iter)):\n",
    "        objs_T = []\n",
    "        \n",
    "        for _ in range(num_steps_min):\n",
    "            optimizer_T.zero_grad()\n",
    "            \n",
    "            smoothed_objective = torch.tensor(0.0)\n",
    "            \n",
    "            for _ in range(num_noise_samples):\n",
    "                # Add noise to T\n",
    "                noise = torch.randn_like(T) * noise_sigma\n",
    "                noisy_T = T + noise\n",
    "                \n",
    "                T_objective = empirical_objective_no_max(\n",
    "                    U_L, U_H, noisy_T, digit_onehotL, color_onehotL, digit_onehotH, color_onehotH, Ill, omega\n",
    "                )\n",
    "                smoothed_objective += T_objective\n",
    "            \n",
    "            smoothed_objective /= num_noise_samples\n",
    "            objs_T.append(smoothed_objective.item())\n",
    "            \n",
    "            \n",
    "            smoothed_objective.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_([T], max_norm=1.0)\n",
    "            \n",
    "            optimizer_T.step()\n",
    "            \n",
    "            # Check for NaN\n",
    "            if torch.isnan(T).any():\n",
    "                print(\"T contains NaN! Returning zero matrix.\")\n",
    "                print('Failed at step:', iteration + 1)\n",
    "                return torch.zeros_like(T).detach()\n",
    "        \n",
    "        # Check convergence of T's objective\n",
    "        with torch.no_grad():\n",
    "            current_T_objective = smoothed_objective.item()\n",
    "            if abs(prev_T_objective - current_T_objective) < tol:\n",
    "                print(f\"Converged at iteration {iteration + 1}\")\n",
    "                break\n",
    "            prev_T_objective = current_T_objective\n",
    "            \n",
    "    opt_params = {'L': {}, 'H': {}}\n",
    "    return opt_params, T.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_smooth = {\n",
    "                        'U_L': U_L,\n",
    "                        'U_H': U_H,\n",
    "                        'Ill': Ill_relevant,\n",
    "                        'digit_onehotL': digit_onehotL,\n",
    "                        'color_onehotL': color_onehotL,\n",
    "                        'digit_onehotH': digit_onehotH,\n",
    "                        'color_onehotH': color_onehotH,\n",
    "                        'omega': omega,\n",
    "                        'eta_min': eta_min,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'max_iter': 300,\n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'noise_sigma': 0.1,\n",
    "                        'num_noise_samples': 10\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [39:24<00:00,  7.88s/it]\n"
     ]
    }
   ],
   "source": [
    "params_smooth, T_smooth = run_empirical_smooth_optimization(**opt_params_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_s'] = {\n",
    "                                'optimization_params': params_smooth,\n",
    "                                'T_matrix': T_smooth\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(diroca_train_results_empirical, f\"data/{experiment}/diroca_train_results_empirical.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
