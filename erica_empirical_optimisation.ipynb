{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a28ac6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/vn/9swzhgj513q7n9gd_4vsbd840000gn/T/ipykernel_7314/3146703639.py\", line 3, in <module>\n",
      "    from src.CBN import CausalBayesianNetwork as CBN\n",
      "  File \"/Users/giofelekis/Desktop/ERiCA/src/CBN.py\", line 4, in <module>\n",
      "    from pgmpy.models import BayesianNetwork\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/pgmpy/__init__.py\", line 1, in <module>\n",
      "    from .global_vars import config\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/pgmpy/global_vars.py\", line 4, in <module>\n",
      "    import torch\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp \n",
    "from src.CBN import CausalBayesianNetwork as CBN\n",
    "import modularised_utils as mut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "\n",
    "from scipy.stats import wasserstein_distance_nd\n",
    "\n",
    "import params\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5279c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'synth1_gnd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69768f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# subprocess.run(['python', 'params.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21bf6a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the radius of the Wasserstein balls (epsilon, delta) and the size for both models.\n",
    "epsilon         = params.radius[experiment][0]\n",
    "ll_num_envs     = params.n_envs[experiment][0]\n",
    "\n",
    "delta           = params.radius[experiment][1]\n",
    "hl_num_envs     = params.n_envs[experiment][1]\n",
    "\n",
    "# Define the number of samples per environment. Currently every environment has the same number of samples\n",
    "num_llsamples   = params.n_samples[experiment][0]\n",
    "num_hlsamples   = params.n_samples[experiment][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01341509",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dll = mut.load_samples(experiment)[None][0]\n",
    "Gll = mut.load_ll_model(experiment)[0]\n",
    "Ill = mut.load_ll_model(experiment)[1]\n",
    "\n",
    "\n",
    "Dhl = mut.load_samples(experiment)[None][1]\n",
    "Ghl = mut.load_hl_model(experiment)[0]\n",
    "Ihl = mut.load_hl_model(experiment)[1]\n",
    "\n",
    "omega = mut.load_omega_map(experiment)\n",
    "\n",
    "num_llvars      = Dll.shape[1]\n",
    "num_hlvars      = Dhl.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16fef938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giofelekis/opt/anaconda3/envs/erica/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "ll_coeffs = mut.get_mle_coefficients_gmm(Dll, Gll, weights=None, n_components=num_llvars)\n",
    "hl_coeffs = mut.get_mle_coefficients_gmm(Dhl, Ghl, weights=None, n_components=num_hlvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "966329bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_ll_hat, mu_U_ll_hat, Sigma_U_ll_hat = mut.lan_abduction(Dll, Gll, ll_coeffs)\n",
    "U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat = mut.lan_abduction(Dhl, Ghl, hl_coeffs)\n",
    "\n",
    "A_ll = mut.generate_perturbed_datasets(D = U_ll_hat, bound = epsilon, num_envs = ll_num_envs) #Low-level: A_epsilon\n",
    "A_hl = mut.generate_perturbed_datasets(D = U_hl_hat, bound = delta, num_envs = hl_num_envs) #High-level A_delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ced89cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLmodels = {}\n",
    "for iota in Ill:\n",
    "    LLmodels[iota] = lanm.LinearAddSCM(Gll, ll_coeffs, iota)\n",
    "    \n",
    "HLmodels, Dhl_samples = {}, {}\n",
    "for eta in Ihl:\n",
    "    HLmodels[eta] = lanm.LinearAddSCM(Ghl, hl_coeffs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ced86cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized T: [[4.40233870e-02 5.24051282e-01 2.84222149e-11]\n",
      " [5.00478745e-02 5.85633066e-01 2.11665540e-11]]\n",
      "Optimized Theta: [[0.32837565 0.75562743 0.15067658]\n",
      " [0.46114388 0.98786115 0.81417388]\n",
      " [0.83813587 0.26627572 0.60100954]\n",
      " ...\n",
      " [0.76923449 0.91967435 0.3551281 ]\n",
      " [0.24663028 0.3930757  0.15834196]\n",
      " [0.29023167 0.41256838 0.48609085]]\n",
      "Optimized Phi: [[0.35156436 0.76006632]\n",
      " [0.36504361 0.50266474]\n",
      " [0.53557355 0.4831303 ]\n",
      " ...\n",
      " [0.08081637 0.69483101]\n",
      " [0.64751276 0.70658683]\n",
      " [0.46724663 0.33484956]]\n"
     ]
    }
   ],
   "source": [
    "U_L = U_ll_hat\n",
    "U_H = U_hl_hat\n",
    "\n",
    "num_samples, n = U_L.shape\n",
    "num_samples, m = U_H.shape\n",
    "\n",
    "epsilon = 1.0  # Radius of the Wasserstein ball for the low-level model\n",
    "delta   = 1.0  # Radius of the Wasserstein ball for the high-level model\n",
    "alpha   = 0.01 # Learning rate for ascent steps in Theta and Phi\n",
    "\n",
    "# Initialize variables\n",
    "T     = np.random.rand(m, n)\n",
    "Theta = np.random.rand(num_samples, n)\n",
    "Phi   = np.random.rand(num_samples, m)\n",
    "\n",
    "# Project onto Frobenius ball function\n",
    "def project_onto_frobenius_ball(matrix, radius):\n",
    "    norm = np.linalg.norm(matrix, 'fro')\n",
    "    if norm > radius:\n",
    "        return matrix * (radius / norm)\n",
    "    return matrix\n",
    "\n",
    "# Update function for T \n",
    "def update_T(U_L, U_H, Theta, Phi):\n",
    "    T_var = cp.Variable((m, n), nonneg=True)\n",
    "    objective = 0\n",
    "    for iota in Ill:\n",
    "        Li = LLmodels[iota].compute_mechanism() \n",
    "        Hi = HLmodels[omega[iota]].compute_mechanism()\n",
    "        A  = T_var @ Li @ (U_L.T + Theta.T) - Hi @ (U_H.T + Phi.T)\n",
    "\n",
    "        objective += cp.norm(A, \"fro\")**2\n",
    "\n",
    "    objective = cp.Minimize(objective / num_samples)\n",
    "    prob      = cp.Problem(objective)\n",
    "    prob.solve()\n",
    "    return T_var.value\n",
    "\n",
    "# Gradient ascent step for Theta\n",
    "def ascent_step_Theta(U_L, U_H, T, Phi, Theta, epsilon, alpha):\n",
    "    gradient = np.zeros_like(Theta)\n",
    "    for iota in Ill:\n",
    "        Li = LLmodels[iota].compute_mechanism() \n",
    "        Hi = HLmodels[omega[iota]].compute_mechanism()\n",
    "        A  = T @ Li @ (U_L.T + Theta.T) - Hi @ (U_H.T + Phi.T)\n",
    "\n",
    "        gradient += ((T @ Li).T @ A).T  # Compute gradient wrt Theta\n",
    "\n",
    "    gradient /= num_samples\n",
    "    Theta += alpha * gradient  # Ascent step\n",
    "    return project_onto_frobenius_ball(Theta, np.sqrt(num_samples * epsilon**2))\n",
    "\n",
    "# Gradient ascent step for Phi\n",
    "def ascent_step_Phi(U_L, U_H, T, Theta, Phi, delta, alpha):\n",
    "    gradient = np.zeros_like(Phi)\n",
    "    for iota in Ill:\n",
    "        Li = LLmodels[iota].compute_mechanism() \n",
    "        Hi = HLmodels[omega[iota]].compute_mechanism()\n",
    "        A  = T @ Li @ (U_L.T + Theta.T) - Hi @ (U_H.T + Phi.T)\n",
    "\n",
    "        gradient += (Hi @ A).T  # Compute gradient wrt Phi\n",
    "\n",
    "    gradient /= num_samples\n",
    "    Phi += alpha * gradient  # Ascent step\n",
    "    return project_onto_frobenius_ball(Phi, np.sqrt(num_samples * delta**2))\n",
    "\n",
    "# Main optimization loop\n",
    "max_iters = 100\n",
    "tol = 1e-4\n",
    "\n",
    "for iteration in range(max_iters):\n",
    "    T_prev, Theta_prev, Phi_prev = T.copy(), Theta.copy(), Phi.copy()\n",
    "\n",
    "    # Minimize wrt T\n",
    "    T = update_T(U_L, U_H, Theta, Phi)\n",
    "\n",
    "    # Maximize wrt Theta and Phi using gradient ascent\n",
    "    Theta = ascent_step_Theta(U_L, U_H, T, Phi, Theta, epsilon, alpha)\n",
    "    Phi   = ascent_step_Phi(U_L, U_H, T, Theta, Phi, delta, alpha)\n",
    "\n",
    "    # Check for convergence\n",
    "    if (np.linalg.norm(T - T_prev, 'fro') < tol and\n",
    "        np.linalg.norm(Theta - Theta_prev, 'fro') < tol and\n",
    "        np.linalg.norm(Phi - Phi_prev, 'fro') < tol):\n",
    "        print(f\"Converged in {iteration + 1} iterations.\")\n",
    "        break\n",
    "\n",
    "# Final optimized values of T, Theta, and Phi\n",
    "print(\"Optimized T:\", T)\n",
    "print(\"Optimized Theta:\", Theta)\n",
    "print(\"Optimized Phi:\", Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c944c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample = np.array([1.5, 2.5, 3.5])\n",
    "mapped_point = T @ x_sample\n",
    "print(f'{x_sample} maps to {mapped_point}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fef1594",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WITHOUT CVXPY\n",
    "U_L = U_ll_hat\n",
    "U_H = U_hl_hat\n",
    "\n",
    "num_samples, n = U_L.shape\n",
    "num_samples, m = U_H.shape\n",
    "\n",
    "# Parameters\n",
    "epsilon = 1.0\n",
    "delta = 1.0\n",
    "alpha = 0.01  # Learning rate for ascent steps in Theta and Phi\n",
    "learning_rate_T = 0.001  # Learning rate for descent step in T\n",
    "\n",
    "# Initialize primal and dual variables\n",
    "T = np.random.rand(m, n)\n",
    "Theta = np.random.rand(num_samples, n)\n",
    "Phi = np.random.rand(num_samples, m)\n",
    "\n",
    "# Define a function to project onto Frobenius ball\n",
    "def project_onto_frobenius_ball(matrix, radius):\n",
    "    norm = np.linalg.norm(matrix, 'fro')\n",
    "    if norm > radius:\n",
    "        return matrix * (radius / norm)\n",
    "    return matrix\n",
    "\n",
    "# Define a function to project onto the non-negative orthant\n",
    "def project_onto_non_negative(matrix):\n",
    "    return np.maximum(matrix, 0)\n",
    "\n",
    "# Gradient descent step for T\n",
    "def descent_step_T(U_L, U_H, T, Theta, Phi, learning_rate_T):\n",
    "    gradient = np.zeros_like(T)\n",
    "    for iota in Ill:\n",
    "        Li = LLmodels[iota].compute_mechanism() \n",
    "        Hi = HLmodels[omega[iota]].compute_mechanism()\n",
    "        A = T @ Li @ (U_L.T + Theta.T) - Hi @ (U_H.T + Phi.T)\n",
    "        \n",
    "        # Compute gradient with respect to T\n",
    "        gradient += A @ (Li @ (U_L.T + Theta.T)).T\n",
    "        \n",
    "    gradient /= num_samples\n",
    "    T = T - learning_rate_T * gradient  # Gradient descent step\n",
    "    return project_onto_non_negative(T)  # Ensure non-negativity\n",
    "\n",
    "# Gradient ascent step for Theta\n",
    "def ascent_step_Theta(U_L, U_H, T, Phi, Theta, epsilon, alpha):\n",
    "    gradient = np.zeros_like(Theta)\n",
    "    for iota in Ill:\n",
    "        Li = LLmodels[iota].compute_mechanism() \n",
    "        Hi = HLmodels[omega[iota]].compute_mechanism()\n",
    "        A = T @ Li @ (U_L.T + Theta.T) - Hi @ (U_H.T + Phi.T)\n",
    "\n",
    "        gradient += ((T @ Li).T @ A).T  # Compute gradient wrt Theta\n",
    "\n",
    "    gradient /= num_samples\n",
    "    Theta += alpha * gradient  # Ascent step\n",
    "    return project_onto_frobenius_ball(Theta, np.sqrt(num_samples * epsilon**2))\n",
    "\n",
    "# Gradient ascent step for Phi\n",
    "def ascent_step_Phi(U_L, U_H, T, Theta, Phi, delta, alpha):\n",
    "    gradient = np.zeros_like(Phi)\n",
    "    for iota in Ill:\n",
    "        Li = LLmodels[iota].compute_mechanism() \n",
    "        Hi = HLmodels[omega[iota]].compute_mechanism()\n",
    "        A = T @ Li @ (U_L.T + Theta.T) - Hi @ (U_H.T + Phi.T)\n",
    "\n",
    "        gradient += (Hi @ A).T  # Compute gradient wrt Phi\n",
    "\n",
    "    gradient /= num_samples\n",
    "    Phi += alpha * gradient  # Ascent step\n",
    "    return project_onto_frobenius_ball(Phi, np.sqrt(num_samples * delta**2))\n",
    "\n",
    "# Main optimization loop\n",
    "max_iters = 100\n",
    "tol = 1e-4\n",
    "\n",
    "for iteration in range(max_iters):\n",
    "    T_prev, Theta_prev, Phi_prev = T.copy(), Theta.copy(), Phi.copy()\n",
    "\n",
    "    # Gradient descent step for T\n",
    "    T = descent_step_T(U_L, U_H, T, Theta, Phi, learning_rate_T)\n",
    "\n",
    "    # Gradient ascent steps for Theta and Phi\n",
    "    Theta = ascent_step_Theta(U_L, U_H, T, Phi, Theta, epsilon, alpha)\n",
    "    Phi = ascent_step_Phi(U_L, U_H, T, Theta, Phi, delta, alpha)\n",
    "\n",
    "    # Check for convergence\n",
    "    if (np.linalg.norm(T - T_prev, 'fro') < tol and\n",
    "        np.linalg.norm(Theta - Theta_prev, 'fro') < tol and\n",
    "        np.linalg.norm(Phi - Phi_prev, 'fro') < tol):\n",
    "        print(f\"Converged in {iteration + 1} iterations.\")\n",
    "        break\n",
    "\n",
    "# Final optimized values of T, Theta, and Phi\n",
    "print(\"Optimized T:\", T)\n",
    "print(\"Optimized Theta:\", Theta)\n",
    "print(\"Optimized Phi:\", Phi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7df312e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstraction_errors             = {}\n",
    "# abstraction_env_errors         = {}\n",
    "# max_env_avg_interv_error_value = -np.inf\n",
    "# max_env_avg_interv_error_key   = None\n",
    "\n",
    "# for lenv in A_ll:\n",
    "#     for henv in A_hl:\n",
    "#         total_ui_error = 0\n",
    "#         num_distros    = len(Ill)\n",
    "\n",
    "#         T  = mut.sample_stoch_matrix(num_hlvars, num_llvars) # sample the abstraction map/matrix\n",
    "\n",
    "#         for iota in Ill:\n",
    "#             llcm   = LLmodels[iota]\n",
    "#             hlcm   = HLmodels[omega[iota]]\n",
    "#             llmech = llcm.compute_mechanism()\n",
    "#             hlmech = hlcm.compute_mechanism()\n",
    "\n",
    "#             lefthh = T @ (llmech @ lenv.T)\n",
    "#             righthh = hlmech @ henv.T\n",
    "#             #print(rig)\n",
    "#             error = wasserstein_distance_nd(lefthh, righthh)\n",
    "#             #error = mut.mat_jsd_distance(T@(llmech @ lenv.T), hlmech @ henv.T)\n",
    "#             #error = mut.mat_ot_wasserstein_distance(T@(llmech @ lenv.T), hlmech @ henv.T)\n",
    "#             #error  = mut.mat_wasserstein_distance(T@(llmech @ lenv.T), hlmech @ henv.T)\n",
    "            \n",
    "#             #print(error,'\\n')\n",
    "#             total_ui_error += error\n",
    "\n",
    "#         avg_interv_error = total_ui_error/num_distros\n",
    "\n",
    "#         if avg_interv_error > max_env_avg_interv_error_value:\n",
    "#             max_env_avg_interv_error_value = avg_interv_error\n",
    "#             max_env_avg_interv_error_key   = (lenv, henv)\n",
    "\n",
    "#         abstraction_errors[str(T)] = avg_interv_error\n",
    "#         #abstraction_env_errors['ll: '+str(ll_environment.means_)+' hl: '+str(hl_environment.means_)] = avg_interv_error\n",
    "\n",
    "# max_tau   = max(abstraction_errors, key=abstraction_errors.get)\n",
    "# max_error = abstraction_errors[max_tau]\n",
    "\n",
    "# print(f\"Abstraction: {max_tau}, Error: {max_error}\")\n",
    "# max_lenv = max_env_avg_interv_error_key[0]\n",
    "# max_henv = max_env_avg_interv_error_key[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d2c81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
