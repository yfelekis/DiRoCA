{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56dc4554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import opt_utilities as optu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d570838",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'slc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "390ab7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f\"data/{experiment}\"\n",
    "\n",
    "low_model = joblib.load(f\"{path}/LLmodel.pkl\")\n",
    "high_model = joblib.load(f\"{path}/HLmodel.pkl\")\n",
    "abstraction_data = joblib.load(f\"{path}/abstraction_data.pkl\")\n",
    "\n",
    "G_ll = low_model['graph']\n",
    "n_varsll = len(G_ll.nodes())\n",
    "I_ll_relevant = low_model['intervention_set']\n",
    "D_ll = low_model['data']\n",
    "LLmodels = low_model['scm_instances']\n",
    "muL, SigmaL = low_model['noise_dist']['mu'], low_model['noise_dist']['sigma']\n",
    "\n",
    "G_hl = high_model['graph']\n",
    "n_varshl = len(G_hl.nodes())\n",
    "I_hl_relevant = high_model['intervention_set']\n",
    "D_hl = high_model['data']\n",
    "HLmodels = high_model['scm_instances']\n",
    "muH, SigmaH = high_model['noise_dist']['mu'], high_model['noise_dist']['sigma']\n",
    "\n",
    "T = abstraction_data['T']\n",
    "omega = abstraction_data['omega']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0eb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Hyperparameters configured and grouped into a dictionary.\n",
      "  - Number of K-fold splits to generate: 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hyperparameters = {\n",
    "    # Regularization parameters\n",
    "    'lambda_L': 0.6,\n",
    "    'lambda_H': 0.3,\n",
    "    'lambda_param_L': 0.2,\n",
    "    'lambda_param_H': 0.1,\n",
    "    \n",
    "    # Optimization parameters\n",
    "    'eta_max': 0.001,\n",
    "    'eta_min': 0.001,\n",
    "    'max_iter': 1000,\n",
    "    'num_steps_min': 5,\n",
    "    'num_steps_max': 2,\n",
    "    'tol': 1e-4,\n",
    "\n",
    "    # K-Fold Cross-Validation settings\n",
    "    'k_folds': 5,\n",
    "    'random_state': 42, # For reproducible folds\n",
    "\n",
    "    # Method flags from your original code\n",
    "    'xavier': False,\n",
    "    'project_onto_gelbrich': True,\n",
    "    'proximal_grad': True,\n",
    "    'grad_clip': True,\n",
    "    'robust_L': True,\n",
    "    'robust_H': True\n",
    "}\n",
    "\n",
    "print(\"âœ“ Hyperparameters configured and grouped into a dictionary.\")\n",
    "print(f\"  - Number of K-fold splits to generate: {hyperparameters['k_folds']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d85827f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Created and saved 5 cross-validation folds to:\n",
      "  'data/slc/cv_folds.pkl'\n"
     ]
    }
   ],
   "source": [
    "# --- Prepare and Save K-Fold Splits ---\n",
    "num_total_samples = D_ll[None].shape[0]\n",
    "\n",
    "kf = KFold(n_splits=hyperparameters['k_folds'], \n",
    "           shuffle=True, \n",
    "           random_state=hyperparameters['random_state'])\n",
    "\n",
    "# 3. Generate and store the train/test indices for each fold\n",
    "fold_indices = []\n",
    "for train_index, test_index in kf.split(np.arange(num_total_samples)):\n",
    "    fold_indices.append({'train': train_index, 'test': test_index})\n",
    "\n",
    "# 4. Save the fold definitions to the experiment's data folder for later use\n",
    "folds_path = f\"data/{experiment}/cv_folds.pkl\"\n",
    "joblib.dump(fold_indices, folds_path)\n",
    "\n",
    "print(f\"âœ“ Created and saved {len(fold_indices)} cross-validation folds to:\")\n",
    "print(f\"  '{folds_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc45e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Assembling parameters for Fold 0 ---\n",
      "\n",
      "âœ“ Assembled final optimization parameters for one fold.\n",
      "The 'opt_params' dictionary is now ready to be passed to your optimization routine.\n",
      "\n",
      "Keys in opt_params: ['lambda_L', 'lambda_H', 'lambda_param_L', 'lambda_param_H', 'eta_max', 'eta_min', 'max_iter', 'num_steps_min', 'num_steps_max', 'tol', 'k_folds', 'random_state', 'xavier', 'project_onto_gelbrich', 'proximal_grad', 'grad_clip', 'robust_L', 'robust_H', 'LLmodels', 'HLmodels', 'omega', 'experiment', 'initial_theta', 'theta_hatL', 'theta_hatH']\n"
     ]
    }
   ],
   "source": [
    "# --- Cell 6: Prepare a Single Fold for Optimization ---\n",
    "\n",
    "# 1. Load the pre-defined folds we just saved\n",
    "folds_path = f\"data/{experiment}/cv_folds.pkl\"\n",
    "fold_indices = joblib.load(folds_path)\n",
    "\n",
    "# 2. Select the first fold (fold 0) as an example\n",
    "print(\"--- Assembling parameters for Fold 0 ---\")\n",
    "current_fold = fold_indices[0]\n",
    "train_idx, test_idx = current_fold['train'], current_fold['test']\n",
    "\n",
    "# You can create the train/test data splits for this fold if your function needs them\n",
    "# Dll_obs_train, Dll_obs_test = Dll_obs[train_idx], Dll_obs[test_idx]\n",
    "\n",
    "# 3. Assemble the final optimization parameter dictionary\n",
    "# Start with the general hyperparameters we defined earlier\n",
    "opt_params = hyperparameters.copy()\n",
    "\n",
    "# Add the models and mappings\n",
    "opt_params['LLmodels'] = LLmodels\n",
    "opt_params['HLmodels'] = HLmodels\n",
    "opt_params['omega'] = omega\n",
    "opt_params['experiment'] = experiment\n",
    "opt_params['initial_theta'] = 'empirical'\n",
    "\n",
    "train_n = len(train_idx)\n",
    "\n",
    "ll_bound = round(optu.compute_radius_lb(N=train_n, eta=0.05, c=1000), 3)\n",
    "hl_bound = round(optu.compute_radius_lb(N=train_n, eta=0.05, c=1000), 3)\n",
    "\n",
    "opt_params['theta_hatL'] = {\n",
    "    'mu_U': muL, \n",
    "    'Sigma_U': SigmaL, \n",
    "    'radius': ll_bound\n",
    "}\n",
    "opt_params['theta_hatH'] = {\n",
    "    'mu_U': muH, \n",
    "    'Sigma_U': SigmaH, \n",
    "    'radius': hl_bound\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8ae913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f00f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3060cf51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d892547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import yaml\n",
    "from sklearn.model_selection import KFold\n",
    "import opt_utilities as ut \n",
    "\n",
    "\n",
    "def load_all_data(experiment_name):\n",
    "    \"\"\"Loads all model blueprints and abstraction data for a given experiment.\"\"\"\n",
    "    path = f\"data/{experiment_name}\"\n",
    "    data = {\n",
    "        'LLmodel': joblib.load(f\"{path}/LLmodel.pkl\"),\n",
    "        'HLmodel': joblib.load(f\"{path}/HLmodel.pkl\"),\n",
    "        'abstraction_data': joblib.load(f\"{path}/abstraction_data.pkl\")\n",
    "    }\n",
    "    print(f\"Data loaded for '{experiment_name}'.\")\n",
    "\n",
    "    return data\n",
    "\n",
    "def prepare_cv_folds(observational_data, k, random_state, save_path):\n",
    "    \"\"\"Generates and saves K-Fold train/test indices.\"\"\"\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "    num_samples = observational_data.shape[0]\n",
    "    \n",
    "    fold_indices = [{'train': train_idx, 'test': test_idx} \n",
    "                    for train_idx, test_idx in kf.split(np.arange(num_samples))]\n",
    "    \n",
    "    joblib.dump(fold_indices, save_path)\n",
    "    print(f\"Created and saved {len(fold_indices)} folds to '{save_path}'\")\n",
    "    return fold_indices\n",
    "\n",
    "def assemble_fold_parameters(fold_indices, all_data, hyperparameters):\n",
    "    \"\"\"Assembles the final opt_params dictionary for a specific fold.\"\"\"\n",
    "    # Start with the general hyperparameters\n",
    "    opt_params = hyperparameters.copy()\n",
    "\n",
    "    # Add the core models and mappings\n",
    "    opt_params['LLmodels'] = all_data['LLmodel'].get('scm_collection')\n",
    "    opt_params['HLmodels'] = all_data['HLmodel'].get('scm_collection')\n",
    "    opt_params['omega'] = all_data['abstraction_data']['omega']\n",
    "    opt_params['experiment'] = all_data['experiment_name']\n",
    "    opt_params['initial_theta'] = 'empirical'\n",
    "    \n",
    "    # Calculate fold-specific radius\n",
    "    train_n  = len(fold_indices['train'])\n",
    "    ll_bound = round(ut.compute_radius_lb(N=train_n, eta=0.05, c=1000), 3)\n",
    "    hl_bound = round(ut.compute_radius_lb(N=train_n, eta=0.05, c=1000), 3)\n",
    "\n",
    "    # Add the final theta parameters\n",
    "    opt_params['theta_hatL'] = {\n",
    "                                    'mu_U': all_data['LLmodel']['noise_dist']['mu'], \n",
    "                                    'Sigma_U': all_data['LLmodel']['noise_dist']['sigma'], \n",
    "                                    'radius': ll_bound\n",
    "                                }\n",
    "    opt_params['theta_hatH'] = {\n",
    "                                    'mu_U': all_data['HLmodel']['noise_dist']['mu'], \n",
    "                                    'Sigma_U': all_data['HLmodel']['noise_dist']['sigma'], \n",
    "                                    'radius': hl_bound\n",
    "                                }\n",
    "    \n",
    "    return opt_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d23468e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for 'slc'.\n",
      "Created and saved 5 folds to 'data/slc/cv_folds.pkl'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment = 'slc'\n",
    "all_data = load_all_data(experiment)\n",
    "with open('configs/optimization_hyperparams.yaml', 'r') as f:\n",
    "    hyperparams = yaml.safe_load(f)\n",
    "\n",
    "# Add experiment name to the data dictionary for easy access\n",
    "all_data['experiment_name'] = experiment\n",
    "\n",
    "# 2. Prepare and save the cross-validation folds (a one-time setup)\n",
    "Dll_obs = all_data['LLmodel']['data'][None]\n",
    "folds_path = f\"data/{experiment}/cv_folds.pkl\"\n",
    "saved_folds = prepare_cv_folds(Dll_obs, hyperparams['k_folds'], hyperparams['seed'], folds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35840c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Cross-Validation for Fold 1/5 ---\n",
      "  - Training for Îµ=Î´ = 0.111\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_erica_optimization() got an unexpected keyword argument 'k_folds'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     32\u001b[0m params_for_run[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtheta_hatH\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mradius\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m eps_delta\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# c. Run the actual optimization\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#    This calls your function with all the prepared parameters.\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m trained_params, trained_T \u001b[38;5;241m=\u001b[39m oput\u001b[38;5;241m.\u001b[39mrun_erica_optimization(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams_for_run)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# d. Store the results in our nested dictionary\u001b[39;00m\n\u001b[1;32m     39\u001b[0m cv_results[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps_delta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimization_params\u001b[39m\u001b[38;5;124m'\u001b[39m: trained_params,\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m: trained_T\n\u001b[1;32m     42\u001b[0m }\n",
      "\u001b[0;31mTypeError\u001b[0m: run_erica_optimization() got an unexpected keyword argument 'k_folds'"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- The Main Optimization and Evaluation Loop ---\n",
    "\n",
    "# 1. Load the pre-defined folds\n",
    "folds_path = f\"data/{experiment}/cv_folds.pkl\"\n",
    "saved_folds = joblib.load(folds_path)\n",
    "\n",
    "# 2. Initialize a dictionary to store all results\n",
    "cv_results = {}\n",
    "\n",
    "# 3. Outer Loop: Iterate through each cross-validation fold\n",
    "for i, fold_info in enumerate(saved_folds):\n",
    "    print(f\"\\n--- Starting Cross-Validation for Fold {i+1}/{len(saved_folds)} ---\")\n",
    "    cv_results[f'fold_{i}'] = {}\n",
    "    \n",
    "    # Determine the fold-specific radius bound to include in our search\n",
    "    train_n = len(fold_info['train'])\n",
    "    ll_bound = round(ut.compute_radius_lb(N=train_n, eta=0.05, c=1000), 3)\n",
    "    \n",
    "    # Define the hyperparameter values to search over for this fold\n",
    "    eps_delta_values = [ll_bound, 1, 2, 4, 8]\n",
    "\n",
    "    # 4. Inner Loop: Iterate through each hyperparameter value (eps_delta)\n",
    "    for eps_delta in eps_delta_values:\n",
    "        print(f\"  - Training for Îµ=Î´ = {eps_delta}\")\n",
    "\n",
    "        # a. Assemble the base parameters for this specific fold\n",
    "        #    This uses the helper function we defined earlier.\n",
    "        params_for_run = assemble_fold_parameters(fold_info, all_data, hyperparams)\n",
    "        \n",
    "        # b. Update the radius for this specific run\n",
    "        params_for_run['theta_hatL']['radius'] = eps_delta\n",
    "        params_for_run['theta_hatH']['radius'] = eps_delta\n",
    "        \n",
    "        # c. Run the actual optimization\n",
    "        #    This calls your function with all the prepared parameters.\n",
    "        trained_params, trained_T = oput.run_erica_optimization(**params_for_run)\n",
    "        \n",
    "        # d. Store the results in our nested dictionary\n",
    "        cv_results[f'fold_{i}'][f'T_{eps_delta}'] = {\n",
    "            'optimization_params': trained_params,\n",
    "            'T_matrix': trained_T\n",
    "        }\n",
    "\n",
    "print(\"\\n\\n--- Optimization Complete ---\")\n",
    "print(f\"Results for all {len(saved_folds)} folds have been stored in the 'cv_results' dictionary.\")\n",
    "# print(\"Result structure:\", cv_results.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e44ef00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting 5-Fold Cross-Validation for experiment: 'slc'...\n",
      "\n",
      "--- Running Optimization for Fold 1/5 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m erica_args\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# c. Run the actual optimization for this fold\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m trained_params, trained_T \u001b[38;5;241m=\u001b[39m oput\u001b[38;5;241m.\u001b[39mrun_erica_optimization(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39merica_args)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# d. Store the important results from this fold\u001b[39;00m\n\u001b[1;32m     32\u001b[0m cv_results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfold\u001b[39m\u001b[38;5;124m'\u001b[39m: i,\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_indices\u001b[39m\u001b[38;5;124m'\u001b[39m: fold_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mT_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m: trained_T,\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimization_params\u001b[39m\u001b[38;5;124m'\u001b[39m: trained_params\n\u001b[1;32m     37\u001b[0m })\n",
      "File \u001b[0;32m~/Desktop/DiRoCA_TBS/opt_utils.py:1458\u001b[0m, in \u001b[0;36mrun_erica_optimization\u001b[0;34m(theta_hatL, theta_hatH, initial_theta, LLmodels, HLmodels, omega, lambda_L, lambda_H, lambda_param_L, lambda_param_H, xavier, project_onto_gelbrich, eta_min, eta_max, max_iter, num_steps_min, num_steps_max, proximal_grad, tol, seed, robust_L, robust_H, grad_clip, plot_steps, plot_epochs, display_results, experiment)\u001b[0m\n\u001b[1;32m   1455\u001b[0m mu_L_prev, Sigma_L_prev \u001b[38;5;241m=\u001b[39m mu_L\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone(), Sigma_L\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n\u001b[1;32m   1456\u001b[0m mu_H_prev, Sigma_H_prev \u001b[38;5;241m=\u001b[39m mu_H\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone(), mu_H\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mclone()\n\u001b[0;32m-> 1458\u001b[0m T_new, objective_T, T_objectives_epoch, hit_nan \u001b[38;5;241m=\u001b[39m optimize_min(\n\u001b[1;32m   1459\u001b[0m     T, mu_L, Sigma_L, mu_H, Sigma_H, LLmodels, HLmodels, omega,\n\u001b[1;32m   1460\u001b[0m     lambda_L, lambda_H, hat_mu_L, hat_mu_H, hat_Sigma_L, hat_Sigma_H,\n\u001b[1;32m   1461\u001b[0m     epsilon, delta, num_steps_min, optimizer_T, max_grad_norm, seed,\n\u001b[1;32m   1462\u001b[0m     project_onto_gelbrich, xavier)\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hit_nan:\n\u001b[1;32m   1465\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN encountered during optimization. Returning last valid state.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/DiRoCA_TBS/opt_utils.py:1372\u001b[0m, in \u001b[0;36moptimize_min\u001b[0;34m(T, mu_L, Sigma_L, mu_H, Sigma_H, LLmodels, HLmodels, omega, lambda_L, lambda_H, hat_mu_L, hat_mu_H, hat_Sigma_L, hat_Sigma_H, epsilon, delta, num_steps_min, optimizer_T, max_grad_norm, seed, project_onto_gelbrich, xavier)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize_min\u001b[39m(T, mu_L, Sigma_L, mu_H, Sigma_H, LLmodels, HLmodels, omega,\n\u001b[1;32m   1367\u001b[0m                  lambda_L, lambda_H, hat_mu_L, hat_mu_H, hat_Sigma_L, hat_Sigma_H,\n\u001b[1;32m   1368\u001b[0m                  epsilon, delta, num_steps_min, optimizer_T, max_grad_norm, seed,\n\u001b[1;32m   1369\u001b[0m                  project_onto_gelbrich, xavier):\n\u001b[1;32m   1371\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[0;32m-> 1372\u001b[0m     Ill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(LLmodels\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xavier:\n\u001b[1;32m   1375\u001b[0m         T \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mxavier_normal_(T, gain\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# --- The Main K-Fold Cross-Validation Loop ---\n",
    "\n",
    "# 1. Load the pre-defined folds and hyperparameters\n",
    "folds_path = f\"data/{experiment}/cv_folds.pkl\"\n",
    "saved_folds = joblib.load(folds_path)\n",
    "\n",
    "# 2. Initialize a list to store the results from each fold\n",
    "cv_results = []\n",
    "\n",
    "print(f\"ðŸš€ Starting {len(saved_folds)}-Fold Cross-Validation for experiment: '{experiment}'...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# 3. Outer Loop: Iterate through each cross-validation fold\n",
    "for i, fold_info in enumerate(saved_folds):\n",
    "    print(f\"\\n--- Running Optimization for Fold {i+1}/{len(saved_folds)} ---\")\n",
    "\n",
    "    # a. Assemble the base parameters for this specific fold\n",
    "    params_for_this_fold = assemble_fold_parameters(fold_info, all_data, hyperparams)\n",
    "    \n",
    "    # b. Prepare a clean dictionary for the optimization function\n",
    "    #    This removes keys that run_erica_optimization doesn't expect.\n",
    "    erica_args = params_for_this_fold.copy()\n",
    "    erica_args.pop('k_folds', None)\n",
    "    erica_args.pop('random_state', None)\n",
    "    \n",
    "    # c. Run the actual optimization for this fold\n",
    "    trained_params, trained_T = oput.run_erica_optimization(**erica_args)\n",
    "    \n",
    "    # d. Store the important results from this fold\n",
    "    cv_results.append({\n",
    "        'fold': i,\n",
    "        'test_indices': fold_info['test'],\n",
    "        'T_matrix': trained_T,\n",
    "        'optimization_params': trained_params\n",
    "    })\n",
    "    \n",
    "    print(f\"âœ“ Fold {i+1} complete.\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\n\\n--- Cross-Validation Finished ---\")\n",
    "print(f\"Total time: {end_time - start_time:.2f} seconds\")\n",
    "print(f\"Stored results for all {len(cv_results)} folds in the 'cv_results' list.\")\n",
    "\n",
    "# You can now save your final results\n",
    "results_path = f\"data/{experiment}/cv_results.pkl\"\n",
    "joblib.dump(cv_results, results_path)\n",
    "print(f\"âœ“ Final results saved to '{results_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4c39d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b84ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5616df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e9339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a141d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0ea199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ada770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f3206a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9cb385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a28ac6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import modularised_utils as mut\n",
    "import opt_utils as oput \n",
    "import evaluation_utils as evut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import params\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e651d550",
   "metadata": {},
   "source": [
    "# Experiments set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677de9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment       = 'synth1' # or 'lucas6x3'\n",
    "coeff_estimation = False #assumes knowledge of the structural functions when set to False\n",
    "\n",
    "num_llsamples, num_hlsamples  = params.n_samples[experiment]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccf37e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/synth1/Dhl_obs_test.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dll_obs  = mut.load_samples(experiment)[None][0] \n",
    "Gll, Ill = mut.load_model(experiment, 'LL')\n",
    "n_varsll = len(Gll.nodes())\n",
    "\n",
    "Dhl_obs  = mut.load_samples(experiment)[None][1] \n",
    "Ghl, Ihl = mut.load_model(experiment, 'HL')\n",
    "n_varshl = len(Ghl.nodes())\n",
    "\n",
    "omega    = mut.load_omega_map(experiment)\n",
    "\n",
    "test_size = 0.1\n",
    "\n",
    "Dll_obs, Dll_obs_test = train_test_split(Dll_obs, test_size=test_size, random_state=42)\n",
    "Dhl_obs, Dhl_obs_test = train_test_split(Dhl_obs, test_size=test_size, random_state=42)\n",
    "\n",
    "joblib.dump(Dll_obs_test, f\"data/{experiment}/Dll_obs_test.pkl\")\n",
    "joblib.dump(Dhl_obs_test, f\"data/{experiment}/Dhl_obs_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9fb9e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if coeff_estimation == True:\n",
    "    ll_coeffs = mut.get_coefficients(Dll_obs, Gll)\n",
    "    hl_coeffs = mut.get_coefficients(Dhl_obs, Ghl) \n",
    "else:\n",
    "    ll_coeffs = mut.load_coeffs(experiment, 'LL')\n",
    "    hl_coeffs = mut.load_coeffs(experiment, 'HL')\n",
    "\n",
    "U_ll_hat, mu_U_ll_hat, Sigma_U_ll_hat = mut.lan_abduction(Dll_obs, Gll, ll_coeffs)\n",
    "U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat = mut.lan_abduction(Dhl_obs, Ghl, hl_coeffs)\n",
    "\n",
    "LLmodels = {}\n",
    "for iota in Ill:\n",
    "    LLmodels[iota] = lanm.LinearAddSCM(Gll, ll_coeffs, iota)\n",
    "    \n",
    "HLmodels = {}\n",
    "for eta in Ihl:\n",
    "    HLmodels[eta] = lanm.LinearAddSCM(Ghl, hl_coeffs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af9fae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<operations.Intervention at 0x163a20e00>: <Linear_Additive_Noise_Models.LinearAddSCM at 0x160c924b0>,\n",
       " <operations.Intervention at 0x163a22a20>: <Linear_Additive_Noise_Models.LinearAddSCM at 0x16332ae70>,\n",
       " <operations.Intervention at 0x163a21b50>: <Linear_Additive_Noise_Models.LinearAddSCM at 0x163a21040>,\n",
       " <operations.Intervention at 0x163a22930>: <Linear_Additive_Noise_Models.LinearAddSCM at 0x163a23350>,\n",
       " <operations.Intervention at 0x163a22c00>: <Linear_Additive_Noise_Models.LinearAddSCM at 0x16360c9b0>,\n",
       " None: <Linear_Additive_Noise_Models.LinearAddSCM at 0x163a23500>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac61576",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(LLmodels, f\"data/{experiment}/LLmodels.pkl\")\n",
    "joblib.dump(HLmodels, f\"data/{experiment}/HLmodels.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92881a41",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1047b",
   "metadata": {},
   "source": [
    "### Diroca_e,d optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e63c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_bound = round(mut.compute_radius_lb(N=num_llsamples, eta=0.05, c=1000), 3)\n",
    "hl_bound = round(mut.compute_radius_lb(N=num_hlsamples, eta=0.05, c=1000), 3)\n",
    "\n",
    "print(f\"LL bound: {ll_bound}, HL bound: {hl_bound}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e7182b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hatL   = {'mu_U': mu_U_ll_hat, 'Sigma_U': Sigma_U_ll_hat, 'radius': ll_bound} #epsilonL\n",
    "theta_hatH   = {'mu_U': mu_U_hl_hat, 'Sigma_U': Sigma_U_hl_hat, 'radius': hl_bound} #epsilonH\n",
    "\n",
    "lambda_L = .6 \n",
    "\n",
    "lambda_H = .3 \n",
    "\n",
    "lambda_param_L = .2 \n",
    "lambda_param_H = .1 \n",
    "\n",
    "xavier = False\n",
    "project_onto_gelbrich = True\n",
    "\n",
    "eta_max = 0.001\n",
    "eta_min = 0.001\n",
    "\n",
    "max_iter = 1000\n",
    "num_steps_min = 5\n",
    "num_steps_max = 2\n",
    "\n",
    "robust_L = True \n",
    "robust_H = True\n",
    "\n",
    "proximal_grad = True\n",
    "\n",
    "tol = 1e-4\n",
    "grad_clip = True\n",
    "\n",
    "seed = 23\n",
    "\n",
    "plot_steps = False\n",
    "plot_epochs = False\n",
    "display_results = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1544367",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_erica =  {\n",
    "                        'theta_hatL': theta_hatL,\n",
    "                        'theta_hatH': theta_hatH,\n",
    "                        'initial_theta': 'empirical',\n",
    "                        'LLmodels': LLmodels,\n",
    "                        'HLmodels': HLmodels,\n",
    "                        'omega': omega,\n",
    "                        'lambda_L': lambda_L,\n",
    "                        'lambda_H': lambda_H,\n",
    "                        'lambda_param_L': lambda_param_L,\n",
    "                        'lambda_param_H': lambda_param_H,\n",
    "                        'xavier': xavier, \n",
    "                        'project_onto_gelbrich': project_onto_gelbrich, \n",
    "                        'eta_max': eta_max,\n",
    "                        'eta_min': eta_min,\n",
    "                        'max_iter': max_iter,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'num_steps_max': num_steps_max,\n",
    "                        'proximal_grad': proximal_grad,\n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'robust_L': robust_L,\n",
    "                        'robust_H': robust_H,\n",
    "                        'grad_clip': grad_clip,\n",
    "                        'plot_steps': plot_steps,\n",
    "                        'plot_epochs': plot_epochs,\n",
    "                        'display_results': display_results,\n",
    "                        'experiment': experiment\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e3e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_delta_values     = [8, ll_bound, 1, 2, 4]\n",
    "diroca_train_results = {}\n",
    "\n",
    "for eps_delta in eps_delta_values:\n",
    "    print(f\"Training for Îµ=Î´ = {eps_delta}\")\n",
    "\n",
    "    # Update theta parameters\n",
    "    opt_params_erica['theta_hatL']['radius'] = eps_delta\n",
    "    opt_params_erica['theta_hatH']['radius'] = eps_delta\n",
    "    \n",
    "    # Run DIROCA optimization\n",
    "    params_erica_prox, T_erica_prox = oput.run_erica_optimization(**opt_params_erica)\n",
    "    \n",
    "    diroca_train_results['T_'+str(eps_delta)] = {\n",
    "                                                    'optimization_params': params_erica_prox,\n",
    "                                                    'T_matrix': T_erica_prox\n",
    "                                                }\n",
    "\n",
    "print(\"\\nTraining completed.\")\n",
    "print(\"Available Îµ=Î´ values:\", list(diroca_train_results.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677a5bbf",
   "metadata": {},
   "source": [
    "### 2. GRADCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943088ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_Lenrico, T_enrico = oput.run_erica_optimization(**{**opt_params_erica, 'robust_L': False, 'robust_H': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac0196be",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results['T_0.00'] = {\n",
    "                                'optimization_params': params_Lenrico,\n",
    "                                'T_matrix': T_enrico\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b55cd2",
   "metadata": {},
   "source": [
    "### 3. BARYCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa744410",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_method = 'svd'\n",
    "initialization = 'avg'\n",
    "autograd = False\n",
    "seed = seed\n",
    "max_iter = max_iter\n",
    "tol = tol\n",
    "display_results = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32f0d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_bary =  {\n",
    "                    'theta_L': theta_hatL,\n",
    "                    'theta_H': theta_hatH,\n",
    "                    'LLmodels': LLmodels,\n",
    "                    'HLmodels': HLmodels,\n",
    "                    'Ill': Ill,\n",
    "                    'Ihl': Ihl,\n",
    "                    'projection_method': projection_method,\n",
    "                    'initialization': initialization,\n",
    "                    'autograd': autograd,\n",
    "                    'seed': seed,\n",
    "                    'max_iter': max_iter,\n",
    "                    'tol': tol,\n",
    "                    'display_results': display_results\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e79d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_bary, T_bary = oput.barycentric_optimization(**opt_params_bary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f2440b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results['T_b'] = {\n",
    "                                'optimization_params': params_bary,\n",
    "                                'T_matrix': T_bary\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8711745",
   "metadata": {},
   "source": [
    "## Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec63215",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(diroca_train_results, f\"data/{experiment}/diroca_train_results.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
