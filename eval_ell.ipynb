{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35fe35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import utilities as ut\n",
    "import modularised_utils as mut\n",
    "import scipy.stats as stats\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbee5ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'slc'\n",
    "path = f\"data/{experiment}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34efba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded for 'slc'.\n",
      "Successfully loaded results for all optimization methods.\n",
      "  - DIROCA results keys: ['fold_0', 'fold_1']\n",
      "  - GradCA results keys: ['fold_0', 'fold_1']\n",
      "  - BARYCA results keys: ['fold_0', 'fold_1']\n"
     ]
    }
   ],
   "source": [
    "# Load the dictionaries containing the results for each optimization method\n",
    "diroca_results = joblib.load(f\"{path}/diroca_cv_results.pkl\")\n",
    "gradca_results = joblib.load(f\"{path}/gradca_cv_results.pkl\")\n",
    "baryca_results = joblib.load(f\"{path}/baryca_cv_results.pkl\")\n",
    "\n",
    "# Also load the original data dictionary\n",
    "all_data = ut.load_all_data(experiment)\n",
    "\n",
    "print(\"Successfully loaded results for all optimization methods.\")\n",
    "print(f\"  - DIROCA results keys: {list(diroca_results.keys())}\")\n",
    "print(f\"  - GradCA results keys: {list(gradca_results.keys())}\")\n",
    "print(f\"  - BARYCA results keys: {list(baryca_results.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f30c72ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper function 'calculate_abstraction_error' is defined.\n"
     ]
    }
   ],
   "source": [
    "def calculate_abstraction_error(T_matrix, Dll_test, Dhl_test):\n",
    "    \"\"\"\n",
    "    Calculates the \"0-shift\" abstraction error for a given T matrix on a test set.\n",
    "\n",
    "    This function works in the space of distribution parameters:\n",
    "    1. It estimates Gaussian parameters (mean, cov) from the LL and HL test samples.\n",
    "    2. It transforms the LL Gaussian's parameters using the T matrix.\n",
    "    3. It computes the Wasserstein distance between the transformed LL distribution\n",
    "       and the actual HL distribution.\n",
    "    \n",
    "    Args:\n",
    "        T_matrix (np.ndarray): The learned abstraction matrix.\n",
    "        Dll_test (np.ndarray): The low-level endogenous test samples.\n",
    "        Dhl_test (np.ndarray): The high-level endogenous test samples.\n",
    "        \n",
    "    Returns:\n",
    "        float: The calculated Wasserstein-2 distance.\n",
    "    \"\"\"\n",
    "    # 1. Estimate parameters from the low-level test data\n",
    "    mu_L_test    = np.mean(Dll_test, axis=0)\n",
    "    Sigma_L_test = np.cov(Dll_test, rowvar=False)\n",
    "\n",
    "    # 2. Estimate parameters from the high-level test data\n",
    "    mu_H_test    = np.mean(Dhl_test, axis=0)\n",
    "    Sigma_H_test = np.cov(Dhl_test, rowvar=False)\n",
    "\n",
    "    # 3. Transform the low-level parameters using the T matrix\n",
    "    # This projects the low-level distribution into the high-level space\n",
    "    mu_V_predicted    = mu_L_test @ T_matrix.T\n",
    "    Sigma_V_predicted = T_matrix @ Sigma_L_test @ T_matrix.T\n",
    "    \n",
    "    # 4. Compute the Wasserstein distance between the two resulting Gaussians\n",
    "    # Assuming 'oput.compute_wasserstein' is the function you provided\n",
    "    try:\n",
    "        # Your function returns the squared distance, so we take the sqrt\n",
    "        wasserstein_dist = np.sqrt(mut.compute_wasserstein(mu_V_predicted, Sigma_V_predicted, mu_H_test, Sigma_H_test))\n",
    "    except Exception as e:\n",
    "        print(f\"  - Warning: Could not compute Wasserstein distance. Error: {e}. Returning NaN.\")\n",
    "        return np.nan\n",
    "\n",
    "    return wasserstein_dist\n",
    "\n",
    "print(\"✓ Helper function 'calculate_abstraction_error' is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "64e39174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Unpack the necessary data collections from your loaded data\n",
    "Dll_samples = all_data['LLmodel']['data']\n",
    "Dhl_samples = all_data['HLmodel']['data']\n",
    "I_ll_relevant = all_data['LLmodel']['intervention_set']\n",
    "omega = all_data['abstraction_data']['omega']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2c5d3e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluating method: DIROCA --\n",
      "-- Evaluating method: GradCA --\n",
      "-- Evaluating method: BARYCA --\n",
      "\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Displaying the average '0-shift' error (across all interventions) for every run:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>fold</th>\n",
       "      <th>run_id</th>\n",
       "      <th>avg_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DIROCA</td>\n",
       "      <td>0</td>\n",
       "      <td>eps_delta_8</td>\n",
       "      <td>1.280884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DIROCA</td>\n",
       "      <td>1</td>\n",
       "      <td>eps_delta_8</td>\n",
       "      <td>1.286380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradCA</td>\n",
       "      <td>0</td>\n",
       "      <td>gradca_run</td>\n",
       "      <td>1.265300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradCA</td>\n",
       "      <td>1</td>\n",
       "      <td>gradca_run</td>\n",
       "      <td>1.273351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BARYCA</td>\n",
       "      <td>0</td>\n",
       "      <td>baryca_run</td>\n",
       "      <td>2.641450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BARYCA</td>\n",
       "      <td>1</td>\n",
       "      <td>baryca_run</td>\n",
       "      <td>2.625743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   method  fold       run_id  avg_error\n",
       "0  DIROCA     0  eps_delta_8   1.280884\n",
       "1  DIROCA     1  eps_delta_8   1.286380\n",
       "2  GradCA     0   gradca_run   1.265300\n",
       "3  GradCA     1   gradca_run   1.273351\n",
       "4  BARYCA     0   baryca_run   2.641450\n",
       "5  BARYCA     1   baryca_run   2.625743"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Summary (Mean Error ± Std Dev across all folds) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradCA</th>\n",
       "      <th>gradca_run</th>\n",
       "      <td>1.269326</td>\n",
       "      <td>0.005692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIROCA</th>\n",
       "      <th>eps_delta_8</th>\n",
       "      <td>1.283632</td>\n",
       "      <td>0.003887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARYCA</th>\n",
       "      <th>baryca_run</th>\n",
       "      <td>2.633597</td>\n",
       "      <td>0.011107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean       std\n",
       "method run_id                         \n",
       "GradCA gradca_run   1.269326  0.005692\n",
       "DIROCA eps_delta_8  1.283632  0.003887\n",
       "BARYCA baryca_run   2.633597  0.011107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Main Evaluation Loop (Averaged Over All Interventions) ---\n",
    "\n",
    "# 1. Create a list to store a record for each evaluation run\n",
    "evaluation_records = []\n",
    "\n",
    "# 2. Group all your results dictionaries together for easy iteration\n",
    "results_to_evaluate = {\n",
    "    \"DIROCA\": diroca_results,\n",
    "    \"GradCA\": gradca_results,\n",
    "    \"BARYCA\": baryca_results\n",
    "    # You can add other baselines like Abs-LiNGAM here\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# 4. Loop through each method, fold, and hyperparameter run\n",
    "for method_name, results_dict in results_to_evaluate.items():\n",
    "    print(f\"-- Evaluating method: {method_name} --\")\n",
    "    for fold_key, fold_results in results_dict.items():\n",
    "        for run_key, run_data in fold_results.items():\n",
    "            \n",
    "            # a. Get the learned T matrix and test indices for this run\n",
    "            T_learned = run_data['T_matrix']\n",
    "            test_indices = run_data['test_indices']\n",
    "            \n",
    "            # b. NEW: Loop over all interventions to get an average error\n",
    "            errors_per_intervention = []\n",
    "            for iota in I_ll_relevant:\n",
    "                # Get the correct slice of test data for this intervention\n",
    "                Dll_test_iota = Dll_samples[iota][test_indices]\n",
    "                Dhl_test_iota = Dhl_samples[omega[iota]][test_indices]\n",
    "                \n",
    "                # Calculate the abstraction error for this specific intervention\n",
    "                error = calculate_abstraction_error(T_learned, Dll_test_iota, Dhl_test_iota)\n",
    "                if not np.isnan(error):\n",
    "                    errors_per_intervention.append(error)\n",
    "            \n",
    "            # c. Calculate the final error as the average over all interventions\n",
    "            average_error = np.mean(errors_per_intervention) if errors_per_intervention else np.nan\n",
    "            \n",
    "            # d. Store the result in a structured record\n",
    "            record = {\n",
    "                'method': method_name,\n",
    "                'fold': int(fold_key.split('_')[1]),\n",
    "                'run_id': run_key,\n",
    "                'avg_error': average_error # Store the new average error\n",
    "            }\n",
    "            evaluation_records.append(record)\n",
    "\n",
    "# 5. Convert the list of records into a pandas DataFrame for easy analysis\n",
    "results_df = pd.DataFrame(evaluation_records)\n",
    "\n",
    "print(\"\\n\\n--- Evaluation Complete ---\")\n",
    "print(\"Displaying the average '0-shift' error (across all interventions) for every run:\")\n",
    "display(results_df)\n",
    "\n",
    "# 6. Calculate and display the final summary statistics\n",
    "print(\"\\n--- Final Summary (Mean Error ± Std Dev across all folds) ---\")\n",
    "summary_stats = results_df.groupby(['method', 'run_id'])['avg_error'].agg(['mean', 'std']).sort_values('mean')\n",
    "display(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68343c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce1fed0a",
   "metadata": {},
   "source": [
    "## rho-shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07427490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Final generalized helper function 'apply_shift' is defined.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def apply_shift(clean_data, shift_config, all_var_names, model_level, seed=42):\n",
    "    \"\"\"\n",
    "    Applies a specified contamination to the test data with full flexibility.\n",
    "    - Handles different shift types (additive, multiplicative).\n",
    "    - Handles different distributions (gaussian, student-t, exponential).\n",
    "    - Handles selective application to a subset of variables.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    shift_type = shift_config.get('type')\n",
    "    dist_type = shift_config.get('distribution', 'gaussian')\n",
    "    n_samples, n_dims = clean_data.shape\n",
    "\n",
    "    # Select the correct parameter dictionary for the current model level\n",
    "    level_key = 'll_params' if model_level == 'L' else 'hl_params'\n",
    "    params = shift_config.get(level_key, {})\n",
    "    \n",
    "    # --- 1. Generate the full noise matrix based on the specified distribution ---\n",
    "    noise_matrix = np.zeros_like(clean_data)\n",
    "    if dist_type == 'gaussian':\n",
    "        mu = np.array(params.get('mu', np.zeros(n_dims)))\n",
    "        sigma_def = params.get('sigma', np.eye(n_dims))\n",
    "        sigma = np.diag(np.array(sigma_def)) if np.array(sigma_def).ndim == 1 else np.array(sigma_def)\n",
    "        noise_matrix = np.random.multivariate_normal(mean=mu, cov=sigma, size=n_samples)\n",
    "\n",
    "    elif dist_type == 'student-t':\n",
    "        df = params.get('df', 3)\n",
    "        loc = np.array(params.get('loc', np.zeros(n_dims)))\n",
    "        shape_def = params.get('shape', np.eye(n_dims))\n",
    "        shape = np.diag(np.array(shape_def)) if np.array(shape_def).ndim == 1 else np.array(shape_def)\n",
    "        noise_matrix = stats.multivariate_t.rvs(loc=loc, shape=shape, df=df, size=n_samples)\n",
    "\n",
    "    elif dist_type == 'exponential':\n",
    "        scale = params.get('scale', 1.0)\n",
    "        noise_matrix = np.random.exponential(scale=scale, size=(n_samples, n_dims))\n",
    "    \n",
    "    # --- 2. Apply noise selectively if specified ---\n",
    "    final_noise = np.zeros_like(clean_data)\n",
    "    vars_to_affect = params.get('apply_to_vars')\n",
    "\n",
    "    if vars_to_affect is None:\n",
    "        # If not specified, apply noise to all variables\n",
    "        final_noise = noise_matrix\n",
    "    else:\n",
    "        # If specified, apply noise only to the selected columns\n",
    "        try:\n",
    "            indices_to_affect = [all_var_names.index(var) for var in vars_to_affect]\n",
    "            final_noise[:, indices_to_affect] = noise_matrix[:, indices_to_affect]\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: A variable in 'apply_to_vars' not found. Error: {e}\")\n",
    "            return clean_data # Return clean data if there's a config error\n",
    "\n",
    "    # --- 3. Return the contaminated data ---\n",
    "    if shift_type == 'additive':\n",
    "        return clean_data + final_noise\n",
    "    elif shift_type == 'multiplicative':\n",
    "        return clean_data * final_noise\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown shift type: {shift_type}\")\n",
    "\n",
    "print(\"✓ Final generalized helper function 'apply_shift' is defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea3ffd7",
   "metadata": {},
   "source": [
    "## Configuration Guide for \"Rho-Shift\" Evaluation\n",
    "\n",
    "The entire \"rho-shift\" evaluation is controlled by a single Python dictionary named `shift_config`. By changing the keys and values in this dictionary, you can test a wide variety of data contamination scenarios.\n",
    "\n",
    "### Top-Level Keys\n",
    "\n",
    "These keys define the main type of contamination to apply.\n",
    "\n",
    "* `type: str`: Determines the primary operation.\n",
    "    * **Options:** `'translation'`, `'scaling'`, `'additive'`, `'multiplicative'`.\n",
    "\n",
    "* `distribution: str` (Used only for `additive` and `multiplicative` types): Determines the type of random noise to generate.\n",
    "    * **Options:** `'gaussian'`, `'student-t'`, `'exponential'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb564d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 'rho-shift' evaluation with shift type: 'additive'\n",
      "-- Evaluating method's robustness: DIROCA --\n",
      "-- Evaluating method's robustness: GradCA --\n",
      "-- Evaluating method's robustness: BARYCA --\n",
      "\n",
      "\n",
      "--- 'Rho-Shift' Evaluation Complete ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradCA</th>\n",
       "      <th>gradca_run</th>\n",
       "      <td>1.964032</td>\n",
       "      <td>0.005390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIROCA</th>\n",
       "      <th>eps_delta_8</th>\n",
       "      <td>2.062791</td>\n",
       "      <td>0.009017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARYCA</th>\n",
       "      <th>baryca_run</th>\n",
       "      <td>4.353293</td>\n",
       "      <td>0.024379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean       std\n",
       "method run_id                         \n",
       "GradCA gradca_run   1.964032  0.005390\n",
       "DIROCA eps_delta_8  2.062791  0.009017\n",
       "BARYCA baryca_run   4.353293  0.024379"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "shift_config = {\n",
    "    'type': 'additive',\n",
    "    'distribution': 'student-t',  # Can be 'gaussian', 'student-t', or 'exponential'\n",
    "    \n",
    "    'll_params': {\n",
    "        'df': 3,\n",
    "        'loc': [0, 0, 0],\n",
    "        'shape': [0.5, 2.0, 1.0] # Define diagonal elements of the scale matrix\n",
    "    },\n",
    "    'hl_params': {\n",
    "        'df': 5,\n",
    "        'loc': [0, 0],\n",
    "        'shape': [[0.8, -0.3], [-0.3, 0.8]] # Define a full scale matrix\n",
    "    }\n",
    "}\n",
    "\n",
    "# 2. Prepare necessary variables\n",
    "print(f\"Running 'rho-shift' evaluation with shift type: '{shift_config['type']}'\")\n",
    "rho_shift_records = []\n",
    "ll_var_names = list(all_data['LLmodel']['graph'].nodes())\n",
    "hl_var_names = list(all_data['HLmodel']['graph'].nodes())\n",
    "\n",
    "# 3. Main evaluation loop\n",
    "for method_name, results_dict in results_to_evaluate.items():\n",
    "    print(f\"-- Evaluating method's robustness: {method_name} --\")\n",
    "    for fold_key, fold_results in results_dict.items():\n",
    "        for run_key, run_data in fold_results.items():\n",
    "            \n",
    "            T_learned = run_data['T_matrix']\n",
    "            test_indices = run_data['test_indices']\n",
    "            \n",
    "            errors_per_intervention = []\n",
    "            for iota in I_ll_relevant:\n",
    "                Dll_test_clean = Dll_samples[iota][test_indices]\n",
    "                Dhl_test_clean = Dhl_samples[omega[iota]][test_indices]\n",
    "                \n",
    "                # Apply the shift, now providing the list of variable names\n",
    "                Dll_test_noisy = apply_shift(Dll_test_clean, shift_config, ll_var_names, model_level='L')\n",
    "                Dhl_test_noisy = apply_shift(Dhl_test_clean, shift_config, hl_var_names, model_level='H')\n",
    "                \n",
    "                error = calculate_abstraction_error(T_learned, Dll_test_noisy, Dhl_test_noisy)\n",
    "                if not np.isnan(error):\n",
    "                    errors_per_intervention.append(error)\n",
    "            \n",
    "            average_error = np.mean(errors_per_intervention) if errors_per_intervention else np.nan\n",
    "            \n",
    "            record = {\n",
    "                'method': method_name,\n",
    "                'fold': int(fold_key.split('_')[1]),\n",
    "                'run_id': run_key,\n",
    "                'avg_error_noisy': average_error\n",
    "            }\n",
    "            rho_shift_records.append(record)\n",
    "\n",
    "# 4. Display Final Results\n",
    "rho_shift_df = pd.DataFrame(rho_shift_records)\n",
    "print(\"\\n\\n--- 'Rho-Shift' Evaluation Complete ---\")\n",
    "summary = rho_shift_df.groupby(['method', 'run_id'])['avg_error_noisy'].agg(['mean', 'std']).sort_values('mean')\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5e1a88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6761a787",
   "metadata": {},
   "source": [
    "# Huber contamination logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d81209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_shift(clean_data, shift_config, all_var_names, model_level, seed=42):\n",
    "    \"\"\"\n",
    "    Applies a specified contamination to the test data with full flexibility.\n",
    "    - Handles different shift types (additive, multiplicative).\n",
    "    - Handles different distributions (gaussian, student-t, exponential).\n",
    "    - Handles selective application to a subset of variables.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    shift_type = shift_config.get('type')\n",
    "    dist_type = shift_config.get('distribution', 'gaussian')\n",
    "    n_samples, n_dims = clean_data.shape\n",
    "\n",
    "    # Select the correct parameter dictionary for the current model level\n",
    "    level_key = 'll_params' if model_level == 'L' else 'hl_params'\n",
    "    params = shift_config.get(level_key, {})\n",
    "    \n",
    "    # --- 1. Generate the full noise matrix based on the specified distribution ---\n",
    "    noise_matrix = np.zeros_like(clean_data)\n",
    "    if dist_type == 'gaussian':\n",
    "        mu = np.array(params.get('mu', np.zeros(n_dims)))\n",
    "        sigma_def = params.get('sigma', np.eye(n_dims))\n",
    "        sigma = np.diag(np.array(sigma_def)) if np.array(sigma_def).ndim == 1 else np.array(sigma_def)\n",
    "        noise_matrix = np.random.multivariate_normal(mean=mu, cov=sigma, size=n_samples)\n",
    "\n",
    "    elif dist_type == 'student-t':\n",
    "        df = params.get('df', 3)\n",
    "        loc = np.array(params.get('loc', np.zeros(n_dims)))\n",
    "        shape_def = params.get('shape', np.eye(n_dims))\n",
    "        shape = np.diag(np.array(shape_def)) if np.array(shape_def).ndim == 1 else np.array(shape_def)\n",
    "        noise_matrix = stats.multivariate_t.rvs(loc=loc, shape=shape, df=df, size=n_samples)\n",
    "\n",
    "    elif dist_type == 'exponential':\n",
    "        scale = params.get('scale', 1.0)\n",
    "        noise_matrix = np.random.exponential(scale=scale, size=(n_samples, n_dims))\n",
    "    \n",
    "    # --- 2. Apply noise selectively if specified ---\n",
    "    final_noise = np.zeros_like(clean_data)\n",
    "    vars_to_affect = params.get('apply_to_vars')\n",
    "\n",
    "    if vars_to_affect is None:\n",
    "        # If not specified, apply noise to all variables\n",
    "        final_noise = noise_matrix\n",
    "    else:\n",
    "        # If specified, apply noise only to the selected columns\n",
    "        try:\n",
    "            indices_to_affect = [all_var_names.index(var) for var in vars_to_affect]\n",
    "            final_noise[:, indices_to_affect] = noise_matrix[:, indices_to_affect]\n",
    "        except ValueError as e:\n",
    "            print(f\"Warning: A variable in 'apply_to_vars' not found. Error: {e}\")\n",
    "            return clean_data # Return clean data if there's a config error\n",
    "\n",
    "    # --- 3. Return the contaminated data ---\n",
    "    if shift_type == 'additive':\n",
    "        return clean_data + final_noise\n",
    "    elif shift_type == 'multiplicative':\n",
    "        return clean_data * final_noise\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown shift type: {shift_type}\")\n",
    "\n",
    "print(\"✓ Final generalized helper function 'apply_shift' is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032612ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper function 'apply_huber_contamination' is defined.\n"
     ]
    }
   ],
   "source": [
    "def apply_huber_contamination(clean_data, alpha, shift_config, all_var_names, model_level, seed=42):\n",
    "    \"\"\"\n",
    "    Contaminates a dataset using the Huber model. A fraction 'alpha' of the\n",
    "    samples are replaced with noisy versions.\n",
    "\n",
    "    Args:\n",
    "        clean_data (np.ndarray): The original, clean test data samples.\n",
    "        alpha (float): The fraction of data to contaminate (between 0 and 1).\n",
    "        shift_config (dict): Configuration defining the noise for the outliers.\n",
    "        all_var_names (list): List of all variable names for this data.\n",
    "        model_level (str): 'L' for low-level or 'H' for high-level.\n",
    "        \n",
    "    Returns:\n",
    "        np.ndarray: The new, contaminated test data.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    if not (0 <= alpha <= 1):\n",
    "        raise ValueError(\"Alpha must be between 0 and 1.\")\n",
    "\n",
    "    if alpha == 0:\n",
    "        return clean_data\n",
    "    \n",
    "    # Create the fully noisy version of the data using our existing function\n",
    "    noisy_data = apply_shift(clean_data, shift_config, all_var_names, model_level)\n",
    "    \n",
    "    if alpha == 1:\n",
    "        return noisy_data\n",
    "        \n",
    "    n_samples = clean_data.shape[0]\n",
    "    n_to_contaminate = int(alpha * n_samples)\n",
    "    \n",
    "    # Randomly select which rows to replace\n",
    "    indices_to_replace = np.random.choice(n_samples, n_to_contaminate, replace=False)\n",
    "    \n",
    "    # Start with a copy of the clean data\n",
    "    contaminated_data = clean_data.copy()\n",
    "    \n",
    "    # Replace the selected rows with their noisy versions\n",
    "    contaminated_data[indices_to_replace] = noisy_data[indices_to_replace]\n",
    "    \n",
    "    return contaminated_data\n",
    "\n",
    "print(\"✓ Helper function 'apply_huber_contamination' is defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c157b768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 'Huber-Shift' evaluation with alpha = 1.0\n",
      "-- Evaluating method's robustness: DIROCA --\n",
      "-- Evaluating method's robustness: GradCA --\n",
      "-- Evaluating method's robustness: BARYCA --\n",
      "\n",
      "\n",
      "--- 'Huber-Shift' Evaluation Complete ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>method</th>\n",
       "      <th>run_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradCA</th>\n",
       "      <th>gradca_run</th>\n",
       "      <td>1.964032</td>\n",
       "      <td>0.005390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIROCA</th>\n",
       "      <th>eps_delta_8</th>\n",
       "      <td>2.062791</td>\n",
       "      <td>0.009017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BARYCA</th>\n",
       "      <th>baryca_run</th>\n",
       "      <td>4.353293</td>\n",
       "      <td>0.024379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mean       std\n",
       "method run_id                         \n",
       "GradCA gradca_run   1.964032  0.005390\n",
       "DIROCA eps_delta_8  2.062791  0.009017\n",
       "BARYCA baryca_run   4.353293  0.024379"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- \"Huber-Shift\" Evaluation Loop ---\n",
    "\n",
    "# ======================================================================\n",
    "# 1. CONFIGURE YOUR HUBER TEST HERE\n",
    "# ======================================================================\n",
    "\n",
    "# Set the contamination level (e.g., 0.1 means 10% of data will be outliers)\n",
    "alpha = 1.0\n",
    "\n",
    "# Define the type of noise to use for the outliers\n",
    "shift_config = {\n",
    "    'type': 'additive',\n",
    "    'distribution': 'student-t',  # Can be 'gaussian', 'student-t', or 'exponential'\n",
    "    \n",
    "    'll_params': {\n",
    "        'df': 3,\n",
    "        'loc': [0, 0, 0],\n",
    "        'shape': [0.5, 2.0, 1.0] # Define diagonal elements of the scale matrix\n",
    "    },\n",
    "    'hl_params': {\n",
    "        'df': 5,\n",
    "        'loc': [0, 0],\n",
    "        'shape': [[0.8, -0.3], [-0.3, 0.8]] # Define a full scale matrix\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# 2. MAIN EVALUATION LOOP\n",
    "# ======================================================================\n",
    "\n",
    "print(f\"Running 'Huber-Shift' evaluation with alpha = {alpha}\")\n",
    "huber_shift_records = []\n",
    "\n",
    "for method_name, results_dict in results_to_evaluate.items():\n",
    "    print(f\"-- Evaluating method's robustness: {method_name} --\")\n",
    "    for fold_key, fold_results in results_dict.items():\n",
    "        for run_key, run_data in fold_results.items():\n",
    "            \n",
    "            T_learned = run_data['T_matrix']\n",
    "            test_indices = run_data['test_indices']\n",
    "            \n",
    "            errors_per_intervention = []\n",
    "            for iota in I_ll_relevant:\n",
    "                # a. Get the clean test data\n",
    "                Dll_test_clean = Dll_samples[iota][test_indices]\n",
    "                Dhl_test_clean = Dhl_samples[omega[iota]][test_indices]\n",
    "                \n",
    "                # b. Apply Huber contamination to create the test set\n",
    "                Dll_test_contaminated = apply_huber_contamination(Dll_test_clean, alpha, shift_config, ll_var_names, model_level='L')\n",
    "                Dhl_test_contaminated = apply_huber_contamination(Dhl_test_clean, alpha, shift_config, hl_var_names, model_level='H')\n",
    "                \n",
    "                # c. Calculate error on the CONTAMINATED data\n",
    "                error = calculate_abstraction_error(T_learned, Dll_test_contaminated, Dhl_test_contaminated)\n",
    "                if not np.isnan(error):\n",
    "                    errors_per_intervention.append(error)\n",
    "            \n",
    "            average_error = np.mean(errors_per_intervention) if errors_per_intervention else np.nan\n",
    "            \n",
    "            record = {\n",
    "                'method': method_name,\n",
    "                'fold': int(fold_key.split('_')[1]),\n",
    "                'run_id': run_key,\n",
    "                'avg_error_huber': average_error\n",
    "            }\n",
    "            huber_shift_records.append(record)\n",
    "\n",
    "# 3. Display Final Results\n",
    "huber_shift_df = pd.DataFrame(huber_shift_records)\n",
    "print(\"\\n\\n--- 'Huber-Shift' Evaluation Complete ---\")\n",
    "summary = huber_shift_df.groupby(['method', 'run_id'])['avg_error_huber'].agg(['mean', 'std']).sort_values('mean')\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822ab2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc662fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb13bf58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c249e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b4f9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bc963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c17e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9789e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358bf85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e67ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e857160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd0c47f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2773c108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a045693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b906fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a28ac6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "# Local modules\n",
    "import modularised_utils as mut\n",
    "import opt_utils as oput \n",
    "import evaluation_utils as evut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import params\n",
    "import random\n",
    "\n",
    "from math_utils import compute_wasserstein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3532da1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'synth1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "003375c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_results = joblib.load(f\"data/{experiment}/diroca_train_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "326791cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_estimation = True\n",
    "\n",
    "Dll_obs = joblib.load(f\"data/{experiment}/Dll_obs_test.pkl\")\n",
    "Dhl_obs = joblib.load(f\"data/{experiment}/Dhl_obs_test.pkl\")\n",
    "\n",
    "LLmodels = joblib.load(f\"data/{experiment}/LLmodels.pkl\")\n",
    "HLmodels = joblib.load(f\"data/{experiment}/HLmodels.pkl\")\n",
    "\n",
    "num_llsamples, num_hlsamples  = Dll_obs.shape[0], Dhl_obs.shape[0]\n",
    "\n",
    "Gll, Ill = mut.load_model(experiment, 'LL')\n",
    "Ghl, Ihl = mut.load_model(experiment, 'HL')\n",
    "\n",
    "n_varsll, n_varshl = len(Gll.nodes()), len(Ghl.nodes())\n",
    "\n",
    "omega    = mut.load_omega_map(experiment)\n",
    "\n",
    "if coeff_estimation == True:\n",
    "    ll_coeffs = mut.get_coefficients(Dll_obs, Gll)\n",
    "    hl_coeffs = mut.get_coefficients(Dhl_obs, Ghl) \n",
    "else:\n",
    "    ll_coeffs = mut.load_coeffs(experiment, 'LL')\n",
    "    hl_coeffs = mut.load_coeffs(experiment, 'HL')\n",
    "\n",
    "U_ll_hat, mu_U_ll_hat, Sigma_U_ll_hat = mut.lan_abduction(Dll_obs, Gll, ll_coeffs)\n",
    "U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat = mut.lan_abduction(Dhl_obs, Ghl, hl_coeffs)\n",
    "\n",
    "data = evut.generate_data(LLmodels, HLmodels, omega, num_llsamples, num_hlsamples, mu_U_ll_hat, Sigma_U_ll_hat, mu_U_hl_hat, Sigma_U_hl_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80fce0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_observ        = True \n",
    "test_interv        = True\n",
    "num_iter           = 100\n",
    "metric             = 'wass'\n",
    "\n",
    "if test_observ and test_interv:\n",
    "    test_data = data\n",
    "\n",
    "elif test_observ:\n",
    "    test_data = {None: data[None]}\n",
    "\n",
    "elif test_interv:\n",
    "    test_data = {k: v for k, v in data.items() if k is not None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b74d9ca",
   "metadata": {},
   "source": [
    "## 0-shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20534b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Has to be learnt with coeff = True as well. check opt_ell.ipynb'\n",
    "if coeff_estimation == True:\n",
    "    \n",
    "    results_single = {method: {'errors': [], 'mean': 0, 'ci': 0} for method in T_results.keys()}\n",
    "\n",
    "    for name, res in T_results.items():\n",
    "        T = res['T_matrix']\n",
    "        errors = []  # Store errors for each intervention\n",
    "        scale_factor = 1/np.sqrt(len(Ill))\n",
    "        wass_total = 0\n",
    "        for iota in Ill:\n",
    "            L_i = LLmodels[iota].F\n",
    "            V_i = T @ L_i\n",
    "            H_i = HLmodels[omega[iota]].F\n",
    "\n",
    "            muV    = V_i @ mu_U_ll_hat\n",
    "            sigmaV = V_i @ Sigma_U_ll_hat @ V_i.T\n",
    "            muH    = H_i @ mu_U_hl_hat\n",
    "            sigmaH = H_i @ Sigma_U_hl_hat @ H_i.T\n",
    "\n",
    "\n",
    "            # Compute Wasserstein metric\n",
    "            wass_dist = np.sqrt(mut.compute_wasserstein(muV, sigmaV, muH, sigmaH))\n",
    "            errors.append(wass_dist)\n",
    "            wass_total += wass_dist\n",
    "\n",
    "        # Calculate mean and CI\n",
    "        mean_error = np.mean(errors)\n",
    "        std_error = np.std(errors)\n",
    "        ci = std_error\n",
    "\n",
    "        # Store all statistics\n",
    "        results_single[name] = {\n",
    "            'errors': errors,\n",
    "            'mean': mean_error,\n",
    "            'ci': ci\n",
    "        }\n",
    "\n",
    "    results_single = dict(sorted(results_single.items(), key=lambda x: x[1]['mean']))\n",
    "    ll_coeffs = mut.load_coeffs(experiment, 'LL')\n",
    "    hl_coeffs = mut.load_coeffs(experiment, 'HL')\n",
    "else:\n",
    "    print('No coeff estimation')\n",
    "    \n",
    "# Print results\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"{'Method':<15} {'Error (mean ± std)':<35}\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for method, stats in results_single.items():\n",
    "    print(f\"{method:<15} {stats['mean']:>8.4f} ± {stats['ci']:<8.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df493378",
   "metadata": {},
   "source": [
    "## ρ-shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b64a080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_values = np.arange(0.05, 100.05, 10).tolist()  \n",
    "sample_forms = ['boundary', 'sample']\n",
    "\n",
    "center   = 'worst'\n",
    "coverage_type = 'uniform'\n",
    "\n",
    "hat_dict = {'L': [mu_U_ll_hat, Sigma_U_ll_hat], 'H': [mu_U_hl_hat, Sigma_U_hl_hat]}\n",
    "\n",
    "worst = 'T_8'\n",
    "mu_worst_L    = T_results[worst]['optimization_params']['L']['mu_U']\n",
    "Sigma_worst_L = T_results[worst]['optimization_params']['L']['Sigma_U']\n",
    "mu_worst_H    = T_results[worst]['optimization_params']['H']['mu_U']\n",
    "Sigma_worst_H = T_results[worst]['optimization_params']['H']['Sigma_U']\n",
    "\n",
    "worst_dict = {'L': [mu_worst_L, Sigma_worst_L], 'H': [mu_worst_H, Sigma_worst_H]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682047d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the r_sigma values to sweep over\n",
    "sigma_values = np.linspace(0, 1, 100)\n",
    "methods_to_track = list(T_results.keys())\n",
    "\n",
    "# Storage for plotting and for mean/CI across all sigmas\n",
    "error_evolution = {method: [] for method in methods_to_track}\n",
    "mean_across_sigmas = {method: [] for method in methods_to_track}\n",
    "ci_across_sigmas = {method: [] for method in methods_to_track}\n",
    "\n",
    "for r_sigma in sigma_values:\n",
    "    #print(f\"Testing with r_sigma = {r_sigma}\")\n",
    "    # Generate shifted Gaussian families for this sigma\n",
    "    shift_family_L = mut.generate_shifted_gaussian_family(\n",
    "        mu_worst_L, Sigma_worst_L, 1, r_mu=0, r_sigma=r_sigma, coverage='rand', seed=None)\n",
    "    shift_family_H = mut.generate_shifted_gaussian_family(\n",
    "        mu_worst_H, Sigma_worst_H, 1, r_mu=0, r_sigma=r_sigma, coverage='rand', seed=None)\n",
    "\n",
    "    # Initialize results for this sigma\n",
    "    results = {method: [] for method in methods_to_track}\n",
    "\n",
    "    for shift_L, shift_H in zip(shift_family_L, shift_family_H):\n",
    "        noise_muL, noise_SigmaL = shift_L\n",
    "        noise_muH, noise_SigmaH = shift_H\n",
    "        noise_muL = noise_muL.numpy() if hasattr(noise_muL, 'numpy') else noise_muL\n",
    "        noise_muH = noise_muH.numpy() if hasattr(noise_muH, 'numpy') else noise_muH\n",
    "        noise_SigmaL = noise_SigmaL.numpy() if hasattr(noise_SigmaL, 'numpy') else noise_SigmaL\n",
    "        noise_SigmaH = noise_SigmaH.numpy() if hasattr(noise_SigmaH, 'numpy') else noise_SigmaH\n",
    "\n",
    "        for name in methods_to_track:\n",
    "            res = T_results[name]\n",
    "            T = res['T_matrix']\n",
    "            wass_total = 0\n",
    "            for iota in Ill:\n",
    "                L_i = LLmodels[iota].F\n",
    "                V_i = T @ L_i\n",
    "                H_i = HLmodels[omega[iota]].F\n",
    "                muV = V_i @ noise_muL\n",
    "                sigmaV = V_i @ noise_SigmaL @ V_i.T\n",
    "                muH = H_i @ noise_muH\n",
    "                sigmaH = H_i @ noise_SigmaH @ H_i.T\n",
    "                wass_dist = np.sqrt(compute_wasserstein(muV, sigmaV, muH, sigmaH))\n",
    "                wass_total += wass_dist\n",
    "            results[name].append(wass_total / len(Ill))\n",
    "\n",
    "    # Store mean and CI for each method for this sigma\n",
    "    for method in methods_to_track:\n",
    "        mean = np.mean(results[method])\n",
    "        std = np.std(results[method])\n",
    "        ci = std/10\n",
    "        error_evolution[method].append(mean)\n",
    "        mean_across_sigmas[method].append(mean)\n",
    "        ci_across_sigmas[method].append(ci)\n",
    "\n",
    "# Print mean and CI across all sigmas for each method\n",
    "print(f\"\\n{'Method':<15} {'Mean across sigmas ± Std':<35}\")\n",
    "print(\"=\"*50)\n",
    "method_stats = []\n",
    "for method in methods_to_track:\n",
    "    mean_over_sigmas = np.mean(mean_across_sigmas[method])\n",
    "    std_over_sigmas = np.std(mean_across_sigmas[method])\n",
    "    ci_over_sigmas = std_over_sigmas\n",
    "    method_stats.append((method, mean_over_sigmas, ci_over_sigmas))\n",
    "# Sort by mean, descending (worst to best)\n",
    "method_stats.sort(key=lambda x: x[1], reverse=True)\n",
    "for method, mean, ci in method_stats:\n",
    "    print(f\"{method:<15} {mean:8.4f} ± {ci:<8.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f732879",
   "metadata": {},
   "source": [
    "## F-contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed9c2742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contaminate_structural_matrix(M, contamination_fraction, contamination_type, num_segments=10, seed=None):\n",
    "   \"\"\"\n",
    "   Contaminates a linear transformation matrix M to break its strict linearity.\n",
    "  \n",
    "   Args:\n",
    "       M (np.ndarray): Original linear transformation matrix (n x m).\n",
    "       contamination_fraction (float): Magnitude of contamination (e.g., between 0.05 and 1.0).\n",
    "       contamination_type (str): Type of contamination to apply. Options are:\n",
    "                                 'multiplicative', 'nonlinear', or 'piecewise'.\n",
    "       num_segments (int): Number of segments for piecewise linear contamination (default: 3).\n",
    "       seed (int, optional): Random seed for reproducibility.\n",
    "      \n",
    "   Returns:\n",
    "       np.ndarray: The contaminated matrix.\n",
    "   \"\"\"\n",
    "   rng = np.random.default_rng(seed)\n",
    "   M_cont = M.copy() \n",
    "   n, m = M.shape\n",
    "\n",
    "\n",
    "   if contamination_type == \"multiplicative\":\n",
    "       # Apply element-wise multiplicative noise (preserving zeros below the main diagonal)\n",
    "       # Only perturb the upper-triangular part.\n",
    "       noise = rng.uniform(low=1.0 - contamination_fraction, high=1.0 + contamination_fraction, size=M.shape)\n",
    "       # Create a mask for the upper triangular (including diagonal)\n",
    "       mask = np.triu(np.ones_like(M))\n",
    "       M_cont = M * (1 - mask + mask * noise)\n",
    "  \n",
    "   elif contamination_type == \"nonlinear\":\n",
    "       # Apply a nonlinear function to L: for instance, add a sine-based perturbation.\n",
    "       M_cont = M + contamination_fraction * np.sin(M)\n",
    "  \n",
    "   elif contamination_type == \"piecewise\":\n",
    "       # Contaminate each row with a piecewise linear function.\n",
    "       def piecewise_contaminate_row(row, cont_frac, segments, rng):\n",
    "           n_elem = len(row)\n",
    "           # Choose random breakpoints among indices\n",
    "           if segments < 2:\n",
    "               return row  # nothing to do\n",
    "           breakpoints = np.sort(rng.integers(low=1, high=n_elem, size=segments - 1))\n",
    "           breakpoints = np.concatenate(([0], breakpoints, [n_elem]))\n",
    "           contaminated_row = np.empty_like(row)\n",
    "           # For each segment, assign a random multiplicative factor.\n",
    "           for j in range(len(breakpoints) - 1):\n",
    "               start = breakpoints[j]\n",
    "               end = breakpoints[j+1]\n",
    "               factor = 1.0 + rng.uniform(low=-cont_frac, high=cont_frac)\n",
    "               contaminated_row[start:end] = row[start:end] * factor\n",
    "           return contaminated_row\n",
    "      \n",
    "       # Apply the piecewise contamination row-by-row.\n",
    "       for i in range(n):\n",
    "           M_cont[i, :] = piecewise_contaminate_row(M[i, :], contamination_fraction, num_segments, rng)\n",
    "  \n",
    "   else:\n",
    "       raise ValueError(\"Unknown contamination type. Choose among 'multiplicative', 'nonlinear', or 'piecewise'.\")\n",
    "  \n",
    "   return M_cont\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea99392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contamination levels to test\n",
    "contamination_levels = np.linspace(0.0, 1.0, 100)  \n",
    "for cont_type in ['piecewise']:\n",
    "    print(f\"Contamination type: {cont_type}\")\n",
    "    # Store results for plotting\n",
    "    plot_results = {method: {'means': [], 'stds': []} for method in T_results.keys()}\n",
    "\n",
    "\n",
    "    # Run experiment for each contamination level\n",
    "    for cont_frac in tqdm(contamination_levels):\n",
    "        abstraction_error = {name: [] for name in T_results.keys()}\n",
    "    \n",
    "        for _ in range(1):\n",
    "            noise_muL, noise_SigmaL = mu_U_ll_hat, Sigma_U_ll_hat\n",
    "            noise_muH, noise_SigmaH = mu_U_hl_hat, Sigma_U_hl_hat\n",
    "            \n",
    "            noise_muL    = noise_muL.numpy() if torch.is_tensor(noise_muL) else noise_muL\n",
    "            noise_muH    = noise_muH.numpy() if torch.is_tensor(noise_muH) else noise_muH\n",
    "            noise_SigmaL = noise_SigmaL.numpy() if torch.is_tensor(noise_SigmaL) else noise_SigmaL\n",
    "            noise_SigmaH = noise_SigmaH.numpy() if torch.is_tensor(noise_SigmaH) else noise_SigmaH\n",
    "\n",
    "            for name, res in T_results.items():\n",
    "                T = res['T_matrix']\n",
    "                total = 0\n",
    "                for iota in Ill:\n",
    "                    L_i = LLmodels[iota].F\n",
    "                    L_i = contaminate_structural_matrix(L_i, contamination_fraction=cont_frac, contamination_type=cont_type)\n",
    "                    V_i = T @ L_i\n",
    "                    H_i = HLmodels[omega[iota]].F\n",
    "                    H_i = contaminate_structural_matrix(H_i, contamination_fraction=cont_frac, contamination_type=cont_type)\n",
    "                    \n",
    "                    muV    = V_i @ noise_muL\n",
    "                    sigmaV = V_i @ noise_SigmaL @ V_i.T\n",
    "                    muH    = H_i @ noise_muH\n",
    "                    sigmaH = H_i @ noise_SigmaH @ H_i.T\n",
    "\n",
    "                    dist = np.sqrt(compute_wasserstein(muV, sigmaV, muH, sigmaH))\n",
    "\n",
    "                    total += dist\n",
    "\n",
    "\n",
    "                iter_avg = total / len(Ill)\n",
    "                abstraction_error[name].append(iter_avg)\n",
    "\n",
    "\n",
    "        # Store results for this contamination level\n",
    "        for method in T_results.keys():\n",
    "            mean_e = np.mean(abstraction_error[method])\n",
    "            std_e = np.std(abstraction_error[method])\n",
    "            plot_results[method]['means'].append(mean_e)\n",
    "            plot_results[method]['stds'].append(std_e)\n",
    "\n",
    "    # Compute averages across all contamination levels for each method\n",
    "    method_averages = {}\n",
    "\n",
    "    for method in T_results.keys():\n",
    "        # Get all means across contamination levels\n",
    "        all_means = plot_results[method]['means']\n",
    "        # Compute the mean and std across all contamination levels\n",
    "        overall_mean = np.mean(all_means)\n",
    "        overall_std = np.std(all_means)\n",
    "        method_averages[method] = (overall_mean, overall_std)\n",
    "\n",
    "    # Sort methods by average (worst to best)\n",
    "    sorted_methods = sorted(method_averages.items(), key=lambda x: x[1][0], reverse=True)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"AVERAGE WASSERSTEIN DISTANCE ACROSS ALL CONTAMINATION LEVELS (0.0 to 1.0)\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{'Method':<15} {'Mean ± std':<35}\")\n",
    "    print(\"-\"*100)\n",
    "\n",
    "    for method, (mean, std) in sorted_methods:\n",
    "        ci = std\n",
    "        print(f\"{method:<15} {mean:>8.4f} ± {ci:<8.4f}\")\n",
    "\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23a4128",
   "metadata": {},
   "source": [
    "## ω-contamination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cecbba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contaminate_omega_map(original_omega, num_misalignments):\n",
    "    \"\"\"\n",
    "    Randomly corrupt a subset of entries in the ω map to simulate mapping misspecification.\n",
    "    \n",
    "    Args:\n",
    "        original_omega (dict): Original intervention mapping.\n",
    "            For example: {None: None, iota1: H_i1, iota2: H_i1, iota3: H_i2, ...}\n",
    "        num_misalignments (int): Desired number of misaligned mappings.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A new ω mapping with up to num_misalignments entries altered.\n",
    "    \"\"\"\n",
    "    # Exclude keys or values that are None if desired.\n",
    "    omega_keys = [k for k in original_omega.keys() if k is not None]\n",
    "    omega_vals = [original_omega[k] for k in omega_keys if original_omega[k] is not None]\n",
    "    \n",
    "    # Start with a copy of the original mapping.\n",
    "    contaminated_omega = original_omega.copy()\n",
    "    \n",
    "    # Bound the number of misalignments by the number of eligible keys.\n",
    "    num_to_corrupt = min(num_misalignments, len(omega_keys))\n",
    "    \n",
    "    # Randomly select keys to corrupt.\n",
    "    to_corrupt = random.sample(omega_keys, k=num_to_corrupt)\n",
    "    \n",
    "    # Create a random permutation of available targets (ensuring change)\n",
    "    # Use the set of targets from eligible keys.\n",
    "    all_targets = list(set(omega_vals))\n",
    "    \n",
    "    for key in to_corrupt:\n",
    "        original_target = original_omega[key]\n",
    "        # Only corrupt if there's an alternative available.\n",
    "        available_targets = [t for t in all_targets if t != original_target]\n",
    "        if available_targets:\n",
    "            new_target = random.choice(available_targets)\n",
    "            contaminated_omega[key] = new_target\n",
    "            \n",
    "    return contaminated_omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b381ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contamination levels to test\n",
    "misalignment_levels = range(0, len(Ill))\n",
    "\n",
    "# Store results for plotting\n",
    "omega_plot_results = {method: {'means': [], 'stds': []} for method in T_results.keys()}\n",
    "\n",
    "\n",
    "# Run experiment for each contamination level\n",
    "for num_mis in tqdm(misalignment_levels):\n",
    "   abstraction_error = {name: [] for name in T_results.keys()}\n",
    "  \n",
    "   for _ in range(1):\n",
    "    noise_muL, noise_SigmaL = mu_U_ll_hat, Sigma_U_ll_hat\n",
    "    noise_muH, noise_SigmaH = mu_U_hl_hat, Sigma_U_hl_hat\n",
    "    \n",
    "    noise_muL    = noise_muL.numpy() if torch.is_tensor(noise_muL) else noise_muL\n",
    "    noise_muH    = noise_muH.numpy() if torch.is_tensor(noise_muH) else noise_muH\n",
    "    noise_SigmaL = noise_SigmaL.numpy() if torch.is_tensor(noise_SigmaL) else noise_SigmaL\n",
    "    noise_SigmaH = noise_SigmaH.numpy() if torch.is_tensor(noise_SigmaH) else noise_SigmaH\n",
    "\n",
    "    omega_cont = contaminate_omega_map(omega, num_mis)\n",
    "\n",
    "\n",
    "    for name, res in T_results.items():\n",
    "        T = res['T_matrix']\n",
    "        total = 0\n",
    "        for iota in Ill:\n",
    "            L_i = LLmodels[iota].F\n",
    "            V_i = T @ L_i\n",
    "            H_i = HLmodels[omega_cont[iota]].F\n",
    "            \n",
    "            muV    = V_i @ noise_muL\n",
    "            sigmaV = V_i @ noise_SigmaL @ V_i.T\n",
    "            muH    = H_i @ noise_muH\n",
    "            sigmaH = H_i @ noise_SigmaH @ H_i.T\n",
    "\n",
    "\n",
    "            dist = np.sqrt(compute_wasserstein(muV, sigmaV, muH, sigmaH))\n",
    "            total += dist\n",
    "\n",
    "\n",
    "        iter_avg = total / len(Ill)\n",
    "        abstraction_error[name].append(iter_avg)\n",
    "\n",
    "\n",
    "   # Store results for this contamination level\n",
    "   for method in T_results.keys():\n",
    "       mean_e = np.mean(abstraction_error[method])\n",
    "       std_e = np.std(abstraction_error[method])\n",
    "       omega_plot_results[method]['means'].append(mean_e)\n",
    "       omega_plot_results[method]['stds'].append(std_e)\n",
    "\n",
    "# Compute averages for each method\n",
    "method_averages = []\n",
    "for method in T_results.keys():\n",
    "    # Get all means across misalignment levels\n",
    "    all_means = omega_plot_results[method]['means']\n",
    "    # Compute overall mean and std\n",
    "    overall_mean = np.mean(all_means)\n",
    "    overall_std = np.std(all_means)\n",
    "    method_averages.append((method, overall_mean, overall_std))\n",
    "\n",
    "# Sort methods by mean (worst to best)\n",
    "method_averages.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print sorted averages\n",
    "for method, mean, std in method_averages:\n",
    "    ci = std\n",
    "    print(f\"{method:<15} {mean:>8.4f} ± {ci:<8.4f}\")\n",
    "\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c06790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
