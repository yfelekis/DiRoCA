{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ca742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : CUDA libraries not found or could not be loaded; Switching to CPU only.\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import joblib\n",
    "import pickle \n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import seaborn as sns\n",
    "import random \n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from src.CBN import CausalBayesianNetwork as CBN\n",
    "import modularised_utils as mut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "import evaluation_utils as evut\n",
    "import opt_utils as oput\n",
    "import params\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe511603",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'battery_discrete'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28cc3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_base = joblib.load('batteries/scms/M_WMG_bins_5_avg_2.pkl')\n",
    "M_abst = joblib.load('batteries/scms/M_LRCS_bins_5.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8977f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = joblib.load('batteries/dfs/df_WMG_bins_5_avg_2.pkl')\n",
    "df_abst = joblib.load('batteries/dfs/df_LRCS_bins_5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "451f8922",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base.drop(df_base.columns[[1,2]], axis=1, inplace=True)\n",
    "df_base.replace({75:0, 110:1, 150:2, 170:3, 180:4, 200:5}, inplace=True)\n",
    "\n",
    "df_abst.drop(df_abst.columns[[1]], axis=1, inplace=True)\n",
    "df_abst.replace({75:0, 100:1, 200:2}, inplace=True)\n",
    "\n",
    "# Rename columns to match graph\n",
    "df_base = df_base.rename(columns={\n",
    "    'binned ML_avg0': 'ML0',\n",
    "    'binned ML_avg1': 'ML1'\n",
    "})\n",
    "# Rename columns to match graph\n",
    "df_abst = df_abst.rename(columns={\n",
    "    'Comma gap (µm)': 'CG', 'binned ML': 'ML'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea008d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gll = nx.DiGraph()\n",
    "Gll.add_nodes_from(M_base.nodes())\n",
    "Gll.add_edges_from(M_base.edges())\n",
    "Ghl = nx.DiGraph()\n",
    "Ghl.add_nodes_from(M_abst.nodes())\n",
    "Ghl.add_edges_from(M_abst.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe066191",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "\n",
    "df_base_train, df_base_test = train_test_split(df_base, test_size=test_size, random_state=42)\n",
    "df_abst_train, df_abst_test = train_test_split(df_abst, test_size=test_size, random_state=42)\n",
    "\n",
    "# Get coefficients using the modularised_utils function\n",
    "ll_coeffs = mut.get_coefficients(df_base_train.to_numpy(), Gll)\n",
    "hl_coeffs = mut.get_coefficients(df_abst_train.to_numpy(), Ghl)\n",
    "\n",
    "Gll = CBN(list(ll_coeffs.keys()))\n",
    "Ghl = CBN(list(hl_coeffs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0a90233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/battery_discrete/df_abst_test.pkl']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(df_base_test, f\"data/{experiment}/df_base_test.pkl\")\n",
    "joblib.dump(df_abst_test, f\"data/{experiment}/df_abst_test.pkl\")\n",
    "# joblib.dump(df_base_test, f\"data/{experiment}/Dll_obs_test.pkl\")\n",
    "# joblib.dump(df_abst_test, f\"data/{experiment}/Dhl_obs_test.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ea37eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_llsamples, l = df_base_train.shape\n",
    "num_hlsamples, h = df_abst_train.shape\n",
    "min_samples = min(num_llsamples, num_hlsamples)\n",
    "\n",
    "df_base_train = df_base_train[:min_samples]\n",
    "df_abst_train = df_abst_train[:min_samples]\n",
    "\n",
    "df_base_train = df_base_train.to_numpy()\n",
    "df_abst_train = df_abst_train.to_numpy()\n",
    "\n",
    "l = len(Gll.nodes())\n",
    "h = len(Ghl.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d43d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_n_bin_old(T, df_base, df_abst):\n",
    "    \"\"\"\n",
    "    Transform base samples and bin them to match abstract domain\n",
    "    \n",
    "    Args:\n",
    "        T: transformation matrix\n",
    "        df_base: base model data (already numpy array)\n",
    "        df_abst: abstract model data (already numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        binned_samples: transformed and binned samples matching abstract domain\n",
    "    \"\"\"\n",
    "    # Apply transformation\n",
    "    continuous_samples = T @ df_base.T  # This gives us continuous values\n",
    "    \n",
    "    # Get the unique values in abstract domain to understand our target bins\n",
    "    abst_unique_values = np.sort(np.unique(df_abst, axis=0), axis=0)\n",
    "    \n",
    "    # Create bins for each dimension\n",
    "    binned_samples = np.zeros_like(continuous_samples)\n",
    "    \n",
    "    for dim in range(continuous_samples.shape[0]):\n",
    "        # Get unique values for this dimension\n",
    "        unique_vals = np.unique(df_abst[:, dim])\n",
    "        n_bins = len(unique_vals)\n",
    "        \n",
    "        # Create bin edges using percentiles of the continuous data\n",
    "        bin_edges = np.percentile(continuous_samples[dim], \n",
    "                                np.linspace(0, 100, n_bins + 1))\n",
    "        \n",
    "        # Ensure unique bin edges\n",
    "        bin_edges = np.unique(bin_edges)\n",
    "        if len(bin_edges) < n_bins + 1:\n",
    "            # If we don't have enough unique edges, create artificial ones\n",
    "            bin_edges = np.linspace(continuous_samples[dim].min(),\n",
    "                                  continuous_samples[dim].max(),\n",
    "                                  n_bins + 1)\n",
    "        \n",
    "        # Digitize the continuous values into bins\n",
    "        bin_indices = np.digitize(continuous_samples[dim], bin_edges[1:-1])\n",
    "        \n",
    "        # Map bin indices to abstract domain values\n",
    "        binned_samples[dim] = unique_vals[bin_indices]\n",
    "    \n",
    "    return binned_samples.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2424820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_n_bin(T, df_base, df_abst):\n",
    "    \"\"\"\n",
    "    Transform base samples and bin them using fixed bin edges from df_abst.\n",
    "    \n",
    "    Args:\n",
    "        T: transformation matrix\n",
    "        df_base: base model data (numpy array)\n",
    "        df_abst: abstract model data (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        binned_samples: transformed and binned samples matching abstract domain\n",
    "    \"\"\"\n",
    "    # Apply transformation\n",
    "    continuous_samples = T @ df_base.T  # (d, N)\n",
    "\n",
    "    # Precompute fixed bin edges from df_abst\n",
    "    abst_unique = np.sort(np.unique(df_abst, axis=0), axis=0)\n",
    "\n",
    "    # We assume:\n",
    "    # - Dimension 0: CG (control gap) -> use discrete values (no binning needed, handled separately)\n",
    "    # - Dimension 1: ML (mass loading) -> use percentile bins from df_abst\n",
    "\n",
    "    binned_samples = np.zeros_like(continuous_samples)\n",
    "\n",
    "    # Dimension 0: CG\n",
    "    unique_cg = np.unique(df_abst[:, 0])\n",
    "    n_bins_cg = len(unique_cg)\n",
    "    \n",
    "    # Manual mapping for CG later after transformation\n",
    "    # So no binning for CG here!\n",
    "\n",
    "    # Dimension 1: ML\n",
    "    unique_ml = np.unique(df_abst[:, 1])\n",
    "    n_bins_ml = len(unique_ml)\n",
    "    \n",
    "    # Create bin edges for ML using df_abst\n",
    "    ml_values = df_abst[:, 1]\n",
    "    bin_edges_ml = np.percentile(ml_values, np.linspace(0, 100, n_bins_ml + 1))\n",
    "    bin_edges_ml = np.unique(bin_edges_ml)\n",
    "    if len(bin_edges_ml) < n_bins_ml + 1:\n",
    "        bin_edges_ml = np.linspace(ml_values.min(), ml_values.max(), n_bins_ml + 1)\n",
    "\n",
    "    # Now bin the samples\n",
    "    # (0) CG: leave as continuous now, mapping will happen separately\n",
    "    binned_samples[0] = continuous_samples[0]  # keep CG for now (later mapped)\n",
    "\n",
    "    # (1) ML: use fixed bin edges\n",
    "    bin_indices_ml = np.digitize(continuous_samples[1], bin_edges_ml[1:-1])\n",
    "    binned_samples[1] = unique_ml[bin_indices_ml]\n",
    "\n",
    "    return binned_samples.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a584fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_ll_hat, mu_U_ll_hat, Sigma_U_ll_hat = mut.lan_abduction(df_base_train, Gll, ll_coeffs)\n",
    "U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat = mut.lan_abduction(df_abst_train, Ghl, hl_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a46c5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base-level interventions \n",
    "iota0 = None\n",
    "# iota1 = ops.Intervention({'CG': 75.})\n",
    "# iota2 = ops.Intervention({'CG': 110.})\n",
    "# iota3 = ops.Intervention({'CG': 180.})\n",
    "# iota4 = ops.Intervention({'CG': 200.})\n",
    "iota1 = ops.Intervention({'CG': 0})\n",
    "iota2 = ops.Intervention({'CG': 1})\n",
    "iota3 = ops.Intervention({'CG': 4})\n",
    "iota4 = ops.Intervention({'CG': 5})\n",
    "\n",
    "# Abstract-level interventions \n",
    "iota0_prime = None\n",
    "# iota1_prime = ops.Intervention({'CG': 75.})\n",
    "# iota2_prime = ops.Intervention({'CG': 100.})\n",
    "# iota3_prime = ops.Intervention({'CG': 200.})\n",
    "iota1_prime = ops.Intervention({'CG': 0})\n",
    "iota2_prime = ops.Intervention({'CG': 1})\n",
    "iota3_prime = ops.Intervention({'CG': 2})\n",
    "\n",
    "\n",
    "# Mapping\n",
    "omega = {\n",
    "    iota0: iota0_prime,\n",
    "    iota1: iota1_prime,\n",
    "    iota2: iota2_prime,\n",
    "    iota3: iota3_prime,\n",
    "    iota4: iota3_prime\n",
    "}\n",
    "\n",
    "Ill = list(set(omega.keys()))\n",
    "Ihl = list(set(omega.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cb0b714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/battery_discrete/exogenous_HL.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ds = {}\n",
    "Ds[None] = (df_base_train, df_abst_train)\n",
    "    \n",
    "joblib.dump((Gll, Ill), f\"data/{experiment}/LL.pkl\")\n",
    "joblib.dump(ll_coeffs, f\"data/{experiment}/ll_coeffs.pkl\")\n",
    "\n",
    "joblib.dump((Ghl, Ihl), f\"data/{experiment}/HL.pkl\")\n",
    "joblib.dump(hl_coeffs, f\"data/{experiment}/hl_coeffs.pkl\")\n",
    "\n",
    "joblib.dump(Ds, f\"data/{experiment}/Ds.pkl\")\n",
    "\n",
    "joblib.dump(omega, f\"data/{experiment}/omega.pkl\")\n",
    "joblib.dump((U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat), f\"data/{experiment}/exogenous_HL.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e7b8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLmodels = {}\n",
    "for iota in Ill:\n",
    "    LLmodels[iota] = lanm.LinearAddSCM(Gll, ll_coeffs, iota)\n",
    "\n",
    "HLmodels = {}\n",
    "for eta in Ihl:\n",
    "    HLmodels[eta] = lanm.LinearAddSCM(Ghl, hl_coeffs, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62f677ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/battery_discrete/HLmodels.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(LLmodels, f\"data/{experiment}/LLmodels.pkl\")\n",
    "joblib.dump(HLmodels, f\"data/{experiment}/HLmodels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62b4bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_matrices = oput.compute_struc_matrices(LLmodels, Ill)\n",
    "H_matrices = oput.compute_struc_matrices(HLmodels, Ihl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bdb4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_bound = round(evut.compute_empirical_radius(N=num_llsamples, eta=0.05, c1=1000.0, c2=1.0, alpha=2.0, m=l), 3)\n",
    "hl_bound = round(evut.compute_empirical_radius(N=num_hlsamples, eta=0.05, c1=1000.0, c2=1.0, alpha=2.0, m=h), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c053d7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.358 0.417\n"
     ]
    }
   ],
   "source": [
    "print(ll_bound, hl_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b9ae69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon, delta = ll_bound, hl_bound\n",
    "\n",
    "eta_max = 0.001\n",
    "eta_min = 0.001\n",
    "\n",
    "max_iter = 5000\n",
    "num_steps_min = 5\n",
    "num_steps_max = 2\n",
    "\n",
    "robust_L = True \n",
    "robust_H = True\n",
    "\n",
    "initialization = 'random' # 'random'\n",
    "\n",
    "tol  = 1e-4\n",
    "seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "526c1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_erica = {\n",
    "                        'U_L': U_ll_hat,\n",
    "                        'U_H': U_hl_hat,\n",
    "                        'L_models': LLmodels,\n",
    "                        'H_models': HLmodels,\n",
    "                        'omega': omega,\n",
    "                        'epsilon': epsilon,\n",
    "                        'delta': delta,\n",
    "                        'eta_min': eta_min,\n",
    "                        'eta_max': eta_max,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'num_steps_max': num_steps_max,\n",
    "                        'max_iter': max_iter,\n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'robust_L': robust_L,\n",
    "                        'robust_H': robust_H,\n",
    "                        'initialization': initialization,\n",
    "                        'experiment': 'battery_discrete'\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7b2b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ca15028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for ε=δ = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 224/1000 [00:11<00:38, 19.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 225\n",
      "Training for ε=δ = 0.358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [00:14<00:33, 20.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 301\n",
      "Training for ε=δ = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 272/1000 [00:13<00:34, 20.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 273\n",
      "Training for ε=δ = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 224/1000 [00:10<00:37, 20.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 225\n",
      "Training for ε=δ = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 224/1000 [00:10<00:37, 20.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 225\n",
      "\n",
      "Training completed. T matrices stored in trained_results dictionary.\n",
      "Available ε=δ values: ['T_8', 'T_0.358-0.417', 'T_1', 'T_2', 'T_4']\n"
     ]
    }
   ],
   "source": [
    "# Define different epsilon=delta values\n",
    "eps_delta_values     = [8, ll_bound, 1, 2, 4]\n",
    "\n",
    "# For each epsilon=delta value\n",
    "for eps_delta in eps_delta_values:\n",
    "    print(f\"Training for ε=δ = {eps_delta}\")\n",
    "    # Update theta parameters\n",
    "    if eps_delta == ll_bound:\n",
    "        opt_params_erica['epsilon'] = ll_bound\n",
    "        opt_params_erica['delta']   = hl_bound\n",
    "    \n",
    "    else:\n",
    "        opt_params_erica['epsilon'] = eps_delta\n",
    "        opt_params_erica['delta']   = eps_delta\n",
    "    \n",
    "    # Run ERICA optimization\n",
    "    params_empirical, T_empirical = oput.run_empirical_erica_optimization_batt(**opt_params_erica)\n",
    "    \n",
    "    # Store results including optimization parameters and transformation matrix\n",
    "    if eps_delta == ll_bound:\n",
    "        diroca_train_results_empirical['T_'+str(ll_bound)+'-'+str(hl_bound)] = {\n",
    "                                                    'optimization_params': params_empirical,\n",
    "                                                    'T_matrix': T_empirical\n",
    "                                                }\n",
    "    else:\n",
    "        diroca_train_results_empirical['T_'+str(eps_delta)] = {\n",
    "                                                    'optimization_params': params_empirical,\n",
    "                                                    'T_matrix': T_empirical\n",
    "                                                }\n",
    "\n",
    "print(\"\\nTraining completed. T matrices stored in trained_results dictionary.\")\n",
    "print(\"Available ε=δ values:\", list(diroca_train_results_empirical.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89c2b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3539/5000 [00:17<00:07, 204.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged at iteration 3540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params_enrico, T_enrico = oput.run_empirical_erica_optimization(**{**opt_params_erica, 'robust_L': False, 'robust_H': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "58c4424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_0.00'] = {\n",
    "                                'optimization_params': params_enrico,\n",
    "                                'T_matrix': T_enrico\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca07a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_bary = {\n",
    "                        'U_ll_hat':U_ll_hat,\n",
    "                        'U_hl_hat':U_hl_hat,\n",
    "                        'L_matrices':L_matrices,\n",
    "                        'H_matrices':H_matrices,\n",
    "                        'max_iter':1000,\n",
    "                        'tol':tol,\n",
    "                        'seed':seed\n",
    "                    }\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ae0e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 740.78it/s]\n"
     ]
    }
   ],
   "source": [
    "T_bary = oput.run_empirical_bary_optim(**opt_params_bary)\n",
    "params_bary = {'L':{}, 'H':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "042aeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_b'] = {\n",
    "                                'optimization_params': params_bary,\n",
    "                                'T_matrix': T_bary\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdb53936",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_smooth = {\n",
    "                        'U_L': U_ll_hat,\n",
    "                        'U_H': U_hl_hat,\n",
    "                        'L_models': LLmodels,\n",
    "                        'H_models': HLmodels,\n",
    "                        'omega': omega,\n",
    "                        'eta_min': eta_min,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'max_iter': 300, #300\n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'noise_sigma': 0.1, #0.1\n",
    "                        'num_noise_samples': 10\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e3110da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:49<00:00,  6.10it/s]\n"
     ]
    }
   ],
   "source": [
    "params_smooth, T_smooth = oput.run_empirical_smooth_optimization_batt(**opt_params_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd9c6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_s'] = {\n",
    "                                'optimization_params': params_smooth,\n",
    "                                'T_matrix': T_smooth\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07be452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linabs_results = evut.run_abs_lingam_complete(df_base_train, df_abst_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "969ae0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_pa'] = {'optimization_params':{'L':{'pert_U':U_ll_hat},'H':{'pert_U':U_hl_hat}}, 'T_matrix': linabs_results['Perfect']['T'].T}\n",
    "diroca_train_results_empirical['T_na'] = {'optimization_params':{'L':{'pert_U':U_ll_hat},'H':{'pert_U':U_hl_hat}}, 'T_matrix': linabs_results['Noisy']['T'].T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5da17060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/battery_discrete/diroca_train_results_empirical.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(diroca_train_results_empirical, f\"data/{experiment}/diroca_train_results_empirical.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "149c4ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical = joblib.load(f\"data/{experiment}/diroca_train_results_empirical.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f70d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33973829",
   "metadata": {},
   "source": [
    "# Downstream Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "31687760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_n_bin_fixed(T, df_base, df_abst):\n",
    "    \"\"\"\n",
    "    Transform base samples and bin them using fixed bin edges from df_abst.\n",
    "    \n",
    "    Args:\n",
    "        T: transformation matrix\n",
    "        df_base: base model data (numpy array)\n",
    "        df_abst: abstract model data (numpy array)\n",
    "    \n",
    "    Returns:\n",
    "        binned_samples: transformed and binned samples matching abstract domain\n",
    "    \"\"\"\n",
    "    # Apply transformation\n",
    "    continuous_samples = T @ df_base.T  # (d, N)\n",
    "\n",
    "    # Precompute fixed bin edges from df_abst\n",
    "    abst_unique = np.sort(np.unique(df_abst, axis=0), axis=0)\n",
    "\n",
    "    # We assume:\n",
    "    # - Dimension 0: CG (control gap) -> use discrete values (no binning needed, handled separately)\n",
    "    # - Dimension 1: ML (mass loading) -> use percentile bins from df_abst\n",
    "\n",
    "    binned_samples = np.zeros_like(continuous_samples)\n",
    "\n",
    "    # Dimension 0: CG\n",
    "    unique_cg = np.unique(df_abst[:, 0])\n",
    "    n_bins_cg = len(unique_cg)\n",
    "    \n",
    "    # Manual mapping for CG later after transformation\n",
    "    # So no binning for CG here!\n",
    "\n",
    "    # Dimension 1: ML\n",
    "    unique_ml = np.unique(df_abst[:, 1])\n",
    "    n_bins_ml = len(unique_ml)\n",
    "    \n",
    "    # Create bin edges for ML using df_abst\n",
    "    ml_values = df_abst[:, 1]\n",
    "    bin_edges_ml = np.percentile(ml_values, np.linspace(0, 100, n_bins_ml + 1))\n",
    "    bin_edges_ml = np.unique(bin_edges_ml)\n",
    "    if len(bin_edges_ml) < n_bins_ml + 1:\n",
    "        bin_edges_ml = np.linspace(ml_values.min(), ml_values.max(), n_bins_ml + 1)\n",
    "\n",
    "    # Now bin the samples\n",
    "    # (0) CG: leave as continuous now, mapping will happen separately\n",
    "    binned_samples[0] = continuous_samples[0]  # keep CG for now (later mapped)\n",
    "\n",
    "    # (1) ML: use fixed bin edges\n",
    "    bin_indices_ml = np.digitize(continuous_samples[1], bin_edges_ml[1:-1])\n",
    "    binned_samples[1] = unique_ml[bin_indices_ml]\n",
    "\n",
    "    return binned_samples.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f326a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "def map_wmg_to_lrcs_cg(wmg_cg_values):\n",
    "    \"\"\"\n",
    "    Map WMG CG values into LRCS CG domain (75, 100, 200).\n",
    "    This is manual based on the abstraction described.\n",
    "    \"\"\"\n",
    "    mapped_cg = []\n",
    "    for val in wmg_cg_values:\n",
    "        if val in [0]:  # WMG 75 mapped to LRCS 75\n",
    "            mapped_cg.append(0)\n",
    "        elif val in [1, 2, 3, 4]:  # WMG 110, 150, 170, 180 mapped to LRCS 100\n",
    "            mapped_cg.append(1)\n",
    "        elif val in [5]:  # WMG 200 mapped to LRCS 200\n",
    "            mapped_cg.append(2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected WMG CG value {val} during mapping.\")\n",
    "    return np.array(mapped_cg)\n",
    "\n",
    "def downstream_evaluation_fair(T, df_base, df_abst):\n",
    "    \"\"\"\n",
    "    Implements paper's evaluation methodology: Scenarios (a), (b), (c).\n",
    "    Assumes df_base and df_abst are preprocessed as described.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocessing\n",
    "    df_base_np = df_base.to_numpy()\n",
    "    df_abst_np = df_abst.to_numpy()\n",
    "\n",
    "    # Map and bin the base samples\n",
    "    tau_samples = map_n_bin_old(T, df_base_np, df_abst_np)\n",
    "\n",
    "    # Map CG values from WMG (base) to LRCS space\n",
    "    tau_samples[:, 0] = map_wmg_to_lrcs_cg(tau_samples[:, 0].astype(int))\n",
    "\n",
    "    comma_gaps = np.unique(df_abst_np[:, 0])\n",
    "    lasso_params = {'alpha': 0.0001, 'max_iter': 500, 'tol': 0.0001}\n",
    "\n",
    "    # Concatenate LRCS and transported WMG (for scenarios b and c)\n",
    "    enhanced_data = np.concatenate([df_abst_np, tau_samples])\n",
    "\n",
    "    results = {'Real': [], 'Aug': [], 'AugReal': []}\n",
    "\n",
    "    for cg in comma_gaps:\n",
    "        # Scenario (a): Real only\n",
    "        train_mask_a = (df_abst_np[:, 0] != cg)\n",
    "        test_mask_a = (df_abst_np[:, 0] == cg)\n",
    "\n",
    "        X_train_a = df_abst_np[train_mask_a, 0].reshape(-1, 1)\n",
    "        y_train_a = df_abst_np[train_mask_a, 1]\n",
    "        X_test_a = df_abst_np[test_mask_a, 0].reshape(-1, 1)\n",
    "        y_test_a = df_abst_np[test_mask_a, 1]\n",
    "\n",
    "        model_a = Lasso(**lasso_params).fit(X_train_a, y_train_a)\n",
    "        y_pred_a = model_a.predict(X_test_a)\n",
    "        mse_a = np.mean((y_pred_a - y_test_a) ** 2)\n",
    "        results['Real'].append(mse_a)\n",
    "\n",
    "        # Scenario (b): Augmented (full WMG support)\n",
    "        # Train on LRCS (CG ≠ cg) + all tau_samples\n",
    "        train_mask_b = np.ones(len(enhanced_data), dtype=bool)\n",
    "        train_mask_b[:len(df_abst_np)][test_mask_a] = False  # Drop LRCS samples with CG=cg\n",
    "\n",
    "        X_train_b = enhanced_data[train_mask_b, 0].reshape(-1, 1)\n",
    "        y_train_b = enhanced_data[train_mask_b, 1]\n",
    "        X_test_b = df_abst_np[test_mask_a, 0].reshape(-1, 1)\n",
    "        y_test_b = df_abst_np[test_mask_a, 1]\n",
    "\n",
    "        model_b = Lasso(**lasso_params).fit(X_train_b, y_train_b)\n",
    "        y_pred_b = model_b.predict(X_test_b)\n",
    "        mse_b = np.mean((y_pred_b - y_test_b) ** 2)\n",
    "        results['Aug'].append(mse_b)\n",
    "\n",
    "        # Scenario (c): Augmented without support\n",
    "        test_mask_tau = (tau_samples[:, 0] == cg)\n",
    "\n",
    "        train_data_c = np.concatenate([\n",
    "            df_abst_np[~test_mask_a],\n",
    "            tau_samples[~test_mask_tau]\n",
    "        ])\n",
    "\n",
    "        test_data_c = np.concatenate([\n",
    "            df_abst_np[test_mask_a],\n",
    "            tau_samples[test_mask_tau]\n",
    "        ])\n",
    "\n",
    "        X_train_c = train_data_c[:, 0].reshape(-1, 1)\n",
    "        y_train_c = train_data_c[:, 1]\n",
    "        X_test_c = test_data_c[:, 0].reshape(-1, 1)\n",
    "        y_test_c = test_data_c[:, 1]\n",
    "\n",
    "        model_c = Lasso(**lasso_params).fit(X_train_c, y_train_c)\n",
    "        y_pred_c = model_c.predict(X_test_c)\n",
    "        mse_c = np.mean((y_pred_c - y_test_c) ** 2)\n",
    "        results['AugReal'].append(mse_c)\n",
    "\n",
    "    # Aggregate\n",
    "    final_results = {\n",
    "        'Real': (np.mean(results['Real']), np.std(results['Real'])),\n",
    "        'Aug': (np.mean(results['Aug']), np.std(results['Aug'])),\n",
    "        'AugReal': (np.mean(results['AugReal']), np.std(results['AugReal'])),\n",
    "    }\n",
    "    \n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9eeea1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Abstraction Performance Evaluation\n",
      "================================================================================\n",
      "\n",
      "Real Scenario\n",
      "================================================================================\n",
      "Rank  Method          Error (mean ± std)                 \n",
      "--------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario\n",
      "================================================================================\n",
      "Rank  Method          Error (mean ± std)                 \n",
      "--------------------------------------------------------------------------------\n",
      "1     T_b               5.0341 ± 6.5736  \n",
      "2     T_8               3.0630 ± 3.2846  \n",
      "3     T_2               3.0630 ± 3.2846  \n",
      "4     T_4               3.0630 ± 3.2846  \n",
      "5     T_1               1.2565 ± 0.7856  \n",
      "6     T_pa              1.1264 ± 0.3280  \n",
      "7     T_na              1.0144 ± 0.1449  \n",
      "8     T_0.00            0.9878 ± 0.6400  \n",
      "9     T_s               0.2742 ± 0.1399  \n",
      "10    T_0.358-0.417     0.2717 ± 0.1316  \n",
      "\n",
      "AugReal Scenario\n",
      "================================================================================\n",
      "Rank  Method          Error (mean ± std)                 \n",
      "--------------------------------------------------------------------------------\n",
      "1     T_b              10.8889 ± 5.0261  \n",
      "2     T_8               5.8310 ± 2.6593  \n",
      "3     T_2               5.8310 ± 2.6593  \n",
      "4     T_4               5.8310 ± 2.6593  \n",
      "5     T_1               1.6276 ± 0.3223  \n",
      "6     T_0.00            1.5013 ± 0.3655  \n",
      "7     T_pa              1.3852 ± 0.4085  \n",
      "8     T_na              0.9953 ± 0.1714  \n",
      "9     T_0.358-0.417     0.5135 ± 0.1363  \n",
      "10    T_s               0.4863 ± 0.1221  \n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def print_ordered_results(results_dict, scenario_name):\n",
    "    # Extract results for the given scenario\n",
    "    scenario_results = {method: results_dict[method][scenario_name] for method in results_dict.keys()}\n",
    "    \n",
    "    # Sort by mean error (first element of the tuple) in descending order (worst to best)\n",
    "    sorted_results = dict(sorted(scenario_results.items(), key=lambda x: x[1][0], reverse=True))\n",
    "    \n",
    "    print(f\"\\n{scenario_name} Scenario\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Rank':<5} {'Method':<15} {'Error (mean ± std)':<35}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for rank, (method, (mean, std)) in enumerate(sorted_results.items(), 1):\n",
    "        print(f\"{rank:<5} {method:<15} {mean:>8.4f} ± {std:<8.4f}\")\n",
    "\n",
    "# ========== FIRST compute downstream evaluations ==========\n",
    "all_results = {}\n",
    "for method in diroca_train_results_empirical.keys():\n",
    "    T_matrix = diroca_train_results_empirical[method]['T_matrix']\n",
    "    eval_result = downstream_evaluation_fair(T_matrix, df_base, df_abst)\n",
    "    all_results[method] = eval_result\n",
    "\n",
    "# ========== THEN print for each scenario ==========\n",
    "print(\"\\nAbstraction Performance Evaluation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Real → Real scenario\n",
    "print_ordered_results(all_results, 'Real')\n",
    "\n",
    "# Aug → Real scenario\n",
    "print_ordered_results(all_results, 'Aug')\n",
    "\n",
    "# Real+Aug → Real scenario\n",
    "print_ordered_results(all_results, 'AugReal')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae7718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2f5882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_dict = {'L': U_ll_hat, 'H': U_hl_hat}\n",
    "\n",
    "worst = 'T_8'\n",
    "\n",
    "U_worst_L = diroca_train_results_empirical[worst]['optimization_params']['L']['pert_U']\n",
    "U_worst_H = diroca_train_results_empirical[worst]['optimization_params']['H']['pert_U']\n",
    "\n",
    "worst_dict = {'L': U_worst_L, 'H': U_worst_H}\n",
    "\n",
    "center = 'hat'\n",
    "if center == 'hat':\n",
    "    center_matrix = hat_dict\n",
    "elif center == 'worst':\n",
    "    center_matrix = worst_dict\n",
    "\n",
    "coverage_type='uniform'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4050dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_values = np.arange(0.0, 10.0, 1).tolist()  \n",
    "noise_levels = np.arange(0.0, 10.0, 1).tolist()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "a44a4659",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df_base_test\n",
    "df_abst = df_abst_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3967ff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downstream_evaluation_paper_with_noise(T, df_base, df_abst, rad, noise_level, noise_in):\n",
    "    \"\"\"\n",
    "    Implements the paper's evaluation methodology with three scenarios, with added noise functionality\n",
    "    \"\"\"\n",
    "    # Create noisy copies of the data and convert to float\n",
    "    df_base = df_base.to_numpy()\n",
    "    df_abst = df_abst.to_numpy()\n",
    "\n",
    "    df_base_noisy = df_base.copy().astype(float)\n",
    "    df_abst_noisy = df_abst.copy().astype(float)\n",
    "\n",
    "    pert_L = evut.generate_perturbation_matrix(rad, 'boundary', 'L', hat_dict, coverage = coverage_type)\n",
    "    pert_H = evut.generate_perturbation_matrix(rad, 'boundary', 'H', hat_dict, coverage = coverage_type)\n",
    "\n",
    "    if noise_level == 0:\n",
    "        noise_in = 'none'\n",
    "    # Add noise according to specified parameters\n",
    "    if noise_in == 'both':\n",
    "        # meanL = np.random.uniform(-1, 1)  # generates random mean between -1 and 1\n",
    "        #df_base_noisy += np.random.normal(0, noise_level, df_base.shape)\n",
    "        #df_base_noisy += (LLmodels[None].F @ (center_matrix['L'] + pert_L).T).T\n",
    "        \n",
    "        df_base_noisy += pert_L\n",
    "        # meanH = np.random.uniform(-1, 1)  # generates random mean between -1 and 1\n",
    "        # df_abst_noisy += np.random.normal(meanH, noise_level, df_abst.shape)\n",
    "        #df_abst_noisy += (HLmodels[None].F @ (center_matrix['H'] + pert_H).T).T\n",
    "        df_abst_noisy += pert_H\n",
    "        \n",
    "    elif noise_in == 'base':\n",
    "        df_base_noisy += np.random.normal(0, noise_level, df_base.shape)\n",
    "        df_abst_noisy = df_abst.copy().astype(float)\n",
    "\n",
    "    elif noise_in == 'abst':\n",
    "        df_abst_noisy += np.random.normal(0, noise_level, df_abst.shape)\n",
    "        df_base_noisy = df_base.copy().astype(float)\n",
    "        \n",
    "    elif noise_in == 'none':\n",
    "        df_base_noisy = df_base.copy().astype(float)\n",
    "        df_abst_noisy = df_abst.copy().astype(float)\n",
    "    \n",
    "    # Get unique Comma Gap values\n",
    "    comma_gaps = np.unique(df_abst_noisy[:, 0])\n",
    "    lasso_params = {'alpha': 0.0001, 'max_iter': 500, 'tol': 0.0001}\n",
    "    tau_samples = map_n_bin(T, df_base_noisy, df_abst_noisy)\n",
    "    # Now tau_samples is (num_base_samples x 2)\n",
    "    \n",
    "    # Scenario 1: Before abstraction (Real → Real)\n",
    "    mse_real = []\n",
    "    for cg in comma_gaps:\n",
    "        test_mask = (df_abst_noisy[:, 0] == cg)\n",
    "        train_mask = ~test_mask\n",
    "        \n",
    "        X_train = df_abst_noisy[train_mask, 0].reshape(-1, 1)\n",
    "        y_train = df_abst_noisy[train_mask, 1]\n",
    "        \n",
    "        X_test = df_abst_noisy[test_mask, 0].reshape(-1, 1)\n",
    "        y_test = df_abst_noisy[test_mask, 1]\n",
    "        \n",
    "        model = Lasso(**lasso_params).fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mses = (y_pred - y_test)**2\n",
    "        mean_mse = np.mean(mses)\n",
    "        std_mse = np.std(mses)\n",
    "        mse_real.append(mean_mse)\n",
    "    \n",
    "    # Scenario 2: After abstraction with support (Aug → Real)\n",
    "    mse_aug = []\n",
    "    \n",
    "    # Concatenate abstract and transformed data\n",
    "    enhanced_data = np.concatenate([df_abst_noisy, tau_samples])\n",
    "    \n",
    "    for cg in comma_gaps:\n",
    "        # Create test mask for abstract data\n",
    "        test_mask_abst = (df_abst_noisy[:, 0] == cg)\n",
    "        \n",
    "        # Create full training mask\n",
    "        train_mask_full = np.ones(len(enhanced_data), dtype=bool)\n",
    "        train_mask_full[:len(df_abst_noisy)][test_mask_abst] = False\n",
    "        \n",
    "        # Training data (all transformed samples + non-test abstract samples)\n",
    "        X_train = enhanced_data[train_mask_full, 0].reshape(-1, 1)\n",
    "        y_train = enhanced_data[train_mask_full, 1]\n",
    "        \n",
    "        # Test data (only from abstract)\n",
    "        X_test = df_abst_noisy[test_mask_abst, 0].reshape(-1, 1)\n",
    "        y_test = df_abst_noisy[test_mask_abst, 1]\n",
    "        \n",
    "        model = Lasso(**lasso_params).fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mses = (y_pred - y_test)**2\n",
    "        mean_mse = np.mean(mses)\n",
    "        std_mse = np.std(mses)\n",
    "        mse_aug.append(mean_mse)\n",
    "    \n",
    "    # Scenario 3: After abstraction without support (Real+Aug → Real)\n",
    "    mse_mix = []\n",
    "    \n",
    "    for cg in comma_gaps:\n",
    "        test_mask_abst = (df_abst_noisy[:, 0] == cg)\n",
    "        test_mask_tau = (tau_samples[:, 0] == cg)\n",
    "        \n",
    "        # Combine data excluding test samples\n",
    "        train_data = np.concatenate([\n",
    "            df_abst_noisy[~test_mask_abst],\n",
    "            tau_samples[~test_mask_tau]\n",
    "        ])\n",
    "        \n",
    "        X_train = train_data[:, 0].reshape(-1, 1)\n",
    "        y_train = train_data[:, 1]\n",
    "        \n",
    "        X_test = df_abst_noisy[test_mask_abst, 0].reshape(-1, 1)\n",
    "        y_test = df_abst_noisy[test_mask_abst, 1]\n",
    "        \n",
    "        model = Lasso(**lasso_params).fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mses = (y_pred - y_test)**2\n",
    "        mean_mse = np.mean(mses)\n",
    "        std_mse = np.std(mses)\n",
    "        mse_mix.append(mean_mse)\n",
    "    \n",
    "    return {\n",
    "        \"Real\": (np.mean(mse_real), np.std(mse_real)),\n",
    "        \"Aug\": (np.mean(mse_aug), np.std(mse_aug)),\n",
    "        \"AugReal\": (np.mean(mse_mix), np.std(mse_mix))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5613d20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ordered_noisy_results(results_dict, scenario_name, noise_level, noise_in):\n",
    "    # Extract results for the given scenario\n",
    "    scenario_results = {method: results_dict[method][scenario_name] for method in results_dict.keys()}\n",
    "    # Sort by mean error (first element of the tuple) in descending order (worst to best)\n",
    "    sorted_results = dict(sorted(scenario_results.items(), key=lambda x: x[1][0], reverse=True))\n",
    "    \n",
    "    print(f\"\\n{scenario_name} Scenario (Noise Level: {noise_level}, Applied to: {noise_in})\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{'Rank':<5} {'Method':<15} {'Error (mean ± CI)':<35}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    for rank, (method, (mean, std)) in enumerate(sorted_results.items(), 1):\n",
    "        print(f\"{rank:<5} {method:<15} {mean:>8.4f} ± {std:<8.4f}\")\n",
    "\n",
    "# Print results for each scenario and noise configuration\n",
    "def evaluate_and_print_noisy_results(diroca_train_results_empirical, df_base, df_abst, noise_level, noise_in):\n",
    "    print(\"\\nAbstraction Performance Evaluation with Noise\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"Noise Configuration: Level = {noise_level}, Applied to: {noise_in}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    # Collect all results\n",
    "    results = {method: downstream_evaluation_paper_with_noise(\n",
    "        diroca_train_results_empirical[method]['T_matrix'],\n",
    "        df_base, df_abst, rad=rad,\n",
    "        noise_level=noise_level,\n",
    "        noise_in=noise_in\n",
    "    ) for method in diroca_train_results_empirical.keys()}\n",
    "\n",
    "    # Print results for each scenario\n",
    "    print_ordered_noisy_results(results, 'Real', noise_level, noise_in)\n",
    "    print_ordered_noisy_results(results, 'Aug', noise_level, noise_in)\n",
    "    print_ordered_noisy_results(results, 'AugReal', noise_level, noise_in)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1f2f46b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rad value: 0.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 1.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 2.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 3.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 4.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 5.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 6.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 7.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 8.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n",
      "Rad value: 9.0\n",
      "\n",
      "Real Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_8               0.5701 ± 0.2816  \n",
      "2     T_0.358-0.417     0.5701 ± 0.2816  \n",
      "3     T_1               0.5701 ± 0.2816  \n",
      "4     T_2               0.5701 ± 0.2816  \n",
      "5     T_4               0.5701 ± 0.2816  \n",
      "6     T_0.00            0.5701 ± 0.2816  \n",
      "7     T_b               0.5701 ± 0.2816  \n",
      "8     T_s               0.5701 ± 0.2816  \n",
      "9     T_pa              0.5701 ± 0.2816  \n",
      "10    T_na              0.5701 ± 0.2816  \n",
      "\n",
      "Aug Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.0604 ± 5.4531  \n",
      "2     T_8               2.7670 ± 3.2527  \n",
      "3     T_2               2.7670 ± 3.2527  \n",
      "4     T_4               2.7670 ± 3.2527  \n",
      "5     T_1               1.5068 ± 0.8734  \n",
      "6     T_0.00            1.2235 ± 0.6990  \n",
      "7     T_na              0.3825 ± 0.4658  \n",
      "8     T_s               0.3275 ± 0.2282  \n",
      "9     T_0.358-0.417     0.2865 ± 0.3757  \n",
      "10    T_pa              0.2450 ± 0.2383  \n",
      "\n",
      "AugReal Scenario (Noise Level: 0.1, Applied to: none)\n",
      "====================================================================================================\n",
      "Rank  Method          Error (mean ± CI)                  \n",
      "----------------------------------------------------------------------------------------------------\n",
      "1     T_b               4.9407 ± 5.8781  \n",
      "2     T_8               3.5624 ± 3.4431  \n",
      "3     T_2               3.5624 ± 3.4431  \n",
      "4     T_4               3.5624 ± 3.4431  \n",
      "5     T_1               3.3119 ± 2.3975  \n",
      "6     T_0.00            2.7009 ± 1.9378  \n",
      "7     T_0.358-0.417     0.2956 ± 0.3681  \n",
      "8     T_na              0.2816 ± 0.3240  \n",
      "9     T_s               0.1099 ± 0.0952  \n",
      "10    T_pa              0.0810 ± 0.0712  \n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def evaluate_and_print_noisy_results(diroca_train_results_empirical, df_base, df_abst, rad, noise_level, noise_in):\n",
    "    # print(\"\\nAbstraction Performance Evaluation with Noise\")\n",
    "    # print(\"=\"*100)\n",
    "    # print(f\"Noise Configuration: Level = {rad}, Applied to: {noise_in}\")\n",
    "    # print(\"=\"*100)\n",
    "\n",
    "    # Initialize dictionaries to store accumulated results\n",
    "    accumulated_results = {\n",
    "        'Real': {'mean': [], 'std': []},\n",
    "        'Aug': {'mean': [], 'std': []},\n",
    "        'AugReal': {'mean': [], 'std': []}\n",
    "    }\n",
    "\n",
    "    # Run 100 iterations\n",
    "    for _ in range(5):\n",
    "    #for rad in rad_values:\n",
    "        # Collect results for each method\n",
    "        results = {method: downstream_evaluation_paper_with_noise(\n",
    "            diroca_train_results_empirical[method]['T_matrix'],\n",
    "            df_base, df_abst, rad=rad,\n",
    "            noise_level=noise_level,\n",
    "            noise_in=noise_in\n",
    "        ) for method in diroca_train_results_empirical.keys()}\n",
    "\n",
    "        # Accumulate results\n",
    "        for scenario in ['Real', 'Aug', 'AugReal']:\n",
    "            for method in results:\n",
    "                mean, std = results[method][scenario]\n",
    "                accumulated_results[scenario]['mean'].append(mean)\n",
    "                accumulated_results[scenario]['std'].append(std)\n",
    "\n",
    "    # Calculate averages and structure final results\n",
    "    final_results = {}\n",
    "    for method in diroca_train_results_empirical.keys():\n",
    "        method_results = {}\n",
    "        for scenario in ['Real', 'Aug', 'AugReal']:\n",
    "            # Get the mean and std for this method across all runs\n",
    "            means = [accumulated_results[scenario]['mean'][i] for i in range(len(accumulated_results[scenario]['mean'])) if i % len(diroca_train_results_empirical) == list(diroca_train_results_empirical.keys()).index(method)]\n",
    "            stds = [accumulated_results[scenario]['std'][i] for i in range(len(accumulated_results[scenario]['std'])) if i % len(diroca_train_results_empirical) == list(diroca_train_results_empirical.keys()).index(method)]\n",
    "            \n",
    "            method_results[scenario] = (np.mean(means), np.mean(stds))\n",
    "        final_results[method] = method_results\n",
    "\n",
    "    # Print results for each scenario\n",
    "    for scenario in ['Real', 'Aug', 'AugReal']:\n",
    "        print_ordered_noisy_results(final_results, scenario, noise_level, noise_in)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "\n",
    "for rad in rad_values:\n",
    "#for noise_level in noise_levels:\n",
    "    print(f\"Rad value: {rad}\")\n",
    "    evaluate_and_print_noisy_results(\n",
    "        diroca_train_results_empirical,\n",
    "        df_base,\n",
    "        df_abst,\n",
    "        rad = rad,\n",
    "        noise_level=.1,\n",
    "        noise_in='none'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402ace3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
