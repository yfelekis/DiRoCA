{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d1ca742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import joblib\n",
    "import pickle \n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxpy as cp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import seaborn as sns\n",
    "import random \n",
    "import joblib\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from src.CBN import CausalBayesianNetwork as CBN\n",
    "import modularised_utils as mut\n",
    "import Linear_Additive_Noise_Models as lanm\n",
    "import operations as ops\n",
    "import evaluation_utils as evut\n",
    "import opt_utils as oput\n",
    "import params\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe511603",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'battery_discrete'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7c0287",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8977f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_base = joblib.load('batteries/scms/M_WMG_bins_5_avg_2.pkl')\n",
    "M_abst = joblib.load('batteries/scms/M_LRCS_bins_5.pkl') \n",
    "\n",
    "df_base = joblib.load('batteries/dfs/df_WMG_bins_5_avg_2.pkl')\n",
    "df_abst = joblib.load('batteries/dfs/df_LRCS_bins_5.pkl')\n",
    "\n",
    "df_base.drop(df_base.columns[[1,2]], axis=1, inplace=True)\n",
    "df_base.replace({75:0, 110:1, 150:2, 170:3, 180:4, 200:5}, inplace=True)\n",
    "\n",
    "df_abst.drop(df_abst.columns[[1]], axis=1, inplace=True)\n",
    "df_abst.replace({75:0, 100:1, 200:2}, inplace=True)\n",
    "\n",
    "# Rename columns to match graph\n",
    "df_base = df_base.rename(columns={\n",
    "    'binned ML_avg0': 'ML0',\n",
    "    'binned ML_avg1': 'ML1'\n",
    "})\n",
    "# Rename columns to match graph\n",
    "df_abst = df_abst.rename(columns={\n",
    "    'Comma gap (µm)': 'CG', 'binned ML': 'ML'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eea008d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gll = nx.DiGraph()\n",
    "Gll.add_nodes_from(M_base.nodes())\n",
    "Gll.add_edges_from(M_base.edges())\n",
    "Ghl = nx.DiGraph()\n",
    "Ghl.add_nodes_from(M_abst.nodes())\n",
    "Ghl.add_edges_from(M_abst.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fe066191",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.1\n",
    "\n",
    "df_base_train, df_base_test = train_test_split(df_base, test_size=test_size, random_state=42)\n",
    "df_abst_train, df_abst_test = train_test_split(df_abst, test_size=test_size, random_state=42)\n",
    "\n",
    "# Get coefficients using the modularised_utils function\n",
    "ll_coeffs = mut.get_coefficients(df_base_train.to_numpy(), Gll)\n",
    "hl_coeffs = mut.get_coefficients(df_abst_train.to_numpy(), Ghl)\n",
    "\n",
    "Gll = CBN(list(ll_coeffs.keys()))\n",
    "Ghl = CBN(list(hl_coeffs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a90233",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(df_base_test, f\"data/{experiment}/df_base_test.pkl\")\n",
    "joblib.dump(df_abst_test, f\"data/{experiment}/df_abst_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ea37eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_llsamples, l = df_base_train.shape\n",
    "num_hlsamples, h = df_abst_train.shape\n",
    "min_samples = min(num_llsamples, num_hlsamples)\n",
    "\n",
    "df_base_train = df_base_train[:min_samples]\n",
    "df_abst_train = df_abst_train[:min_samples]\n",
    "\n",
    "df_base_train = df_base_train.to_numpy()\n",
    "df_abst_train = df_abst_train.to_numpy()\n",
    "\n",
    "l = len(Gll.nodes())\n",
    "h = len(Ghl.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a584fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "U_ll_hat, mu_U_ll_hat, Sigma_U_ll_hat = mut.lan_abduction(df_base_train, Gll, ll_coeffs)\n",
    "U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat = mut.lan_abduction(df_abst_train, Ghl, hl_coeffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a46c5483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low-level interventions \n",
    "iota0 = None\n",
    "iota1 = ops.Intervention({'CG': 0})\n",
    "iota2 = ops.Intervention({'CG': 1})\n",
    "iota3 = ops.Intervention({'CG': 4})\n",
    "iota4 = ops.Intervention({'CG': 5})\n",
    "\n",
    "# High-level interventions \n",
    "iota0_prime = None\n",
    "iota1_prime = ops.Intervention({'CG': 0})\n",
    "iota2_prime = ops.Intervention({'CG': 1})\n",
    "iota3_prime = ops.Intervention({'CG': 2})\n",
    "\n",
    "# Mapping\n",
    "omega = {\n",
    "    iota0: iota0_prime,\n",
    "    iota1: iota1_prime,\n",
    "    iota2: iota2_prime,\n",
    "    iota3: iota3_prime,\n",
    "    iota4: iota3_prime\n",
    "}\n",
    "\n",
    "Ill = list(set(omega.keys()))\n",
    "Ihl = list(set(omega.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "963e8f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLmodels = {}\n",
    "for iota in Ill:\n",
    "    LLmodels[iota] = lanm.LinearAddSCM(Gll, ll_coeffs, iota)\n",
    "\n",
    "HLmodels = {}\n",
    "for eta in Ihl:\n",
    "    HLmodels[eta] = lanm.LinearAddSCM(Ghl, hl_coeffs, eta)\n",
    "\n",
    "L_matrices = oput.compute_struc_matrices(LLmodels, Ill)\n",
    "H_matrices = oput.compute_struc_matrices(HLmodels, Ihl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0b714",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ds = {}\n",
    "Ds[None] = (df_base_train, df_abst_train)\n",
    "    \n",
    "joblib.dump((Gll, Ill), f\"data/{experiment}/LL.pkl\")\n",
    "joblib.dump(ll_coeffs, f\"data/{experiment}/ll_coeffs.pkl\")\n",
    "\n",
    "joblib.dump((Ghl, Ihl), f\"data/{experiment}/HL.pkl\")\n",
    "joblib.dump(hl_coeffs, f\"data/{experiment}/hl_coeffs.pkl\")\n",
    "\n",
    "joblib.dump(Ds, f\"data/{experiment}/Ds.pkl\")\n",
    "\n",
    "joblib.dump(omega, f\"data/{experiment}/omega.pkl\")\n",
    "joblib.dump((U_hl_hat, mu_U_hl_hat, Sigma_U_hl_hat), f\"data/{experiment}/exogenous_HL.pkl\")\n",
    "\n",
    "joblib.dump(LLmodels, f\"data/{experiment}/LLmodels.pkl\")\n",
    "joblib.dump(HLmodels, f\"data/{experiment}/HLmodels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62b4bd86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d33c380",
   "metadata": {},
   "source": [
    "### DIROCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bdb4e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_bound = round(evut.compute_empirical_radius(N=num_llsamples, eta=0.05, c1=1000.0, c2=1.0, alpha=2.0, m=l), 3)\n",
    "hl_bound = round(evut.compute_empirical_radius(N=num_hlsamples, eta=0.05, c1=1000.0, c2=1.0, alpha=2.0, m=h), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9ae69f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon, delta = ll_bound, hl_bound\n",
    "\n",
    "eta_max = 0.001\n",
    "eta_min = 0.001\n",
    "\n",
    "max_iter = 5000\n",
    "num_steps_min = 5\n",
    "num_steps_max = 2\n",
    "\n",
    "robust_L = True \n",
    "robust_H = True\n",
    "\n",
    "initialization = 'random'\n",
    "\n",
    "tol  = 1e-4\n",
    "seed = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "526c1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_erica = {\n",
    "                        'U_L': U_ll_hat,\n",
    "                        'U_H': U_hl_hat,\n",
    "                        'L_models': LLmodels,\n",
    "                        'H_models': HLmodels,\n",
    "                        'omega': omega,\n",
    "                        'epsilon': epsilon,\n",
    "                        'delta': delta,\n",
    "                        'eta_min': eta_min,\n",
    "                        'eta_max': eta_max,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'num_steps_max': num_steps_max,\n",
    "                        'max_iter': max_iter,\n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'robust_L': robust_L,\n",
    "                        'robust_H': robust_H,\n",
    "                        'initialization': initialization,\n",
    "                        'experiment': 'battery_discrete'\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b2b087",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca15028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different epsilon=delta values\n",
    "eps_delta_values     = [8, ll_bound, 1, 2, 4]\n",
    "\n",
    "# For each epsilon=delta value\n",
    "for eps_delta in eps_delta_values:\n",
    "    print(f\"Training for ε=δ = {eps_delta}\")\n",
    "    # Update theta parameters\n",
    "    if eps_delta == ll_bound:\n",
    "        opt_params_erica['epsilon'] = ll_bound\n",
    "        opt_params_erica['delta']   = hl_bound\n",
    "    \n",
    "    else:\n",
    "        opt_params_erica['epsilon'] = eps_delta\n",
    "        opt_params_erica['delta']   = eps_delta\n",
    "    \n",
    "    # Run ERICA optimization\n",
    "    params_empirical, T_empirical = oput.run_empirical_erica_optimization_batt(**opt_params_erica)\n",
    "    \n",
    "    # Store results including optimization parameters and transformation matrix\n",
    "    if eps_delta == ll_bound:\n",
    "        diroca_train_results_empirical['T_'+str(ll_bound)+'-'+str(hl_bound)] = {\n",
    "                                                    'optimization_params': params_empirical,\n",
    "                                                    'T_matrix': T_empirical\n",
    "                                                }\n",
    "    else:\n",
    "        diroca_train_results_empirical['T_'+str(eps_delta)] = {\n",
    "                                                    'optimization_params': params_empirical,\n",
    "                                                    'T_matrix': T_empirical\n",
    "                                                }\n",
    "\n",
    "print(\"\\nTraining completed. T matrices stored in trained_results dictionary.\")\n",
    "print(\"Available ε=δ values:\", list(diroca_train_results_empirical.keys()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedc71b0",
   "metadata": {},
   "source": [
    "### GRADCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c2b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 428.36it/s]\n"
     ]
    }
   ],
   "source": [
    "params_enrico, T_enrico = oput.run_empirical_erica_optimization(**{**opt_params_erica, 'robust_L': False, 'robust_H': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c4424c",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_0.00'] = {\n",
    "                                'optimization_params': params_enrico,\n",
    "                                'T_matrix': T_enrico\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797e040b",
   "metadata": {},
   "source": [
    "### BARYCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca07a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_bary = {\n",
    "                        'U_ll_hat':U_ll_hat,\n",
    "                        'U_hl_hat':U_hl_hat,\n",
    "                        'L_matrices':L_matrices,\n",
    "                        'H_matrices':H_matrices,\n",
    "                        'max_iter':1000,\n",
    "                        'tol':tol,\n",
    "                        'seed':seed\n",
    "                    }\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0e2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_bary = oput.run_empirical_bary_optim(**opt_params_bary)\n",
    "params_bary = {'L':{}, 'H':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "042aeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_b'] = {\n",
    "                                'optimization_params': params_bary,\n",
    "                                'T_matrix': T_bary\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97bf395",
   "metadata": {},
   "source": [
    "### RSCA optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdb53936",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_params_smooth = {\n",
    "                        'U_L': U_ll_hat,\n",
    "                        'U_H': U_hl_hat,\n",
    "                        'L_models': LLmodels,\n",
    "                        'H_models': HLmodels,\n",
    "                        'omega': omega,\n",
    "                        'eta_min': eta_min,\n",
    "                        'num_steps_min': num_steps_min,\n",
    "                        'max_iter': 300, \n",
    "                        'tol': tol,\n",
    "                        'seed': seed,\n",
    "                        'noise_sigma': 0.1, \n",
    "                        'num_noise_samples': 10\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3110da",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_smooth, T_smooth = oput.run_empirical_smooth_optimization_batt(**opt_params_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd9c6a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "diroca_train_results_empirical['T_s'] = {\n",
    "                                'optimization_params': params_smooth,\n",
    "                                'T_matrix': T_smooth\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17798a79",
   "metadata": {},
   "source": [
    "### Abs-LiNGAM optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07be452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linabs_results = evut.run_abs_lingam_complete(df_base_train, df_abst_train)\n",
    "\n",
    "diroca_train_results_empirical['T_pa'] = {'optimization_params':{'L':{'pert_U':U_ll_hat},'H':{'pert_U':U_hl_hat}}, 'T_matrix': linabs_results['Perfect']['T'].T}\n",
    "diroca_train_results_empirical['T_na'] = {'optimization_params':{'L':{'pert_U':U_ll_hat},'H':{'pert_U':U_hl_hat}}, 'T_matrix': linabs_results['Noisy']['T'].T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "969ae0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07897e15",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da17060",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(diroca_train_results_empirical, f\"data/{experiment}/diroca_train_results_empirical.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "149c4ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#diroca_train_results_empirical = joblib.load(f\"data/{experiment}/diroca_train_results_empirical.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f70d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33973829",
   "metadata": {},
   "source": [
    "# Downstream Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f326a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_wmg_to_lrcs_cg(wmg_cg_values):\n",
    "    \"\"\"\n",
    "    Map WMG CG values into LRCS CG domain (75, 100, 200).\n",
    "    This is manual based on the abstraction described.\n",
    "    \"\"\"\n",
    "    mapped_cg = []\n",
    "    for val in wmg_cg_values:\n",
    "        if val in [0]:  # WMG 75 mapped to LRCS 75\n",
    "            mapped_cg.append(0)\n",
    "        elif val in [1, 2, 3, 4]:  # WMG 110, 150, 170, 180 mapped to LRCS 100\n",
    "            mapped_cg.append(1)\n",
    "        elif val in [5]:  # WMG 200 mapped to LRCS 200\n",
    "            mapped_cg.append(2)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected WMG CG value {val} during mapping.\")\n",
    "    return np.array(mapped_cg)\n",
    "\n",
    "def downstream_evaluation_fair(T, df_base, df_abst):\n",
    "    \"\"\"\n",
    "    Implements paper's evaluation methodology: Scenarios (a), (b), (c).\n",
    "    Assumes df_base and df_abst are preprocessed as described.\n",
    "    \"\"\"\n",
    "\n",
    "    df_base_np = df_base.to_numpy()\n",
    "    df_abst_np = df_abst.to_numpy()\n",
    "\n",
    "    # Map and bin the base samples\n",
    "    tau_samples = evut.map_n_bin_old(T, df_base_np, df_abst_np)\n",
    "\n",
    "    # Map CG values from WMG (base) to LRCS space\n",
    "    tau_samples[:, 0] = map_wmg_to_lrcs_cg(tau_samples[:, 0].astype(int))\n",
    "\n",
    "    comma_gaps = np.unique(df_abst_np[:, 0])\n",
    "    lasso_params = {'alpha': 0.0001, 'max_iter': 500, 'tol': 0.0001}\n",
    "\n",
    "    # Concatenate LRCS and transported WMG (for scenarios b and c)\n",
    "    enhanced_data = np.concatenate([df_abst_np, tau_samples])\n",
    "\n",
    "    results = {'Real': [], 'Aug': [], 'AugReal': []}\n",
    "\n",
    "    for cg in comma_gaps:\n",
    "        # Scenario (a): Real only\n",
    "        train_mask_a = (df_abst_np[:, 0] != cg)\n",
    "        test_mask_a = (df_abst_np[:, 0] == cg)\n",
    "\n",
    "        X_train_a = df_abst_np[train_mask_a, 0].reshape(-1, 1)\n",
    "        y_train_a = df_abst_np[train_mask_a, 1]\n",
    "        X_test_a = df_abst_np[test_mask_a, 0].reshape(-1, 1)\n",
    "        y_test_a = df_abst_np[test_mask_a, 1]\n",
    "\n",
    "        model_a = Lasso(**lasso_params).fit(X_train_a, y_train_a)\n",
    "        y_pred_a = model_a.predict(X_test_a)\n",
    "        mse_a = np.mean((y_pred_a - y_test_a) ** 2)\n",
    "        results['Real'].append(mse_a)\n",
    "\n",
    "        # Scenario (b): Augmented (full WMG support)\n",
    "        # Train on LRCS (CG ≠ cg) + all tau_samples\n",
    "        train_mask_b = np.ones(len(enhanced_data), dtype=bool)\n",
    "        train_mask_b[:len(df_abst_np)][test_mask_a] = False  # Drop LRCS samples with CG=cg\n",
    "\n",
    "        X_train_b = enhanced_data[train_mask_b, 0].reshape(-1, 1)\n",
    "        y_train_b = enhanced_data[train_mask_b, 1]\n",
    "        X_test_b = df_abst_np[test_mask_a, 0].reshape(-1, 1)\n",
    "        y_test_b = df_abst_np[test_mask_a, 1]\n",
    "\n",
    "        model_b = Lasso(**lasso_params).fit(X_train_b, y_train_b)\n",
    "        y_pred_b = model_b.predict(X_test_b)\n",
    "        mse_b = np.mean((y_pred_b - y_test_b) ** 2)\n",
    "        results['Aug'].append(mse_b)\n",
    "\n",
    "        # Scenario (c): Augmented without support\n",
    "        test_mask_tau = (tau_samples[:, 0] == cg)\n",
    "\n",
    "        train_data_c = np.concatenate([\n",
    "            df_abst_np[~test_mask_a],\n",
    "            tau_samples[~test_mask_tau]\n",
    "        ])\n",
    "\n",
    "        test_data_c = np.concatenate([\n",
    "            df_abst_np[test_mask_a],\n",
    "            tau_samples[test_mask_tau]\n",
    "        ])\n",
    "\n",
    "        X_train_c = train_data_c[:, 0].reshape(-1, 1)\n",
    "        y_train_c = train_data_c[:, 1]\n",
    "        X_test_c = test_data_c[:, 0].reshape(-1, 1)\n",
    "        y_test_c = test_data_c[:, 1]\n",
    "\n",
    "        model_c = Lasso(**lasso_params).fit(X_train_c, y_train_c)\n",
    "        y_pred_c = model_c.predict(X_test_c)\n",
    "        mse_c = np.mean((y_pred_c - y_test_c) ** 2)\n",
    "        results['AugReal'].append(mse_c)\n",
    "\n",
    "    # Aggregate\n",
    "    final_results = {\n",
    "        'Real': (np.mean(results['Real']), np.std(results['Real'])),\n",
    "        'Aug': (np.mean(results['Aug']), np.std(results['Aug'])),\n",
    "        'AugReal': (np.mean(results['AugReal']), np.std(results['AugReal'])),\n",
    "    }\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeea1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ordered_results(results_dict, scenario_name):\n",
    "    # Extract results for the given scenario\n",
    "    scenario_results = {method: results_dict[method][scenario_name] for method in results_dict.keys()}\n",
    "    \n",
    "    # Sort by mean error (first element of the tuple) in descending order (worst to best)\n",
    "    sorted_results = dict(sorted(scenario_results.items(), key=lambda x: x[1][0], reverse=True))\n",
    "    \n",
    "    print(f\"\\n{scenario_name} Scenario\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Rank':<5} {'Method':<15} {'Error (mean ± std)':<35}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    for rank, (method, (mean, std)) in enumerate(sorted_results.items(), 1):\n",
    "        print(f\"{rank:<5} {method:<15} {mean:>8.4f} ± {std:<8.4f}\")\n",
    "\n",
    "# ========== FIRST compute downstream evaluations ==========\n",
    "all_results = {}\n",
    "for method in diroca_train_results_empirical.keys():\n",
    "    T_matrix = diroca_train_results_empirical[method]['T_matrix']\n",
    "    eval_result = downstream_evaluation_fair(T_matrix, df_base, df_abst)\n",
    "    all_results[method] = eval_result\n",
    "\n",
    "# ========== THEN print for each scenario ==========\n",
    "print(\"\\nAbstraction Performance Evaluation\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Real → Real scenario\n",
    "print_ordered_results(all_results, 'Real')\n",
    "\n",
    "# Aug → Real scenario\n",
    "print_ordered_results(all_results, 'Aug')\n",
    "\n",
    "# Real+Aug → Real scenario\n",
    "print_ordered_results(all_results, 'AugReal')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erica",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
